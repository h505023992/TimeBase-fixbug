Args in experiment:
Namespace(is_training=1, model_id='electricity_96_192', model='FITS', data='custom', root_path='./dataset/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=321, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=34, base_T=36, H_order=8)
Use GPU: cuda:0
>>>>>>>start training : electricity_96_192_FITS_custom_ftM_sl96_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18125
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=34, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  142493184.0
params:  3570.0
Trainable parameters:  3570
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.9154408
	speed: 0.1043s/iter; left time: 430.7838s
Epoch: 1 cost time: 14.15884804725647
Epoch: 1, Steps: 141 | Train Loss: 1.0627376 Vali Loss: 0.7372134 Test Loss: 0.8342131
Validation loss decreased (inf --> 0.737213).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6064581
	speed: 0.2371s/iter; left time: 945.9318s
Epoch: 2 cost time: 13.80601954460144
Epoch: 2, Steps: 141 | Train Loss: 0.6594853 Vali Loss: 0.5362214 Test Loss: 0.6108577
Validation loss decreased (0.737213 --> 0.536221).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4835306
	speed: 0.2447s/iter; left time: 941.9689s
Epoch: 3 cost time: 14.267192125320435
Epoch: 3, Steps: 141 | Train Loss: 0.5103960 Vali Loss: 0.4521969 Test Loss: 0.5167351
Validation loss decreased (0.536221 --> 0.452197).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4160622
	speed: 0.2542s/iter; left time: 942.5047s
Epoch: 4 cost time: 14.212764978408813
Epoch: 4, Steps: 141 | Train Loss: 0.4360638 Vali Loss: 0.4015689 Test Loss: 0.4599191
Validation loss decreased (0.452197 --> 0.401569).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3645018
	speed: 0.2616s/iter; left time: 932.9693s
Epoch: 5 cost time: 15.03574514389038
Epoch: 5, Steps: 141 | Train Loss: 0.3854709 Vali Loss: 0.3644838 Test Loss: 0.4182689
Validation loss decreased (0.401569 --> 0.364484).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3321494
	speed: 0.2808s/iter; left time: 961.9140s
Epoch: 6 cost time: 14.703623533248901
Epoch: 6, Steps: 141 | Train Loss: 0.3458062 Vali Loss: 0.3336419 Test Loss: 0.3834588
Validation loss decreased (0.364484 --> 0.333642).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3158238
	speed: 0.2555s/iter; left time: 839.3117s
Epoch: 7 cost time: 13.928312540054321
Epoch: 7, Steps: 141 | Train Loss: 0.3130721 Vali Loss: 0.3091147 Test Loss: 0.3556199
Validation loss decreased (0.333642 --> 0.309115).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2701858
	speed: 0.2424s/iter; left time: 761.9789s
Epoch: 8 cost time: 13.544395923614502
Epoch: 8, Steps: 141 | Train Loss: 0.2859074 Vali Loss: 0.2883735 Test Loss: 0.3323742
Validation loss decreased (0.309115 --> 0.288374).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2631655
	speed: 0.2474s/iter; left time: 742.8522s
Epoch: 9 cost time: 14.453382968902588
Epoch: 9, Steps: 141 | Train Loss: 0.2630126 Vali Loss: 0.2707180 Test Loss: 0.3122283
Validation loss decreased (0.288374 --> 0.270718).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2379373
	speed: 0.2573s/iter; left time: 736.3236s
Epoch: 10 cost time: 14.462460279464722
Epoch: 10, Steps: 141 | Train Loss: 0.2438085 Vali Loss: 0.2559094 Test Loss: 0.2954991
Validation loss decreased (0.270718 --> 0.255909).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2212856
	speed: 0.2638s/iter; left time: 717.7777s
Epoch: 11 cost time: 14.585227012634277
Epoch: 11, Steps: 141 | Train Loss: 0.2276161 Vali Loss: 0.2436413 Test Loss: 0.2815767
Validation loss decreased (0.255909 --> 0.243641).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2151538
	speed: 0.2447s/iter; left time: 631.3113s
Epoch: 12 cost time: 13.628218412399292
Epoch: 12, Steps: 141 | Train Loss: 0.2140645 Vali Loss: 0.2328379 Test Loss: 0.2694480
Validation loss decreased (0.243641 --> 0.232838).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1986589
	speed: 0.2338s/iter; left time: 570.1316s
Epoch: 13 cost time: 13.367367029190063
Epoch: 13, Steps: 141 | Train Loss: 0.2025068 Vali Loss: 0.2239097 Test Loss: 0.2591521
Validation loss decreased (0.232838 --> 0.223910).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1886241
	speed: 0.2282s/iter; left time: 524.3424s
Epoch: 14 cost time: 13.289210319519043
Epoch: 14, Steps: 141 | Train Loss: 0.1927760 Vali Loss: 0.2165412 Test Loss: 0.2507947
Validation loss decreased (0.223910 --> 0.216541).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1822086
	speed: 0.2303s/iter; left time: 496.7451s
Epoch: 15 cost time: 13.239831686019897
Epoch: 15, Steps: 141 | Train Loss: 0.1844636 Vali Loss: 0.2104816 Test Loss: 0.2437400
Validation loss decreased (0.216541 --> 0.210482).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1780081
	speed: 0.2342s/iter; left time: 472.1532s
Epoch: 16 cost time: 13.99804401397705
Epoch: 16, Steps: 141 | Train Loss: 0.1774171 Vali Loss: 0.2049522 Test Loss: 0.2374321
Validation loss decreased (0.210482 --> 0.204952).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1703636
	speed: 0.2418s/iter; left time: 453.2927s
Epoch: 17 cost time: 13.423348188400269
Epoch: 17, Steps: 141 | Train Loss: 0.1715289 Vali Loss: 0.2004099 Test Loss: 0.2323014
Validation loss decreased (0.204952 --> 0.200410).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1746522
	speed: 0.2437s/iter; left time: 422.5474s
Epoch: 18 cost time: 13.50446891784668
Epoch: 18, Steps: 141 | Train Loss: 0.1664235 Vali Loss: 0.1966707 Test Loss: 0.2279406
Validation loss decreased (0.200410 --> 0.196671).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1624456
	speed: 0.2503s/iter; left time: 398.7541s
Epoch: 19 cost time: 13.957790613174438
Epoch: 19, Steps: 141 | Train Loss: 0.1621626 Vali Loss: 0.1933142 Test Loss: 0.2241395
Validation loss decreased (0.196671 --> 0.193314).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1565936
	speed: 0.2442s/iter; left time: 354.5975s
Epoch: 20 cost time: 13.46579384803772
Epoch: 20, Steps: 141 | Train Loss: 0.1585719 Vali Loss: 0.1906989 Test Loss: 0.2210247
Validation loss decreased (0.193314 --> 0.190699).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1575615
	speed: 0.2407s/iter; left time: 315.5313s
Epoch: 21 cost time: 13.432504892349243
Epoch: 21, Steps: 141 | Train Loss: 0.1554559 Vali Loss: 0.1885349 Test Loss: 0.2184162
Validation loss decreased (0.190699 --> 0.188535).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1461480
	speed: 0.2432s/iter; left time: 284.5483s
Epoch: 22 cost time: 13.801822423934937
Epoch: 22, Steps: 141 | Train Loss: 0.1528313 Vali Loss: 0.1865259 Test Loss: 0.2161580
Validation loss decreased (0.188535 --> 0.186526).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1512009
	speed: 0.2616s/iter; left time: 269.1801s
Epoch: 23 cost time: 14.847299337387085
Epoch: 23, Steps: 141 | Train Loss: 0.1505630 Vali Loss: 0.1848644 Test Loss: 0.2141337
Validation loss decreased (0.186526 --> 0.184864).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1506281
	speed: 0.2653s/iter; left time: 235.5523s
Epoch: 24 cost time: 14.677419662475586
Epoch: 24, Steps: 141 | Train Loss: 0.1486480 Vali Loss: 0.1834156 Test Loss: 0.2125164
Validation loss decreased (0.184864 --> 0.183416).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1472082
	speed: 0.2635s/iter; left time: 196.8129s
Epoch: 25 cost time: 14.520806789398193
Epoch: 25, Steps: 141 | Train Loss: 0.1470282 Vali Loss: 0.1822185 Test Loss: 0.2110859
Validation loss decreased (0.183416 --> 0.182219).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1462288
	speed: 0.2594s/iter; left time: 157.2213s
Epoch: 26 cost time: 14.306194067001343
Epoch: 26, Steps: 141 | Train Loss: 0.1456832 Vali Loss: 0.1812062 Test Loss: 0.2099447
Validation loss decreased (0.182219 --> 0.181206).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1458360
	speed: 0.2491s/iter; left time: 115.8271s
Epoch: 27 cost time: 13.581093549728394
Epoch: 27, Steps: 141 | Train Loss: 0.1444824 Vali Loss: 0.1804758 Test Loss: 0.2089355
Validation loss decreased (0.181206 --> 0.180476).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1430617
	speed: 0.2409s/iter; left time: 78.0538s
Epoch: 28 cost time: 13.368746757507324
Epoch: 28, Steps: 141 | Train Loss: 0.1434798 Vali Loss: 0.1796602 Test Loss: 0.2079940
Validation loss decreased (0.180476 --> 0.179660).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1428701
	speed: 0.2429s/iter; left time: 44.4503s
Epoch: 29 cost time: 13.574689865112305
Epoch: 29, Steps: 141 | Train Loss: 0.1426261 Vali Loss: 0.1791120 Test Loss: 0.2073051
Validation loss decreased (0.179660 --> 0.179112).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.1382112
	speed: 0.2391s/iter; left time: 10.0420s
Epoch: 30 cost time: 13.487258195877075
Epoch: 30, Steps: 141 | Train Loss: 0.1419142 Vali Loss: 0.1786273 Test Loss: 0.2066984
Validation loss decreased (0.179112 --> 0.178627).  Saving model ...
Updating learning rate to 0.00011296777049628277
train 18125
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=34, out_features=102, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  142493184.0
params:  3570.0
Trainable parameters:  3570
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2057816
	speed: 0.1020s/iter; left time: 421.5461s
Epoch: 1 cost time: 13.684280395507812
Epoch: 1, Steps: 141 | Train Loss: 0.2020826 Vali Loss: 0.1761637 Test Loss: 0.2030706
Validation loss decreased (inf --> 0.176164).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1962635
	speed: 0.2464s/iter; left time: 983.1425s
Epoch: 2 cost time: 14.128167629241943
Epoch: 2, Steps: 141 | Train Loss: 0.2013458 Vali Loss: 0.1762259 Test Loss: 0.2030379
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2111010
	speed: 0.2441s/iter; left time: 939.5710s
Epoch: 3 cost time: 13.82299280166626
Epoch: 3, Steps: 141 | Train Loss: 0.2012447 Vali Loss: 0.1761033 Test Loss: 0.2030155
Validation loss decreased (0.176164 --> 0.176103).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2054753
	speed: 0.2402s/iter; left time: 890.7251s
Epoch: 4 cost time: 13.52659821510315
Epoch: 4, Steps: 141 | Train Loss: 0.2013327 Vali Loss: 0.1762035 Test Loss: 0.2029918
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1968170
	speed: 0.2423s/iter; left time: 864.4484s
Epoch: 5 cost time: 13.909393310546875
Epoch: 5, Steps: 141 | Train Loss: 0.2013166 Vali Loss: 0.1760953 Test Loss: 0.2029725
Validation loss decreased (0.176103 --> 0.176095).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2041800
	speed: 0.2708s/iter; left time: 927.9028s
Epoch: 6 cost time: 15.361813068389893
Epoch: 6, Steps: 141 | Train Loss: 0.2012414 Vali Loss: 0.1760521 Test Loss: 0.2029934
Validation loss decreased (0.176095 --> 0.176052).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1978933
	speed: 0.2769s/iter; left time: 909.6225s
Epoch: 7 cost time: 15.434783220291138
Epoch: 7, Steps: 141 | Train Loss: 0.2012443 Vali Loss: 0.1761886 Test Loss: 0.2029636
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2076254
	speed: 0.2879s/iter; left time: 905.2578s
Epoch: 8 cost time: 15.499948024749756
Epoch: 8, Steps: 141 | Train Loss: 0.2012327 Vali Loss: 0.1761009 Test Loss: 0.2029670
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1917560
	speed: 0.2568s/iter; left time: 771.3021s
Epoch: 9 cost time: 13.981579542160034
Epoch: 9, Steps: 141 | Train Loss: 0.2012407 Vali Loss: 0.1761248 Test Loss: 0.2029491
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2078866
	speed: 0.2552s/iter; left time: 730.4314s
Epoch: 10 cost time: 14.06578516960144
Epoch: 10, Steps: 141 | Train Loss: 0.2012758 Vali Loss: 0.1761236 Test Loss: 0.2029553
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2000972
	speed: 0.2634s/iter; left time: 716.7935s
Epoch: 11 cost time: 14.967482328414917
Epoch: 11, Steps: 141 | Train Loss: 0.2012091 Vali Loss: 0.1761700 Test Loss: 0.2029446
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : electricity_96_192_FITS_custom_ftM_sl96_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.2005864381790161, mae:0.2818484604358673, rse:0.44530045986175537, corr:[0.45926547 0.45962188 0.45844015 0.457338   0.45611736 0.45551986
 0.45457596 0.45357093 0.45266336 0.45185935 0.45131087 0.4510381
 0.45070297 0.450309   0.4500233  0.4497246  0.44954455 0.44944307
 0.4491573  0.44871876 0.4485354  0.4486093  0.44846812 0.44851097
 0.4481936  0.44724822 0.4465001  0.44536403 0.4442901  0.44381845
 0.44338116 0.44292945 0.4423609  0.4415579  0.44125584 0.4412221
 0.4411101  0.44095263 0.44084153 0.440871   0.4408255  0.44102463
 0.44100502 0.44096717 0.44157684 0.44231114 0.44288117 0.44430032
 0.44558197 0.44581127 0.44576597 0.44565785 0.4454898  0.44537997
 0.44539505 0.44525424 0.44497836 0.44492993 0.44505155 0.4451684
 0.4453838  0.4456237  0.44607222 0.44660342 0.44701824 0.44770873
 0.44872764 0.44941622 0.4503957  0.45188582 0.4531809  0.4555723
 0.4582057  0.45922682 0.45948955 0.45944506 0.4595642  0.4596964
 0.45969567 0.45968166 0.45966917 0.4596092  0.4595403  0.45953563
 0.45953918 0.45951286 0.45953768 0.4595792  0.45956844 0.4595877
 0.45961955 0.45948234 0.4593369  0.45934653 0.45939603 0.45953643
 0.45960674 0.45961204 0.45964098 0.45953497 0.45946205 0.45946297
 0.45941624 0.45932478 0.45920813 0.4590444  0.45894435 0.45895964
 0.45895094 0.45894206 0.45903596 0.4590997  0.45904514 0.4590388
 0.45910946 0.45905414 0.45903674 0.45915735 0.45916748 0.45918196
 0.45926565 0.45930624 0.4592614  0.4591649  0.45910457 0.4590805
 0.45908785 0.45910344 0.45902067 0.4588311  0.45873865 0.45883563
 0.4589029  0.45888036 0.45892388 0.4589973  0.45903417 0.4590828
 0.45905393 0.45888618 0.45885032 0.45889533 0.4588241  0.4588559
 0.45892656 0.45897484 0.45897213 0.45882198 0.4587189  0.45878237
 0.45882216 0.45874882 0.4586682  0.45860702 0.4585521  0.4585882
 0.4585991  0.45849377 0.45848593 0.4585986  0.4585794  0.45845827
 0.45839912 0.4581806  0.45784172 0.45759338 0.45711702 0.45618075
 0.45419317 0.45235378 0.45107818 0.44945621 0.44835132 0.44761664
 0.44665357 0.44577572 0.4449921  0.4443128  0.44393557 0.44372135
 0.44337368 0.4431666  0.44308    0.4428185  0.44273084 0.44287455
 0.4426867  0.44225097 0.44226387 0.44244274 0.44235834 0.44257262]

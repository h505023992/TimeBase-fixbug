Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='96_720', model='PatchTST', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:1
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 41201664.0
Params: 1506256.0
41.20M MACs
>>>>>>>start training : 96_720_PatchTST_ETTm1_ftM_sl96_ll48_pl720_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.6382208
	speed: 0.1207s/iter; left time: 943.9939s
	iters: 200, epoch: 1 | loss: 0.5941479
	speed: 0.1142s/iter; left time: 881.4887s
Epoch: 1 cost time: 29.776305437088013
Epoch: 1, Steps: 264 | Train Loss: 0.6374168 Vali Loss: 1.1129818 Test Loss: 0.6036698
Validation loss decreased (inf --> 1.112982).  Saving model ...
Updating learning rate to 5.636587467186684e-06
	iters: 100, epoch: 2 | loss: 0.5733723
	speed: 0.4728s/iter; left time: 3572.9462s
	iters: 200, epoch: 2 | loss: 0.5415843
	speed: 0.1290s/iter; left time: 961.9965s
Epoch: 2 cost time: 33.75156879425049
Epoch: 2, Steps: 264 | Train Loss: 0.5462318 Vali Loss: 1.0256717 Test Loss: 0.5155673
Validation loss decreased (1.112982 --> 1.025672).  Saving model ...
Updating learning rate to 1.043474909634038e-05
	iters: 100, epoch: 3 | loss: 0.4837381
	speed: 0.4994s/iter; left time: 3642.3566s
	iters: 200, epoch: 3 | loss: 0.5248056
	speed: 0.1196s/iter; left time: 860.0660s
Epoch: 3 cost time: 32.12931823730469
Epoch: 3, Steps: 264 | Train Loss: 0.5131688 Vali Loss: 1.0089138 Test Loss: 0.4938425
Validation loss decreased (1.025672 --> 1.008914).  Saving model ...
Updating learning rate to 1.806729275463572e-05
	iters: 100, epoch: 4 | loss: 0.4675677
	speed: 0.5166s/iter; left time: 3631.1165s
	iters: 200, epoch: 4 | loss: 0.5016839
	speed: 0.1162s/iter; left time: 804.8487s
Epoch: 4 cost time: 32.34991669654846
Epoch: 4, Steps: 264 | Train Loss: 0.5012622 Vali Loss: 1.0029323 Test Loss: 0.4829733
Validation loss decreased (1.008914 --> 1.002932).  Saving model ...
Updating learning rate to 2.8013746554825966e-05
	iters: 100, epoch: 5 | loss: 0.4923671
	speed: 0.4862s/iter; left time: 3289.3395s
	iters: 200, epoch: 5 | loss: 0.4780928
	speed: 0.1140s/iter; left time: 759.8896s
Epoch: 5 cost time: 31.4424250125885
Epoch: 5, Steps: 264 | Train Loss: 0.4938257 Vali Loss: 1.0000480 Test Loss: 0.4745512
Validation loss decreased (1.002932 --> 1.000048).  Saving model ...
Updating learning rate to 3.959585042889686e-05
	iters: 100, epoch: 6 | loss: 0.4660070
	speed: 0.4810s/iter; left time: 3127.0893s
	iters: 200, epoch: 6 | loss: 0.5028955
	speed: 0.1020s/iter; left time: 652.6057s
Epoch: 6 cost time: 28.761106729507446
Epoch: 6, Steps: 264 | Train Loss: 0.4862751 Vali Loss: 0.9937682 Test Loss: 0.4706620
Validation loss decreased (1.000048 --> 0.993768).  Saving model ...
Updating learning rate to 5.2023807458350115e-05
	iters: 100, epoch: 7 | loss: 0.4739006
	speed: 0.4778s/iter; left time: 2980.0279s
	iters: 200, epoch: 7 | loss: 0.5008060
	speed: 0.1076s/iter; left time: 660.2109s
Epoch: 7 cost time: 30.26506996154785
Epoch: 7, Steps: 264 | Train Loss: 0.4785163 Vali Loss: 0.9802016 Test Loss: 0.4654381
Validation loss decreased (0.993768 --> 0.980202).  Saving model ...
Updating learning rate to 6.44501410299716e-05
	iters: 100, epoch: 8 | loss: 0.4570271
	speed: 0.4822s/iter; left time: 2879.8949s
	iters: 200, epoch: 8 | loss: 0.4854810
	speed: 0.1130s/iter; left time: 663.5291s
Epoch: 8 cost time: 29.97902488708496
Epoch: 8, Steps: 264 | Train Loss: 0.4722997 Vali Loss: 0.9756069 Test Loss: 0.4622907
Validation loss decreased (0.980202 --> 0.975607).  Saving model ...
Updating learning rate to 7.602748523599488e-05
	iters: 100, epoch: 9 | loss: 0.4719738
	speed: 0.4497s/iter; left time: 2567.4998s
	iters: 200, epoch: 9 | loss: 0.4295413
	speed: 0.1102s/iter; left time: 617.9474s
Epoch: 9 cost time: 30.51187229156494
Epoch: 9, Steps: 264 | Train Loss: 0.4671192 Vali Loss: 0.9720200 Test Loss: 0.4586178
Validation loss decreased (0.975607 --> 0.972020).  Saving model ...
Updating learning rate to 8.596636772513305e-05
	iters: 100, epoch: 10 | loss: 0.4580613
	speed: 0.4899s/iter; left time: 2667.4209s
	iters: 200, epoch: 10 | loss: 0.4599888
	speed: 0.1114s/iter; left time: 595.4472s
Epoch: 10 cost time: 30.602569580078125
Epoch: 10, Steps: 264 | Train Loss: 0.4624169 Vali Loss: 0.9738631 Test Loss: 0.4610273
EarlyStopping counter: 1 out of 5
Updating learning rate to 9.358904472573757e-05
	iters: 100, epoch: 11 | loss: 0.4466490
	speed: 0.4764s/iter; left time: 2467.9967s
	iters: 200, epoch: 11 | loss: 0.4278672
	speed: 0.1094s/iter; left time: 555.7842s
Epoch: 11 cost time: 29.975918292999268
Epoch: 11, Steps: 264 | Train Loss: 0.4579856 Vali Loss: 0.9708064 Test Loss: 0.4556169
Validation loss decreased (0.972020 --> 0.970806).  Saving model ...
Updating learning rate to 9.837571716924175e-05
	iters: 100, epoch: 12 | loss: 0.4656873
	speed: 0.4750s/iter; left time: 2335.4066s
	iters: 200, epoch: 12 | loss: 0.4724263
	speed: 0.1133s/iter; left time: 545.9193s
Epoch: 12 cost time: 29.89349055290222
Epoch: 12, Steps: 264 | Train Loss: 0.4540803 Vali Loss: 0.9670662 Test Loss: 0.4568949
Validation loss decreased (0.970806 --> 0.967066).  Saving model ...
Updating learning rate to 9.999998907339768e-05
	iters: 100, epoch: 13 | loss: 0.4513479
	speed: 0.4646s/iter; left time: 2161.6705s
	iters: 200, epoch: 13 | loss: 0.4384349
	speed: 0.1082s/iter; left time: 492.7290s
Epoch: 13 cost time: 30.17668581008911
Epoch: 13, Steps: 264 | Train Loss: 0.4507904 Vali Loss: 0.9721810 Test Loss: 0.4514349
EarlyStopping counter: 1 out of 5
Updating learning rate to 9.923463992827402e-05
	iters: 100, epoch: 14 | loss: 0.4350710
	speed: 0.4846s/iter; left time: 2126.7527s
	iters: 200, epoch: 14 | loss: 0.4743078
	speed: 0.1105s/iter; left time: 474.0273s
Epoch: 14 cost time: 29.840096473693848
Epoch: 14, Steps: 264 | Train Loss: 0.4471817 Vali Loss: 0.9735425 Test Loss: 0.4538280
EarlyStopping counter: 2 out of 5
Updating learning rate to 9.697332723975848e-05
	iters: 100, epoch: 15 | loss: 0.4865506
	speed: 0.4245s/iter; left time: 1750.9972s
	iters: 200, epoch: 15 | loss: 0.4833460
	speed: 0.1130s/iter; left time: 454.9602s
Epoch: 15 cost time: 30.504449605941772
Epoch: 15, Steps: 264 | Train Loss: 0.4447991 Vali Loss: 0.9903586 Test Loss: 0.4544242
EarlyStopping counter: 3 out of 5
Updating learning rate to 9.328475984961217e-05
	iters: 100, epoch: 16 | loss: 0.4569262
	speed: 0.4847s/iter; left time: 1871.3299s
	iters: 200, epoch: 16 | loss: 0.4429264
	speed: 0.1117s/iter; left time: 420.0525s
Epoch: 16 cost time: 30.053635835647583
Epoch: 16, Steps: 264 | Train Loss: 0.4418926 Vali Loss: 0.9769912 Test Loss: 0.4513336
EarlyStopping counter: 4 out of 5
Updating learning rate to 8.82810130114795e-05
	iters: 100, epoch: 17 | loss: 0.4060651
	speed: 0.4763s/iter; left time: 1713.1416s
	iters: 200, epoch: 17 | loss: 0.4402728
	speed: 0.1082s/iter; left time: 378.5451s
Epoch: 17 cost time: 30.32449769973755
Epoch: 17, Steps: 264 | Train Loss: 0.4396917 Vali Loss: 0.9790208 Test Loss: 0.4531443
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : 96_720_PatchTST_ETTm1_ftM_sl96_ll48_pl720_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.4562359154224396, mae:0.43999233841896057, rse:0.6426366567611694

Args in experiment:
Namespace(is_training=1, model_id='ETTh1_96_336', model='LightTimeBaseTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, period_len=24, basis_num=6, use_period_norm=0, use_orthogonal=1, orthogonal_weight=0.12, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.05, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=6, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:6
128
>>>>>>>start training : ETTh1_96_336_LightTimeBaseTST_ETTh1_ftM_sl96_pl336_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
Epoch: 1 cost time: 1.6625308990478516
Epoch: 1, Steps: 17 | Train Loss: 0.7220035 Vali Loss: 1.7353289 Test Loss: 0.7783739
Validation loss decreased (inf --> 1.735329).  Saving model ...
Updating learning rate to 0.05
Epoch: 2 cost time: 0.9668164253234863
Epoch: 2, Steps: 17 | Train Loss: 0.7187366 Vali Loss: 1.7065767 Test Loss: 0.7390286
Validation loss decreased (1.735329 --> 1.706577).  Saving model ...
Updating learning rate to 0.05
Epoch: 3 cost time: 1.0076160430908203
Epoch: 3, Steps: 17 | Train Loss: 0.6558550 Vali Loss: 1.6240928 Test Loss: 0.6779156
Validation loss decreased (1.706577 --> 1.624093).  Saving model ...
Updating learning rate to 0.05
Epoch: 4 cost time: 1.1709070205688477
Epoch: 4, Steps: 17 | Train Loss: 0.6261562 Vali Loss: 1.4265263 Test Loss: 0.5514728
Validation loss decreased (1.624093 --> 1.426526).  Saving model ...
Updating learning rate to 0.04000000000000001
Epoch: 5 cost time: 1.1879312992095947
Epoch: 5, Steps: 17 | Train Loss: 0.5302748 Vali Loss: 1.3789635 Test Loss: 0.5008033
Validation loss decreased (1.426526 --> 1.378963).  Saving model ...
Updating learning rate to 0.03200000000000001
Epoch: 6 cost time: 1.1039667129516602
Epoch: 6, Steps: 17 | Train Loss: 0.5112601 Vali Loss: 1.3647099 Test Loss: 0.4896109
Validation loss decreased (1.378963 --> 1.364710).  Saving model ...
Updating learning rate to 0.025600000000000008
Epoch: 7 cost time: 1.2682685852050781
Epoch: 7, Steps: 17 | Train Loss: 0.5027818 Vali Loss: 1.3419070 Test Loss: 0.4800126
Validation loss decreased (1.364710 --> 1.341907).  Saving model ...
Updating learning rate to 0.020480000000000005
Epoch: 8 cost time: 1.1476562023162842
Epoch: 8, Steps: 17 | Train Loss: 0.4938981 Vali Loss: 1.3391488 Test Loss: 0.4766002
Validation loss decreased (1.341907 --> 1.339149).  Saving model ...
Updating learning rate to 0.016384000000000006
Epoch: 9 cost time: 1.1462132930755615
Epoch: 9, Steps: 17 | Train Loss: 0.5010839 Vali Loss: 1.3354595 Test Loss: 0.4771877
Validation loss decreased (1.339149 --> 1.335459).  Saving model ...
Updating learning rate to 0.013107200000000006
Epoch: 10 cost time: 1.101578950881958
Epoch: 10, Steps: 17 | Train Loss: 0.4983756 Vali Loss: 1.3330086 Test Loss: 0.4759578
Validation loss decreased (1.335459 --> 1.333009).  Saving model ...
Updating learning rate to 0.010485760000000004
Epoch: 11 cost time: 1.183861255645752
Epoch: 11, Steps: 17 | Train Loss: 0.4918420 Vali Loss: 1.3322216 Test Loss: 0.4751040
Validation loss decreased (1.333009 --> 1.332222).  Saving model ...
Updating learning rate to 0.008388608000000004
Epoch: 12 cost time: 1.221287727355957
Epoch: 12, Steps: 17 | Train Loss: 0.4923918 Vali Loss: 1.3313152 Test Loss: 0.4753693
Validation loss decreased (1.332222 --> 1.331315).  Saving model ...
Updating learning rate to 0.006710886400000004
Epoch: 13 cost time: 1.3420915603637695
Epoch: 13, Steps: 17 | Train Loss: 0.4995254 Vali Loss: 1.3308947 Test Loss: 0.4755157
Validation loss decreased (1.331315 --> 1.330895).  Saving model ...
Updating learning rate to 0.005368709120000003
Epoch: 14 cost time: 1.1970114707946777
Epoch: 14, Steps: 17 | Train Loss: 0.4971705 Vali Loss: 1.3318918 Test Loss: 0.4763335
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0042949672960000025
Epoch: 15 cost time: 1.2828667163848877
Epoch: 15, Steps: 17 | Train Loss: 0.4928712 Vali Loss: 1.3313516 Test Loss: 0.4760001
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0034359738368000023
Epoch: 16 cost time: 1.386518955230713
Epoch: 16, Steps: 17 | Train Loss: 0.4915131 Vali Loss: 1.3309462 Test Loss: 0.4759244
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.002748779069440002
Epoch: 17 cost time: 1.2366993427276611
Epoch: 17, Steps: 17 | Train Loss: 0.4867806 Vali Loss: 1.3300898 Test Loss: 0.4756382
Validation loss decreased (1.330895 --> 1.330090).  Saving model ...
Updating learning rate to 0.002199023255552002
Epoch: 18 cost time: 1.22391676902771
Epoch: 18, Steps: 17 | Train Loss: 0.4940197 Vali Loss: 1.3300264 Test Loss: 0.4754792
Validation loss decreased (1.330090 --> 1.330026).  Saving model ...
Updating learning rate to 0.0017592186044416017
Epoch: 19 cost time: 1.0582685470581055
Epoch: 19, Steps: 17 | Train Loss: 0.4963796 Vali Loss: 1.3297489 Test Loss: 0.4753239
Validation loss decreased (1.330026 --> 1.329749).  Saving model ...
Updating learning rate to 0.0014073748835532812
Epoch: 20 cost time: 1.0214753150939941
Epoch: 20, Steps: 17 | Train Loss: 0.4918744 Vali Loss: 1.3297741 Test Loss: 0.4752581
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0011258999068426252
Epoch: 21 cost time: 1.109090805053711
Epoch: 21, Steps: 17 | Train Loss: 0.4966782 Vali Loss: 1.3297247 Test Loss: 0.4753733
Validation loss decreased (1.329749 --> 1.329725).  Saving model ...
Updating learning rate to 0.0009007199254741002
Epoch: 22 cost time: 1.055161952972412
Epoch: 22, Steps: 17 | Train Loss: 0.4915969 Vali Loss: 1.3291942 Test Loss: 0.4752619
Validation loss decreased (1.329725 --> 1.329194).  Saving model ...
Updating learning rate to 0.0007205759403792802
Epoch: 23 cost time: 1.0278778076171875
Epoch: 23, Steps: 17 | Train Loss: 0.4937884 Vali Loss: 1.3296474 Test Loss: 0.4752971
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0005764607523034242
Epoch: 24 cost time: 1.3132305145263672
Epoch: 24, Steps: 17 | Train Loss: 0.4916165 Vali Loss: 1.3295357 Test Loss: 0.4753445
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00046116860184273935
Epoch: 25 cost time: 1.287844181060791
Epoch: 25, Steps: 17 | Train Loss: 0.4865000 Vali Loss: 1.3297635 Test Loss: 0.4753864
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0003689348814741915
Epoch: 26 cost time: 1.2860932350158691
Epoch: 26, Steps: 17 | Train Loss: 0.4956602 Vali Loss: 1.3297343 Test Loss: 0.4754650
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00029514790517935324
Epoch: 27 cost time: 1.3405311107635498
Epoch: 27, Steps: 17 | Train Loss: 0.4962763 Vali Loss: 1.3295438 Test Loss: 0.4754659
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTh1_96_336_LightTimeBaseTST_ETTh1_ftM_sl96_pl336_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4693410646915436, mae:0.4389318437576294, rse:0.6556882858276367

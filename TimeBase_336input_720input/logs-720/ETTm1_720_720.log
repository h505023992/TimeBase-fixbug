Args in experiment:
Namespace(is_training=1, model_id='ETTm1_720_720', model='LightTimeBaseTST', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=720, period_len=6, basis_num=20, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.12, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.01, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:1
4940
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 201600.0
Params: 4940.0
201600.0 MACs
>>>>>>>start training : ETTm1_720_720_LightTimeBaseTST_ETTm1_ftM_sl720_pl720_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5836669
	speed: 0.0408s/iter; left time: 312.8028s
	iters: 200, epoch: 1 | loss: 0.6034304
	speed: 0.0345s/iter; left time: 261.3174s
Max Memory (MB): 29.8134765625
Epoch: 1 cost time: 9.51216435432434
Epoch: 1, Steps: 259 | Train Loss: 0.6093317 Vali Loss: 1.4374374 Test Loss: 0.7150471
Validation loss decreased (inf --> 1.437437).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.4833263
	speed: 0.2060s/iter; left time: 1527.1227s
	iters: 200, epoch: 2 | loss: 0.4449076
	speed: 0.0416s/iter; left time: 304.2191s
Max Memory (MB): 34.62646484375
Epoch: 2 cost time: 11.303358554840088
Epoch: 2, Steps: 259 | Train Loss: 0.4819252 Vali Loss: 1.0464866 Test Loss: 0.5108579
Validation loss decreased (1.437437 --> 1.046487).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 3 | loss: 0.4555518
	speed: 0.1897s/iter; left time: 1357.2407s
	iters: 200, epoch: 3 | loss: 0.4621792
	speed: 0.0435s/iter; left time: 306.5147s
Max Memory (MB): 34.62646484375
Epoch: 3 cost time: 12.662114381790161
Epoch: 3, Steps: 259 | Train Loss: 0.4387743 Vali Loss: 1.0031087 Test Loss: 0.4619737
Validation loss decreased (1.046487 --> 1.003109).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 4 | loss: 0.4172868
	speed: 0.2303s/iter; left time: 1587.6786s
	iters: 200, epoch: 4 | loss: 0.4383847
	speed: 0.0453s/iter; left time: 307.7560s
Max Memory (MB): 34.62646484375
Epoch: 4 cost time: 12.54764437675476
Epoch: 4, Steps: 259 | Train Loss: 0.4360038 Vali Loss: 0.9971601 Test Loss: 0.4409000
Validation loss decreased (1.003109 --> 0.997160).  Saving model ...
Updating learning rate to 0.008
	iters: 100, epoch: 5 | loss: 0.4187718
	speed: 0.1947s/iter; left time: 1291.5384s
	iters: 200, epoch: 5 | loss: 0.4463449
	speed: 0.0319s/iter; left time: 208.7490s
Max Memory (MB): 34.62646484375
Epoch: 5 cost time: 9.408361911773682
Epoch: 5, Steps: 259 | Train Loss: 0.4248588 Vali Loss: 0.9930326 Test Loss: 0.4407998
Validation loss decreased (0.997160 --> 0.993033).  Saving model ...
Updating learning rate to 0.006400000000000001
	iters: 100, epoch: 6 | loss: 0.4272002
	speed: 0.1993s/iter; left time: 1270.8148s
	iters: 200, epoch: 6 | loss: 0.4294530
	speed: 0.0469s/iter; left time: 294.2611s
Max Memory (MB): 34.62646484375
Epoch: 6 cost time: 12.636117219924927
Epoch: 6, Steps: 259 | Train Loss: 0.4201519 Vali Loss: 0.9915473 Test Loss: 0.4438687
Validation loss decreased (0.993033 --> 0.991547).  Saving model ...
Updating learning rate to 0.005120000000000001
	iters: 100, epoch: 7 | loss: 0.3951240
	speed: 0.2107s/iter; left time: 1289.1217s
	iters: 200, epoch: 7 | loss: 0.4207911
	speed: 0.0338s/iter; left time: 203.2880s
Max Memory (MB): 34.62646484375
Epoch: 7 cost time: 9.604480981826782
Epoch: 7, Steps: 259 | Train Loss: 0.4174742 Vali Loss: 0.9803305 Test Loss: 0.4242689
Validation loss decreased (0.991547 --> 0.980331).  Saving model ...
Updating learning rate to 0.004096000000000001
	iters: 100, epoch: 8 | loss: 0.3745300
	speed: 0.1929s/iter; left time: 1130.2349s
	iters: 200, epoch: 8 | loss: 0.4477093
	speed: 0.0438s/iter; left time: 252.1494s
Max Memory (MB): 34.62646484375
Epoch: 8 cost time: 12.553296327590942
Epoch: 8, Steps: 259 | Train Loss: 0.4136873 Vali Loss: 0.9640257 Test Loss: 0.4329535
Validation loss decreased (0.980331 --> 0.964026).  Saving model ...
Updating learning rate to 0.0032768000000000007
	iters: 100, epoch: 9 | loss: 0.3840169
	speed: 0.2281s/iter; left time: 1277.1715s
	iters: 200, epoch: 9 | loss: 0.3705639
	speed: 0.0375s/iter; left time: 206.3626s
Max Memory (MB): 34.62646484375
Epoch: 9 cost time: 10.788704872131348
Epoch: 9, Steps: 259 | Train Loss: 0.4116061 Vali Loss: 0.9558392 Test Loss: 0.4244818
Validation loss decreased (0.964026 --> 0.955839).  Saving model ...
Updating learning rate to 0.002621440000000001
	iters: 100, epoch: 10 | loss: 0.4040132
	speed: 0.1668s/iter; left time: 890.6332s
	iters: 200, epoch: 10 | loss: 0.3862467
	speed: 0.0374s/iter; left time: 196.2329s
Max Memory (MB): 34.62646484375
Epoch: 10 cost time: 10.611217737197876
Epoch: 10, Steps: 259 | Train Loss: 0.4099278 Vali Loss: 0.9683808 Test Loss: 0.4245724
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.002097152000000001
	iters: 100, epoch: 11 | loss: 0.3922349
	speed: 0.2276s/iter; left time: 1156.5906s
	iters: 200, epoch: 11 | loss: 0.4149249
	speed: 0.0450s/iter; left time: 224.1204s
Max Memory (MB): 34.62646484375
Epoch: 11 cost time: 12.323818445205688
Epoch: 11, Steps: 259 | Train Loss: 0.4087482 Vali Loss: 0.9554669 Test Loss: 0.4185865
Validation loss decreased (0.955839 --> 0.955467).  Saving model ...
Updating learning rate to 0.001677721600000001
	iters: 100, epoch: 12 | loss: 0.3791223
	speed: 0.1722s/iter; left time: 830.4162s
	iters: 200, epoch: 12 | loss: 0.4090948
	speed: 0.0407s/iter; left time: 192.1805s
Max Memory (MB): 34.62646484375
Epoch: 12 cost time: 10.837129592895508
Epoch: 12, Steps: 259 | Train Loss: 0.4073698 Vali Loss: 0.9466684 Test Loss: 0.4192185
Validation loss decreased (0.955467 --> 0.946668).  Saving model ...
Updating learning rate to 0.0013421772800000006
	iters: 100, epoch: 13 | loss: 0.4164800
	speed: 0.2208s/iter; left time: 1007.3683s
	iters: 200, epoch: 13 | loss: 0.4196081
	speed: 0.0355s/iter; left time: 158.2568s
Max Memory (MB): 34.62646484375
Epoch: 13 cost time: 11.259390115737915
Epoch: 13, Steps: 259 | Train Loss: 0.4064969 Vali Loss: 0.9562595 Test Loss: 0.4191414
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0010737418240000006
	iters: 100, epoch: 14 | loss: 0.3903438
	speed: 0.2003s/iter; left time: 862.1939s
	iters: 200, epoch: 14 | loss: 0.4153059
	speed: 0.0402s/iter; left time: 169.1514s
Max Memory (MB): 34.62646484375
Epoch: 14 cost time: 10.964285373687744
Epoch: 14, Steps: 259 | Train Loss: 0.4057446 Vali Loss: 0.9475992 Test Loss: 0.4172605
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0008589934592000006
	iters: 100, epoch: 15 | loss: 0.3981564
	speed: 0.1945s/iter; left time: 786.8264s
	iters: 200, epoch: 15 | loss: 0.3898821
	speed: 0.0440s/iter; left time: 173.4442s
Max Memory (MB): 34.62646484375
Epoch: 15 cost time: 12.306542158126831
Epoch: 15, Steps: 259 | Train Loss: 0.4052481 Vali Loss: 0.9527844 Test Loss: 0.4165777
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0006871947673600004
	iters: 100, epoch: 16 | loss: 0.4047333
	speed: 0.2115s/iter; left time: 800.6366s
	iters: 200, epoch: 16 | loss: 0.4086801
	speed: 0.0447s/iter; left time: 164.8050s
Max Memory (MB): 34.62646484375
Epoch: 16 cost time: 12.236377954483032
Epoch: 16, Steps: 259 | Train Loss: 0.4046713 Vali Loss: 0.9514464 Test Loss: 0.4180947
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0005497558138880004
	iters: 100, epoch: 17 | loss: 0.4313331
	speed: 0.2041s/iter; left time: 719.8208s
	iters: 200, epoch: 17 | loss: 0.3871354
	speed: 0.0343s/iter; left time: 117.4868s
Max Memory (MB): 34.62646484375
Epoch: 17 cost time: 9.56534194946289
Epoch: 17, Steps: 259 | Train Loss: 0.4040682 Vali Loss: 0.9461235 Test Loss: 0.4157963
Validation loss decreased (0.946668 --> 0.946124).  Saving model ...
Updating learning rate to 0.00043980465111040037
	iters: 100, epoch: 18 | loss: 0.4103846
	speed: 0.1593s/iter; left time: 520.5186s
	iters: 200, epoch: 18 | loss: 0.4498501
	speed: 0.0343s/iter; left time: 108.5099s
Max Memory (MB): 34.62646484375
Epoch: 18 cost time: 9.86961317062378
Epoch: 18, Steps: 259 | Train Loss: 0.4036470 Vali Loss: 0.9496263 Test Loss: 0.4153198
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003518437208883203
	iters: 100, epoch: 19 | loss: 0.3594955
	speed: 0.2265s/iter; left time: 681.4088s
	iters: 200, epoch: 19 | loss: 0.4371487
	speed: 0.0428s/iter; left time: 124.3715s
Max Memory (MB): 34.62646484375
Epoch: 19 cost time: 12.14823031425476
Epoch: 19, Steps: 259 | Train Loss: 0.4032171 Vali Loss: 0.9483221 Test Loss: 0.4152767
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00028147497671065624
	iters: 100, epoch: 20 | loss: 0.4032332
	speed: 0.2013s/iter; left time: 553.4754s
	iters: 200, epoch: 20 | loss: 0.4063667
	speed: 0.0331s/iter; left time: 87.7721s
Max Memory (MB): 34.62646484375
Epoch: 20 cost time: 9.483466625213623
Epoch: 20, Steps: 259 | Train Loss: 0.4030491 Vali Loss: 0.9527492 Test Loss: 0.4150291
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00022517998136852504
	iters: 100, epoch: 21 | loss: 0.4219425
	speed: 0.1781s/iter; left time: 443.6932s
	iters: 200, epoch: 21 | loss: 0.4080183
	speed: 0.0468s/iter; left time: 112.0068s
Max Memory (MB): 34.62646484375
Epoch: 21 cost time: 12.35460090637207
Epoch: 21, Steps: 259 | Train Loss: 0.4029588 Vali Loss: 0.9443566 Test Loss: 0.4157289
Validation loss decreased (0.946124 --> 0.944357).  Saving model ...
Updating learning rate to 0.00018014398509482002
	iters: 100, epoch: 22 | loss: 0.3494530
	speed: 0.1953s/iter; left time: 435.8901s
	iters: 200, epoch: 22 | loss: 0.4012336
	speed: 0.0370s/iter; left time: 78.8665s
Max Memory (MB): 34.62646484375
Epoch: 22 cost time: 10.448922872543335
Epoch: 22, Steps: 259 | Train Loss: 0.4026565 Vali Loss: 0.9498171 Test Loss: 0.4138441
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00014411518807585602
	iters: 100, epoch: 23 | loss: 0.4177451
	speed: 0.1942s/iter; left time: 383.1818s
	iters: 200, epoch: 23 | loss: 0.4243219
	speed: 0.0421s/iter; left time: 78.7630s
Max Memory (MB): 34.62646484375
Epoch: 23 cost time: 11.234015464782715
Epoch: 23, Steps: 259 | Train Loss: 0.4024631 Vali Loss: 0.9461616 Test Loss: 0.4141656
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00011529215046068484
	iters: 100, epoch: 24 | loss: 0.4352999
	speed: 0.2254s/iter; left time: 386.3233s
	iters: 200, epoch: 24 | loss: 0.4122789
	speed: 0.0432s/iter; left time: 69.6993s
Max Memory (MB): 34.62646484375
Epoch: 24 cost time: 12.480002403259277
Epoch: 24, Steps: 259 | Train Loss: 0.4023151 Vali Loss: 0.9441051 Test Loss: 0.4144402
Validation loss decreased (0.944357 --> 0.944105).  Saving model ...
Updating learning rate to 9.223372036854788e-05
	iters: 100, epoch: 25 | loss: 0.3965611
	speed: 0.2586s/iter; left time: 376.3150s
	iters: 200, epoch: 25 | loss: 0.4470288
	speed: 0.0414s/iter; left time: 56.0640s
Max Memory (MB): 34.62646484375
Epoch: 25 cost time: 12.45576000213623
Epoch: 25, Steps: 259 | Train Loss: 0.4022238 Vali Loss: 0.9480804 Test Loss: 0.4148596
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.37869762948383e-05
	iters: 100, epoch: 26 | loss: 0.4408215
	speed: 0.2065s/iter; left time: 246.9434s
	iters: 200, epoch: 26 | loss: 0.4219384
	speed: 0.0480s/iter; left time: 52.5884s
Max Memory (MB): 34.62646484375
Epoch: 26 cost time: 12.439071416854858
Epoch: 26, Steps: 259 | Train Loss: 0.4020802 Vali Loss: 0.9469200 Test Loss: 0.4133808
EarlyStopping counter: 2 out of 5
Updating learning rate to 5.902958103587064e-05
	iters: 100, epoch: 27 | loss: 0.3983551
	speed: 0.2663s/iter; left time: 249.5452s
	iters: 200, epoch: 27 | loss: 0.4380020
	speed: 0.0584s/iter; left time: 48.8696s
Max Memory (MB): 34.62646484375
Epoch: 27 cost time: 16.238237142562866
Epoch: 27, Steps: 259 | Train Loss: 0.4020600 Vali Loss: 0.9444741 Test Loss: 0.4147428
EarlyStopping counter: 3 out of 5
Updating learning rate to 4.722366482869652e-05
	iters: 100, epoch: 28 | loss: 0.3949069
	speed: 0.3479s/iter; left time: 235.8829s
	iters: 200, epoch: 28 | loss: 0.4201430
	speed: 0.0609s/iter; left time: 35.2048s
Max Memory (MB): 34.62646484375
Epoch: 28 cost time: 16.025182723999023
Epoch: 28, Steps: 259 | Train Loss: 0.4019289 Vali Loss: 0.9439299 Test Loss: 0.4139118
Validation loss decreased (0.944105 --> 0.943930).  Saving model ...
Updating learning rate to 3.777893186295722e-05
	iters: 100, epoch: 29 | loss: 0.4426445
	speed: 0.3406s/iter; left time: 142.7269s
	iters: 200, epoch: 29 | loss: 0.4328604
	speed: 0.0575s/iter; left time: 18.3273s
Max Memory (MB): 34.62646484375
Epoch: 29 cost time: 16.19662308692932
Epoch: 29, Steps: 259 | Train Loss: 0.4018494 Vali Loss: 0.9478172 Test Loss: 0.4138345
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.0223145490365776e-05
	iters: 100, epoch: 30 | loss: 0.4308768
	speed: 0.3501s/iter; left time: 56.0200s
	iters: 200, epoch: 30 | loss: 0.3976698
	speed: 0.0442s/iter; left time: 2.6511s
Max Memory (MB): 34.62646484375
Epoch: 30 cost time: 14.266944169998169
Epoch: 30, Steps: 259 | Train Loss: 0.4018536 Vali Loss: 0.9450531 Test Loss: 0.4138897
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.417851639229262e-05
Final Max Memory (MB): 34.62646484375
>>>>>>>testing : ETTm1_720_720_LightTimeBaseTST_ETTm1_ftM_sl720_pl720_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.4131949245929718, mae:0.41441622376441956, rse:0.6115729212760925

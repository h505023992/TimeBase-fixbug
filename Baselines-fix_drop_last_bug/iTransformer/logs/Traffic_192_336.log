Args in experiment:
Namespace(is_training=1, model_id='traffic_192_336', model='iTransformer', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=336, enc_in=862, dec_in=862, c_out=862, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=2, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)
Use GPU: cuda:2
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
MACs: 804392960.0
Params: 927824.0
804.39M MACs
>>>>>>>start training : traffic_192_336_iTransformer_custom_M_ft192_sl48_ll336_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11753
val 1421
test 3173
	iters: 100, epoch: 1 | loss: 0.5023735
	speed: 0.1700s/iter; left time: 607.1714s
	iters: 200, epoch: 1 | loss: 0.4161965
	speed: 0.1456s/iter; left time: 505.5014s
	iters: 300, epoch: 1 | loss: 0.3829003
	speed: 0.1459s/iter; left time: 491.6778s
Max Memory (MB): 5222.10693359375
Epoch: 1 cost time: 55.69008994102478
Epoch: 1, Steps: 367 | Train Loss: 0.4823758 Vali Loss: 0.4606856 Test Loss: 0.5658036
Validation loss decreased (inf --> 0.460686).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3549173
	speed: 1.6914s/iter; left time: 5419.1048s
	iters: 200, epoch: 2 | loss: 0.3457797
	speed: 0.1447s/iter; left time: 449.2507s
	iters: 300, epoch: 2 | loss: 0.3252192
	speed: 0.1451s/iter; left time: 435.8696s
Max Memory (MB): 5222.10693359375
Epoch: 2 cost time: 57.157068967819214
Epoch: 2, Steps: 367 | Train Loss: 0.3378879 Vali Loss: 0.4111081 Test Loss: 0.5007490
Validation loss decreased (0.460686 --> 0.411108).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3156179
	speed: 1.8278s/iter; left time: 5185.5073s
	iters: 200, epoch: 3 | loss: 0.3238682
	speed: 0.1467s/iter; left time: 401.5768s
	iters: 300, epoch: 3 | loss: 0.3078847
	speed: 0.1463s/iter; left time: 385.8326s
Max Memory (MB): 5222.10693359375
Epoch: 3 cost time: 57.71324610710144
Epoch: 3, Steps: 367 | Train Loss: 0.3156413 Vali Loss: 0.4011859 Test Loss: 0.4871313
Validation loss decreased (0.411108 --> 0.401186).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3101480
	speed: 1.8953s/iter; left time: 4681.4641s
	iters: 200, epoch: 4 | loss: 0.3073205
	speed: 0.1671s/iter; left time: 396.0429s
	iters: 300, epoch: 4 | loss: 0.3078766
	speed: 0.1700s/iter; left time: 385.8297s
Max Memory (MB): 5222.10693359375
Epoch: 4 cost time: 65.57489395141602
Epoch: 4, Steps: 367 | Train Loss: 0.3093889 Vali Loss: 0.3981619 Test Loss: 0.4820965
Validation loss decreased (0.401186 --> 0.398162).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2936289
	speed: 1.8165s/iter; left time: 3820.1335s
	iters: 200, epoch: 5 | loss: 0.3078316
	speed: 0.1508s/iter; left time: 302.0092s
	iters: 300, epoch: 5 | loss: 0.3022196
	speed: 0.1605s/iter; left time: 305.4874s
Max Memory (MB): 5222.10693359375
Epoch: 5 cost time: 60.06222605705261
Epoch: 5, Steps: 367 | Train Loss: 0.3067749 Vali Loss: 0.3965891 Test Loss: 0.4799601
Validation loss decreased (0.398162 --> 0.396589).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3012373
	speed: 2.0838s/iter; left time: 3617.4765s
	iters: 200, epoch: 6 | loss: 0.2961229
	speed: 0.1606s/iter; left time: 262.7621s
	iters: 300, epoch: 6 | loss: 0.3094750
	speed: 0.1635s/iter; left time: 251.1691s
Max Memory (MB): 5222.10693359375
Epoch: 6 cost time: 63.13969850540161
Epoch: 6, Steps: 367 | Train Loss: 0.3055352 Vali Loss: 0.3961222 Test Loss: 0.4788778
Validation loss decreased (0.396589 --> 0.396122).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2946090
	speed: 1.8878s/iter; left time: 2584.4108s
	iters: 200, epoch: 7 | loss: 0.3189435
	speed: 0.1582s/iter; left time: 200.7840s
	iters: 300, epoch: 7 | loss: 0.2967319
	speed: 0.1599s/iter; left time: 186.8700s
Max Memory (MB): 5222.10693359375
Epoch: 7 cost time: 61.0036895275116
Epoch: 7, Steps: 367 | Train Loss: 0.3049019 Vali Loss: 0.3957780 Test Loss: 0.4782929
Validation loss decreased (0.396122 --> 0.395778).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3256491
	speed: 2.0467s/iter; left time: 2050.7818s
	iters: 200, epoch: 8 | loss: 0.2952234
	speed: 0.1580s/iter; left time: 142.4768s
	iters: 300, epoch: 8 | loss: 0.2929030
	speed: 0.1536s/iter; left time: 123.1686s
Max Memory (MB): 5222.10693359375
Epoch: 8 cost time: 61.940001487731934
Epoch: 8, Steps: 367 | Train Loss: 0.3045728 Vali Loss: 0.3952784 Test Loss: 0.4779802
Validation loss decreased (0.395778 --> 0.395278).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3165566
	speed: 1.4763s/iter; left time: 937.4307s
	iters: 200, epoch: 9 | loss: 0.3210390
	speed: 0.1489s/iter; left time: 79.6656s
	iters: 300, epoch: 9 | loss: 0.2894254
	speed: 0.1500s/iter; left time: 65.2470s
Max Memory (MB): 5222.10693359375
Epoch: 9 cost time: 58.03572368621826
Epoch: 9, Steps: 367 | Train Loss: 0.3044025 Vali Loss: 0.3954501 Test Loss: 0.4778232
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2902457
	speed: 2.1527s/iter; left time: 576.9305s
	iters: 200, epoch: 10 | loss: 0.3048117
	speed: 0.1549s/iter; left time: 26.0226s
	iters: 300, epoch: 10 | loss: 0.3088317
	speed: 0.1529s/iter; left time: 10.3983s
Max Memory (MB): 5222.10693359375
Epoch: 10 cost time: 60.74529194831848
Epoch: 10, Steps: 367 | Train Loss: 0.3043326 Vali Loss: 0.3953108 Test Loss: 0.4777723
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : traffic_192_336_iTransformer_custom_M_ft192_sl48_ll336_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
test shape: (3173, 1, 336, 862) (3173, 1, 336, 862)
test shape: (3173, 336, 862) (3173, 336, 862)
mse:0.47797590494155884, mae:0.3364798426628113

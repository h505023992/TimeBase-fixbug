Args in experiment:
Namespace(is_training=1, model_id='ETTh2_192_96', model='FITS', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=64, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_192_96_FITS_ETTh2_ftM_sl192_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=64, out_features=96, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5505024.0
params:  6240.0
Trainable parameters:  6240
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.3329052925109863
Epoch: 1, Steps: 65 | Train Loss: 0.4648296 Vali Loss: 0.3005063 Test Loss: 0.4088778
Validation loss decreased (inf --> 0.300506).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.2415199279785156
Epoch: 2, Steps: 65 | Train Loss: 0.3761845 Vali Loss: 0.2761455 Test Loss: 0.3734626
Validation loss decreased (0.300506 --> 0.276145).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.269925117492676
Epoch: 3, Steps: 65 | Train Loss: 0.3225529 Vali Loss: 0.2612273 Test Loss: 0.3534366
Validation loss decreased (0.276145 --> 0.261227).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.4277288913726807
Epoch: 4, Steps: 65 | Train Loss: 0.2895460 Vali Loss: 0.2531541 Test Loss: 0.3414542
Validation loss decreased (0.261227 --> 0.253154).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.2453794479370117
Epoch: 5, Steps: 65 | Train Loss: 0.2665037 Vali Loss: 0.2472057 Test Loss: 0.3336403
Validation loss decreased (0.253154 --> 0.247206).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 2.858384132385254
Epoch: 6, Steps: 65 | Train Loss: 0.2501103 Vali Loss: 0.2434873 Test Loss: 0.3283936
Validation loss decreased (0.247206 --> 0.243487).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.1915223598480225
Epoch: 7, Steps: 65 | Train Loss: 0.2369755 Vali Loss: 0.2398178 Test Loss: 0.3244689
Validation loss decreased (0.243487 --> 0.239818).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.2649803161621094
Epoch: 8, Steps: 65 | Train Loss: 0.2270473 Vali Loss: 0.2376091 Test Loss: 0.3212959
Validation loss decreased (0.239818 --> 0.237609).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 4.069222450256348
Epoch: 9, Steps: 65 | Train Loss: 0.2184479 Vali Loss: 0.2357832 Test Loss: 0.3187953
Validation loss decreased (0.237609 --> 0.235783).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.1049840450286865
Epoch: 10, Steps: 65 | Train Loss: 0.2116457 Vali Loss: 0.2344179 Test Loss: 0.3165331
Validation loss decreased (0.235783 --> 0.234418).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.0441031455993652
Epoch: 11, Steps: 65 | Train Loss: 0.2057976 Vali Loss: 0.2318642 Test Loss: 0.3146609
Validation loss decreased (0.234418 --> 0.231864).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.0666310787200928
Epoch: 12, Steps: 65 | Train Loss: 0.2004637 Vali Loss: 0.2303400 Test Loss: 0.3128377
Validation loss decreased (0.231864 --> 0.230340).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.026486396789551
Epoch: 13, Steps: 65 | Train Loss: 0.1953650 Vali Loss: 0.2295854 Test Loss: 0.3113596
Validation loss decreased (0.230340 --> 0.229585).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.5383107662200928
Epoch: 14, Steps: 65 | Train Loss: 0.1916057 Vali Loss: 0.2287360 Test Loss: 0.3099501
Validation loss decreased (0.229585 --> 0.228736).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.393148183822632
Epoch: 15, Steps: 65 | Train Loss: 0.1883043 Vali Loss: 0.2269416 Test Loss: 0.3086480
Validation loss decreased (0.228736 --> 0.226942).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.470710277557373
Epoch: 16, Steps: 65 | Train Loss: 0.1853330 Vali Loss: 0.2267388 Test Loss: 0.3074820
Validation loss decreased (0.226942 --> 0.226739).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.4470038414001465
Epoch: 17, Steps: 65 | Train Loss: 0.1825228 Vali Loss: 0.2263628 Test Loss: 0.3064353
Validation loss decreased (0.226739 --> 0.226363).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.4173431396484375
Epoch: 18, Steps: 65 | Train Loss: 0.1797423 Vali Loss: 0.2250910 Test Loss: 0.3054116
Validation loss decreased (0.226363 --> 0.225091).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.7959089279174805
Epoch: 19, Steps: 65 | Train Loss: 0.1777951 Vali Loss: 0.2242325 Test Loss: 0.3044612
Validation loss decreased (0.225091 --> 0.224232).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.972466468811035
Epoch: 20, Steps: 65 | Train Loss: 0.1758587 Vali Loss: 0.2237075 Test Loss: 0.3036220
Validation loss decreased (0.224232 --> 0.223708).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.0235605239868164
Epoch: 21, Steps: 65 | Train Loss: 0.1739041 Vali Loss: 0.2232029 Test Loss: 0.3028660
Validation loss decreased (0.223708 --> 0.223203).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 2.9106109142303467
Epoch: 22, Steps: 65 | Train Loss: 0.1718048 Vali Loss: 0.2216470 Test Loss: 0.3021182
Validation loss decreased (0.223203 --> 0.221647).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.1812174320220947
Epoch: 23, Steps: 65 | Train Loss: 0.1704160 Vali Loss: 0.2225036 Test Loss: 0.3014102
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.0486929416656494
Epoch: 24, Steps: 65 | Train Loss: 0.1692761 Vali Loss: 0.2206854 Test Loss: 0.3007725
Validation loss decreased (0.221647 --> 0.220685).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.9797184467315674
Epoch: 25, Steps: 65 | Train Loss: 0.1680686 Vali Loss: 0.2210229 Test Loss: 0.3002125
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.046121597290039
Epoch: 26, Steps: 65 | Train Loss: 0.1666296 Vali Loss: 0.2205864 Test Loss: 0.2996892
Validation loss decreased (0.220685 --> 0.220586).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 2.9539692401885986
Epoch: 27, Steps: 65 | Train Loss: 0.1656605 Vali Loss: 0.2194439 Test Loss: 0.2991666
Validation loss decreased (0.220586 --> 0.219444).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 4.223735570907593
Epoch: 28, Steps: 65 | Train Loss: 0.1650143 Vali Loss: 0.2186778 Test Loss: 0.2986706
Validation loss decreased (0.219444 --> 0.218678).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 4.184087038040161
Epoch: 29, Steps: 65 | Train Loss: 0.1639886 Vali Loss: 0.2193463 Test Loss: 0.2982449
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.7289016246795654
Epoch: 30, Steps: 65 | Train Loss: 0.1632543 Vali Loss: 0.2187303 Test Loss: 0.2978633
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00011296777049628277
train 8353
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=64, out_features=96, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  5505024.0
params:  6240.0
Trainable parameters:  6240
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.3246264457702637
Epoch: 1, Steps: 65 | Train Loss: 0.4176577 Vali Loss: 0.2121658 Test Loss: 0.2909751
Validation loss decreased (inf --> 0.212166).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.5092458724975586
Epoch: 2, Steps: 65 | Train Loss: 0.4080262 Vali Loss: 0.2084116 Test Loss: 0.2881712
Validation loss decreased (0.212166 --> 0.208412).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 2.9006266593933105
Epoch: 3, Steps: 65 | Train Loss: 0.4070490 Vali Loss: 0.2089488 Test Loss: 0.2872638
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.200347900390625
Epoch: 4, Steps: 65 | Train Loss: 0.4058467 Vali Loss: 0.2081134 Test Loss: 0.2869896
Validation loss decreased (0.208412 --> 0.208113).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.074338436126709
Epoch: 5, Steps: 65 | Train Loss: 0.4044503 Vali Loss: 0.2075140 Test Loss: 0.2867968
Validation loss decreased (0.208113 --> 0.207514).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.58516788482666
Epoch: 6, Steps: 65 | Train Loss: 0.4041978 Vali Loss: 0.2071247 Test Loss: 0.2865011
Validation loss decreased (0.207514 --> 0.207125).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.190136432647705
Epoch: 7, Steps: 65 | Train Loss: 0.4028913 Vali Loss: 0.2072584 Test Loss: 0.2861779
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.991732120513916
Epoch: 8, Steps: 65 | Train Loss: 0.4037847 Vali Loss: 0.2065393 Test Loss: 0.2861096
Validation loss decreased (0.207125 --> 0.206539).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.8288509845733643
Epoch: 9, Steps: 65 | Train Loss: 0.4028918 Vali Loss: 0.2075403 Test Loss: 0.2859634
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.6031455993652344
Epoch: 10, Steps: 65 | Train Loss: 0.4031217 Vali Loss: 0.2061698 Test Loss: 0.2858369
Validation loss decreased (0.206539 --> 0.206170).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.407320261001587
Epoch: 11, Steps: 65 | Train Loss: 0.4014059 Vali Loss: 0.2070944 Test Loss: 0.2856612
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.291154384613037
Epoch: 12, Steps: 65 | Train Loss: 0.4024814 Vali Loss: 0.2062600 Test Loss: 0.2855329
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.417099952697754
Epoch: 13, Steps: 65 | Train Loss: 0.4025250 Vali Loss: 0.2068580 Test Loss: 0.2855475
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.333664655685425
Epoch: 14, Steps: 65 | Train Loss: 0.4009770 Vali Loss: 0.2064267 Test Loss: 0.2854176
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 2.925445556640625
Epoch: 15, Steps: 65 | Train Loss: 0.4023113 Vali Loss: 0.2069395 Test Loss: 0.2853706
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTh2_192_96_FITS_ETTh2_ftM_sl192_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.2855956554412842, mae:0.34015092253685, rse:0.43068236112594604, corr:[0.2770078  0.27905184 0.2767857  0.27691603 0.27516955 0.27378264
 0.27316624 0.2718768  0.2706877  0.26961222 0.26839048 0.26654235
 0.26483288 0.263775   0.26274368 0.262187   0.26188982 0.2611229
 0.26008138 0.2588936  0.25725088 0.25631854 0.25521183 0.25267884
 0.2498377  0.24766605 0.24558975 0.2440844  0.2426807  0.24071185
 0.23962884 0.2383696  0.23605789 0.23460367 0.23343089 0.23124109
 0.2295228  0.22877155 0.22768335 0.22660984 0.22590052 0.2249966
 0.224247   0.22302914 0.22193772 0.22154665 0.22043286 0.21787494
 0.21533756 0.21330775 0.21157146 0.21017623 0.20825332 0.20624974
 0.20491943 0.20275593 0.20033087 0.19930677 0.1986054  0.1970394
 0.19630337 0.19583446 0.19644213 0.19665793 0.19523115 0.19440721
 0.19527403 0.19437464 0.19269067 0.19268584 0.19238256 0.19112936
 0.18933073 0.1880779  0.18753338 0.18657643 0.18490522 0.18480012
 0.1852894  0.18305814 0.18238682 0.18385638 0.18342355 0.18288225
 0.18348499 0.18288834 0.1832172  0.18504396 0.1842386  0.18320587
 0.18328954 0.18171412 0.18182273 0.18253396 0.18090487 0.1820313 ]

Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Autoformer_ETTm1_336_336', model='Autoformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Autoformer_ETTm1_336_336_Autoformer_ETTm1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3877805
	speed: 0.2452s/iter; left time: 7774.0991s
	iters: 200, epoch: 1 | loss: 0.3769607
	speed: 0.2116s/iter; left time: 6687.5626s
	iters: 300, epoch: 1 | loss: 0.4001842
	speed: 0.2152s/iter; left time: 6778.8262s
	iters: 400, epoch: 1 | loss: 0.3407463
	speed: 0.2068s/iter; left time: 6494.2167s
	iters: 500, epoch: 1 | loss: 0.3773316
	speed: 0.2052s/iter; left time: 6424.0476s
	iters: 600, epoch: 1 | loss: 0.3459660
	speed: 0.2035s/iter; left time: 6349.4313s
	iters: 700, epoch: 1 | loss: 0.3957845
	speed: 0.2027s/iter; left time: 6302.7542s
	iters: 800, epoch: 1 | loss: 0.2828502
	speed: 0.2058s/iter; left time: 6379.8182s
	iters: 900, epoch: 1 | loss: 0.2936631
	speed: 0.2144s/iter; left time: 6626.0673s
	iters: 1000, epoch: 1 | loss: 0.3103928
	speed: 0.2178s/iter; left time: 6707.1893s
Epoch: 1 cost time: 226.73476433753967
Epoch: 1, Steps: 1060 | Train Loss: 0.3659421 Vali Loss: 0.8649705 Test Loss: 0.5507702
Validation loss decreased (inf --> 0.864971).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3018249
	speed: 2.0678s/iter; left time: 63359.5601s
	iters: 200, epoch: 2 | loss: 0.3184347
	speed: 0.2145s/iter; left time: 6551.7836s
	iters: 300, epoch: 2 | loss: 0.2727414
	speed: 0.2173s/iter; left time: 6615.0453s
	iters: 400, epoch: 2 | loss: 0.2175734
	speed: 0.2188s/iter; left time: 6638.2664s
	iters: 500, epoch: 2 | loss: 0.2973050
	speed: 0.2267s/iter; left time: 6856.8527s
	iters: 600, epoch: 2 | loss: 0.2816784
	speed: 0.2230s/iter; left time: 6722.6591s
	iters: 700, epoch: 2 | loss: 0.2139715
	speed: 0.2241s/iter; left time: 6732.8805s
	iters: 800, epoch: 2 | loss: 0.2653579
	speed: 0.2284s/iter; left time: 6837.3547s
	iters: 900, epoch: 2 | loss: 0.2627608
	speed: 0.2287s/iter; left time: 6826.0678s
	iters: 1000, epoch: 2 | loss: 0.2486131
	speed: 0.2239s/iter; left time: 6660.2010s
Epoch: 2 cost time: 236.63016605377197
Epoch: 2, Steps: 1060 | Train Loss: 0.2652075 Vali Loss: 0.9172002 Test Loss: 0.5977854
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2095578
	speed: 1.8206s/iter; left time: 53854.8191s
	iters: 200, epoch: 3 | loss: 0.2058765
	speed: 0.2127s/iter; left time: 6271.6327s
	iters: 300, epoch: 3 | loss: 0.2252374
	speed: 0.2152s/iter; left time: 6322.2013s
	iters: 400, epoch: 3 | loss: 0.2341558
	speed: 0.2188s/iter; left time: 6405.2650s
	iters: 500, epoch: 3 | loss: 0.2256760
	speed: 0.2228s/iter; left time: 6501.2315s
	iters: 600, epoch: 3 | loss: 0.2061492
	speed: 0.2291s/iter; left time: 6663.0501s
	iters: 700, epoch: 3 | loss: 0.1942930
	speed: 0.2325s/iter; left time: 6738.5885s
	iters: 800, epoch: 3 | loss: 0.1984867
	speed: 0.2312s/iter; left time: 6677.8042s
	iters: 900, epoch: 3 | loss: 0.1969143
	speed: 0.2244s/iter; left time: 6458.4760s
	iters: 1000, epoch: 3 | loss: 0.2164052
	speed: 0.2265s/iter; left time: 6494.8892s
Epoch: 3 cost time: 236.5373179912567
Epoch: 3, Steps: 1060 | Train Loss: 0.2176048 Vali Loss: 0.9418740 Test Loss: 0.6224760
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1921614
	speed: 1.8474s/iter; left time: 52690.7981s
	iters: 200, epoch: 4 | loss: 0.1857624
	speed: 0.2112s/iter; left time: 6002.9228s
	iters: 300, epoch: 4 | loss: 0.1853964
	speed: 0.2132s/iter; left time: 6038.2803s
	iters: 400, epoch: 4 | loss: 0.2262075
	speed: 0.2159s/iter; left time: 6091.6927s
	iters: 500, epoch: 4 | loss: 0.2016176
	speed: 0.2210s/iter; left time: 6214.6499s
	iters: 600, epoch: 4 | loss: 0.2194872
	speed: 0.2208s/iter; left time: 6186.2557s
	iters: 700, epoch: 4 | loss: 0.1960799
	speed: 0.2252s/iter; left time: 6287.5620s
	iters: 800, epoch: 4 | loss: 0.1751763
	speed: 0.2244s/iter; left time: 6243.0576s
	iters: 900, epoch: 4 | loss: 0.1883013
	speed: 0.2193s/iter; left time: 6078.1732s
	iters: 1000, epoch: 4 | loss: 0.2123505
	speed: 0.2194s/iter; left time: 6060.8340s
Epoch: 4 cost time: 233.0317108631134
Epoch: 4, Steps: 1060 | Train Loss: 0.1968135 Vali Loss: 0.9535036 Test Loss: 0.5912718
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Autoformer_ETTm1_336_336_Autoformer_ETTm1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.5508759617805481, mae:0.5075877904891968

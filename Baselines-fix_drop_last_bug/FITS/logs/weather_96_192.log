Args in experiment:
Namespace(is_training=1, model_id='weather_96_192', model='FITS', data='custom', root_path='./dataset/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=21, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=3, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=22, base_T=144, H_order=12)
Use GPU: cuda:0
>>>>>>>start training : weather_96_192_FITS_custom_ftM_sl96_ll48_pl192_H12_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36600
val 5079
test 10348
Model(
  (freq_upsampler): Linear(in_features=22, out_features=66, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3902976.0
params:  1518.0
Trainable parameters:  1518
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7207112
	speed: 0.0969s/iter; left time: 818.9718s
	iters: 200, epoch: 1 | loss: 0.5493095
	speed: 0.0832s/iter; left time: 694.9143s
Epoch: 1 cost time: 26.028096437454224
Epoch: 1, Steps: 285 | Train Loss: 0.7202085 Vali Loss: 0.6971817 Test Loss: 0.2700482
Validation loss decreased (inf --> 0.697182).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4895956
	speed: 0.3448s/iter; left time: 2815.6014s
	iters: 200, epoch: 2 | loss: 0.4344087
	speed: 0.0841s/iter; left time: 678.6772s
Epoch: 2 cost time: 24.77367639541626
Epoch: 2, Steps: 285 | Train Loss: 0.5099473 Vali Loss: 0.6196940 Test Loss: 0.2499558
Validation loss decreased (0.697182 --> 0.619694).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4389779
	speed: 0.3059s/iter; left time: 2410.7892s
	iters: 200, epoch: 3 | loss: 0.3593708
	speed: 0.0745s/iter; left time: 579.7273s
Epoch: 3 cost time: 22.654741525650024
Epoch: 3, Steps: 285 | Train Loss: 0.4516717 Vali Loss: 0.5922853 Test Loss: 0.2447449
Validation loss decreased (0.619694 --> 0.592285).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4662163
	speed: 0.3302s/iter; left time: 2508.5063s
	iters: 200, epoch: 4 | loss: 0.6106862
	speed: 0.0870s/iter; left time: 651.9506s
Epoch: 4 cost time: 25.339860916137695
Epoch: 4, Steps: 285 | Train Loss: 0.4301791 Vali Loss: 0.5803188 Test Loss: 0.2424552
Validation loss decreased (0.592285 --> 0.580319).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4136581
	speed: 0.3310s/iter; left time: 2420.0883s
	iters: 200, epoch: 5 | loss: 0.4266487
	speed: 0.0784s/iter; left time: 565.1281s
Epoch: 5 cost time: 24.183340549468994
Epoch: 5, Steps: 285 | Train Loss: 0.4200284 Vali Loss: 0.5729256 Test Loss: 0.2414141
Validation loss decreased (0.580319 --> 0.572926).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4135825
	speed: 0.3412s/iter; left time: 2397.5506s
	iters: 200, epoch: 6 | loss: 0.4887191
	speed: 0.0828s/iter; left time: 573.2596s
Epoch: 6 cost time: 25.106812953948975
Epoch: 6, Steps: 285 | Train Loss: 0.4141626 Vali Loss: 0.5695687 Test Loss: 0.2409930
Validation loss decreased (0.572926 --> 0.569569).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3225473
	speed: 0.3326s/iter; left time: 2242.1457s
	iters: 200, epoch: 7 | loss: 0.3552374
	speed: 0.0866s/iter; left time: 575.1010s
Epoch: 7 cost time: 25.98058319091797
Epoch: 7, Steps: 285 | Train Loss: 0.4097110 Vali Loss: 0.5654764 Test Loss: 0.2409800
Validation loss decreased (0.569569 --> 0.565476).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4136393
	speed: 0.3200s/iter; left time: 2065.6026s
	iters: 200, epoch: 8 | loss: 0.4354481
	speed: 0.0730s/iter; left time: 464.2979s
Epoch: 8 cost time: 22.43219780921936
Epoch: 8, Steps: 285 | Train Loss: 0.4088776 Vali Loss: 0.5649163 Test Loss: 0.2409120
Validation loss decreased (0.565476 --> 0.564916).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4214560
	speed: 0.3321s/iter; left time: 2049.3136s
	iters: 200, epoch: 9 | loss: 0.5429398
	speed: 0.0829s/iter; left time: 503.5733s
Epoch: 9 cost time: 25.560818433761597
Epoch: 9, Steps: 285 | Train Loss: 0.4076033 Vali Loss: 0.5641942 Test Loss: 0.2410515
Validation loss decreased (0.564916 --> 0.564194).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3081320
	speed: 0.3349s/iter; left time: 1971.0310s
	iters: 200, epoch: 10 | loss: 0.4304155
	speed: 0.0901s/iter; left time: 521.5634s
Epoch: 10 cost time: 27.002651691436768
Epoch: 10, Steps: 285 | Train Loss: 0.4070761 Vali Loss: 0.5634218 Test Loss: 0.2413584
Validation loss decreased (0.564194 --> 0.563422).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3878976
	speed: 0.3446s/iter; left time: 1930.2692s
	iters: 200, epoch: 11 | loss: 0.4418513
	speed: 0.0768s/iter; left time: 422.4609s
Epoch: 11 cost time: 24.7805278301239
Epoch: 11, Steps: 285 | Train Loss: 0.4062883 Vali Loss: 0.5634770 Test Loss: 0.2413099
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3717408
	speed: 0.3438s/iter; left time: 1827.4052s
	iters: 200, epoch: 12 | loss: 0.3648666
	speed: 0.0840s/iter; left time: 438.3450s
Epoch: 12 cost time: 25.19621467590332
Epoch: 12, Steps: 285 | Train Loss: 0.4068503 Vali Loss: 0.5649874 Test Loss: 0.2413722
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3476964
	speed: 0.3411s/iter; left time: 1716.0772s
	iters: 200, epoch: 13 | loss: 0.3313103
	speed: 0.0899s/iter; left time: 443.1909s
Epoch: 13 cost time: 25.750016927719116
Epoch: 13, Steps: 285 | Train Loss: 0.4066718 Vali Loss: 0.5626554 Test Loss: 0.2414549
Validation loss decreased (0.563422 --> 0.562655).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3087410
	speed: 0.3359s/iter; left time: 1594.1991s
	iters: 200, epoch: 14 | loss: 0.6625909
	speed: 0.0866s/iter; left time: 402.4858s
Epoch: 14 cost time: 25.467025756835938
Epoch: 14, Steps: 285 | Train Loss: 0.4066509 Vali Loss: 0.5629730 Test Loss: 0.2416156
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.4788506
	speed: 0.3325s/iter; left time: 1483.2001s
	iters: 200, epoch: 15 | loss: 0.3744691
	speed: 0.0825s/iter; left time: 359.8823s
Epoch: 15 cost time: 24.55555248260498
Epoch: 15, Steps: 285 | Train Loss: 0.4062680 Vali Loss: 0.5627071 Test Loss: 0.2413894
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3915566
	speed: 0.3391s/iter; left time: 1415.9935s
	iters: 200, epoch: 16 | loss: 0.3423262
	speed: 0.0850s/iter; left time: 346.3991s
Epoch: 16 cost time: 25.480881690979004
Epoch: 16, Steps: 285 | Train Loss: 0.4066810 Vali Loss: 0.5627285 Test Loss: 0.2414250
EarlyStopping counter: 3 out of 3
Early stopping
train 36600
val 5079
test 10348
Model(
  (freq_upsampler): Linear(in_features=22, out_features=66, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  3902976.0
params:  1518.0
Trainable parameters:  1518
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.7138134
	speed: 0.0951s/iter; left time: 803.4153s
	iters: 200, epoch: 1 | loss: 0.7207151
	speed: 0.0906s/iter; left time: 756.9551s
Epoch: 1 cost time: 25.982856035232544
Epoch: 1, Steps: 285 | Train Loss: 0.5773860 Vali Loss: 0.5620258 Test Loss: 0.2412757
Validation loss decreased (inf --> 0.562026).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4123124
	speed: 0.3407s/iter; left time: 2782.5645s
	iters: 200, epoch: 2 | loss: 0.9825963
	speed: 0.0986s/iter; left time: 794.9809s
Epoch: 2 cost time: 26.75489902496338
Epoch: 2, Steps: 285 | Train Loss: 0.5763621 Vali Loss: 0.5618383 Test Loss: 0.2412926
Validation loss decreased (0.562026 --> 0.561838).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4915331
	speed: 0.3428s/iter; left time: 2701.2833s
	iters: 200, epoch: 3 | loss: 0.5887842
	speed: 0.0893s/iter; left time: 694.9162s
Epoch: 3 cost time: 26.503323793411255
Epoch: 3, Steps: 285 | Train Loss: 0.5761388 Vali Loss: 0.5612239 Test Loss: 0.2411054
Validation loss decreased (0.561838 --> 0.561224).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.5078235
	speed: 0.3309s/iter; left time: 2513.8012s
	iters: 200, epoch: 4 | loss: 1.0626345
	speed: 0.0872s/iter; left time: 653.6134s
Epoch: 4 cost time: 26.869200468063354
Epoch: 4, Steps: 285 | Train Loss: 0.5756648 Vali Loss: 0.5613738 Test Loss: 0.2409692
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4704661
	speed: 0.3367s/iter; left time: 2461.3983s
	iters: 200, epoch: 5 | loss: 0.7261866
	speed: 0.0704s/iter; left time: 507.5249s
Epoch: 5 cost time: 22.33670139312744
Epoch: 5, Steps: 285 | Train Loss: 0.5757778 Vali Loss: 0.5614734 Test Loss: 0.2406678
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.5813155
	speed: 0.3334s/iter; left time: 2342.6442s
	iters: 200, epoch: 6 | loss: 0.5887676
	speed: 0.0822s/iter; left time: 569.3326s
Epoch: 6 cost time: 24.47040843963623
Epoch: 6, Steps: 285 | Train Loss: 0.5749776 Vali Loss: 0.5585626 Test Loss: 0.2406535
Validation loss decreased (0.561224 --> 0.558563).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.4715247
	speed: 0.3254s/iter; left time: 2193.6683s
	iters: 200, epoch: 7 | loss: 0.5088835
	speed: 0.0741s/iter; left time: 492.3962s
Epoch: 7 cost time: 23.46265935897827
Epoch: 7, Steps: 285 | Train Loss: 0.5758534 Vali Loss: 0.5613338 Test Loss: 0.2408177
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.4812625
	speed: 0.3316s/iter; left time: 2140.6291s
	iters: 200, epoch: 8 | loss: 0.4906185
	speed: 0.0888s/iter; left time: 564.5975s
Epoch: 8 cost time: 24.69652271270752
Epoch: 8, Steps: 285 | Train Loss: 0.5757442 Vali Loss: 0.5602731 Test Loss: 0.2409773
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.7656149
	speed: 0.3196s/iter; left time: 1972.3990s
	iters: 200, epoch: 9 | loss: 0.5783737
	speed: 0.0789s/iter; left time: 479.2210s
Epoch: 9 cost time: 24.57074213027954
Epoch: 9, Steps: 285 | Train Loss: 0.5753397 Vali Loss: 0.5608552 Test Loss: 0.2407931
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : weather_96_192_FITS_custom_ftM_sl96_ll48_pl192_H12_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10348
mse:0.24093487858772278, mae:0.2718829810619354, rse:0.6461271643638611, corr:[0.48332685 0.48347044 0.48188677 0.48063836 0.47922862 0.477206
 0.47487825 0.4725187  0.46977058 0.46661055 0.46369016 0.46085584
 0.4576644  0.45430157 0.4507853  0.44723243 0.44359827 0.4396739
 0.43598711 0.4322673  0.4280133  0.42359018 0.41979155 0.41661322
 0.4136147  0.41068298 0.40854576 0.4070307  0.4059484  0.405509
 0.40610212 0.40742007 0.40882233 0.40997466 0.41150272 0.41318464
 0.4148093  0.41628364 0.41764846 0.41876206 0.41962737 0.42044196
 0.42137608 0.42234644 0.42292354 0.42315504 0.42328534 0.42363065
 0.4236436  0.42327914 0.42291743 0.4227731  0.4228931  0.42298284
 0.422891   0.42277125 0.42266974 0.42231902 0.42192072 0.42159727
 0.4215001  0.42163908 0.42156753 0.42127603 0.42086834 0.4205131
 0.42003903 0.4195156  0.41917706 0.4189297  0.41889206 0.41871318
 0.41852233 0.41835994 0.4181305  0.41787618 0.4176294  0.41729778
 0.41695625 0.41650853 0.41629016 0.4162411  0.41605192 0.41563383
 0.41509753 0.41461214 0.41450092 0.41425067 0.41398042 0.41368124
 0.41345465 0.41336244 0.41313773 0.41284034 0.4128738  0.41313747
 0.41329527 0.41315886 0.41310832 0.41315588 0.413292   0.4132957
 0.41326755 0.41334358 0.41350096 0.41352203 0.4132768  0.4131269
 0.41306305 0.4130725  0.4131546  0.41321906 0.41310677 0.41297004
 0.41285118 0.41265666 0.41248077 0.41234574 0.41220734 0.4119941
 0.41164944 0.41143608 0.41124588 0.41113424 0.41106212 0.41082355
 0.41057432 0.41029724 0.4100252  0.409663   0.40909514 0.40840793
 0.40775493 0.40712005 0.40670606 0.4063805  0.40605417 0.40565777
 0.4050545  0.40427372 0.40339923 0.40239444 0.40137115 0.40023163
 0.39895403 0.3974932  0.39592642 0.39406928 0.39210823 0.38998675
 0.38763908 0.384858   0.38195077 0.37902442 0.37589815 0.372201
 0.3682304  0.36429998 0.3604757  0.3563896  0.35217807 0.3480187
 0.34400135 0.34000435 0.33601013 0.3327853  0.3304899  0.3290604
 0.3278968  0.32658267 0.3259328  0.3267347  0.32846573 0.33160767
 0.33474433 0.3382299  0.34140238 0.3446288  0.34766668 0.35074732
 0.35403872 0.356562   0.35827604 0.3601301  0.36228374 0.36422402
 0.36546382 0.3668399  0.3688573  0.37097794 0.37196922 0.37198016]

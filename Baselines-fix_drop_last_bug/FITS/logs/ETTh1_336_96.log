Args in experiment:
Namespace(is_training=1, model_id='ETTh1_336_96', model='FITS', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=100, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_336_96_FITS_ETTh1_ftM_sl336_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=100, out_features=128, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11468800.0
params:  12928.0
Trainable parameters:  12928
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.805729866027832
Epoch: 1, Steps: 64 | Train Loss: 0.5955172 Vali Loss: 1.3706425 Test Loss: 0.7797159
Validation loss decreased (inf --> 1.370643).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.0754172801971436
Epoch: 2, Steps: 64 | Train Loss: 0.4685953 Vali Loss: 1.2403606 Test Loss: 0.7134078
Validation loss decreased (1.370643 --> 1.240361).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.1192336082458496
Epoch: 3, Steps: 64 | Train Loss: 0.4020830 Vali Loss: 1.1742742 Test Loss: 0.6809478
Validation loss decreased (1.240361 --> 1.174274).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.116436719894409
Epoch: 4, Steps: 64 | Train Loss: 0.3623376 Vali Loss: 1.1306269 Test Loss: 0.6594087
Validation loss decreased (1.174274 --> 1.130627).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.1493887901306152
Epoch: 5, Steps: 64 | Train Loss: 0.3344393 Vali Loss: 1.0945463 Test Loss: 0.6429140
Validation loss decreased (1.130627 --> 1.094546).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.287121057510376
Epoch: 6, Steps: 64 | Train Loss: 0.3126351 Vali Loss: 1.0654229 Test Loss: 0.6298339
Validation loss decreased (1.094546 --> 1.065423).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.432955265045166
Epoch: 7, Steps: 64 | Train Loss: 0.2945393 Vali Loss: 1.0428553 Test Loss: 0.6156995
Validation loss decreased (1.065423 --> 1.042855).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.5179150104522705
Epoch: 8, Steps: 64 | Train Loss: 0.2789297 Vali Loss: 1.0243263 Test Loss: 0.6044759
Validation loss decreased (1.042855 --> 1.024326).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.45576548576355
Epoch: 9, Steps: 64 | Train Loss: 0.2653861 Vali Loss: 1.0048572 Test Loss: 0.5929357
Validation loss decreased (1.024326 --> 1.004857).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 2.9361488819122314
Epoch: 10, Steps: 64 | Train Loss: 0.2532510 Vali Loss: 0.9853881 Test Loss: 0.5819325
Validation loss decreased (1.004857 --> 0.985388).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.287693977355957
Epoch: 11, Steps: 64 | Train Loss: 0.2426592 Vali Loss: 0.9715523 Test Loss: 0.5728176
Validation loss decreased (0.985388 --> 0.971552).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 2.9136006832122803
Epoch: 12, Steps: 64 | Train Loss: 0.2330813 Vali Loss: 0.9549301 Test Loss: 0.5644355
Validation loss decreased (0.971552 --> 0.954930).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.0430781841278076
Epoch: 13, Steps: 64 | Train Loss: 0.2244319 Vali Loss: 0.9450576 Test Loss: 0.5557918
Validation loss decreased (0.954930 --> 0.945058).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.025656223297119
Epoch: 14, Steps: 64 | Train Loss: 0.2168031 Vali Loss: 0.9308950 Test Loss: 0.5481509
Validation loss decreased (0.945058 --> 0.930895).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.030785322189331
Epoch: 15, Steps: 64 | Train Loss: 0.2098186 Vali Loss: 0.9145774 Test Loss: 0.5401677
Validation loss decreased (0.930895 --> 0.914577).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.782932758331299
Epoch: 16, Steps: 64 | Train Loss: 0.2034938 Vali Loss: 0.9042932 Test Loss: 0.5321078
Validation loss decreased (0.914577 --> 0.904293).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.7653841972351074
Epoch: 17, Steps: 64 | Train Loss: 0.1977753 Vali Loss: 0.8981320 Test Loss: 0.5274475
Validation loss decreased (0.904293 --> 0.898132).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.550218105316162
Epoch: 18, Steps: 64 | Train Loss: 0.1924884 Vali Loss: 0.8888715 Test Loss: 0.5209194
Validation loss decreased (0.898132 --> 0.888871).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.6136786937713623
Epoch: 19, Steps: 64 | Train Loss: 0.1877144 Vali Loss: 0.8817477 Test Loss: 0.5150276
Validation loss decreased (0.888871 --> 0.881748).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.9225728511810303
Epoch: 20, Steps: 64 | Train Loss: 0.1834012 Vali Loss: 0.8752455 Test Loss: 0.5111347
Validation loss decreased (0.881748 --> 0.875246).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.3907315731048584
Epoch: 21, Steps: 64 | Train Loss: 0.1793485 Vali Loss: 0.8673301 Test Loss: 0.5055993
Validation loss decreased (0.875246 --> 0.867330).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.1846847534179688
Epoch: 22, Steps: 64 | Train Loss: 0.1756805 Vali Loss: 0.8601423 Test Loss: 0.5012591
Validation loss decreased (0.867330 --> 0.860142).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.086634397506714
Epoch: 23, Steps: 64 | Train Loss: 0.1723173 Vali Loss: 0.8511351 Test Loss: 0.4972607
Validation loss decreased (0.860142 --> 0.851135).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.1331353187561035
Epoch: 24, Steps: 64 | Train Loss: 0.1691874 Vali Loss: 0.8455846 Test Loss: 0.4933708
Validation loss decreased (0.851135 --> 0.845585).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 2.886866569519043
Epoch: 25, Steps: 64 | Train Loss: 0.1662439 Vali Loss: 0.8470806 Test Loss: 0.4898219
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.4796388149261475
Epoch: 26, Steps: 64 | Train Loss: 0.1635938 Vali Loss: 0.8402376 Test Loss: 0.4862930
Validation loss decreased (0.845585 --> 0.840238).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.627619981765747
Epoch: 27, Steps: 64 | Train Loss: 0.1611490 Vali Loss: 0.8359269 Test Loss: 0.4831888
Validation loss decreased (0.840238 --> 0.835927).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 3.584123134613037
Epoch: 28, Steps: 64 | Train Loss: 0.1588345 Vali Loss: 0.8301950 Test Loss: 0.4805405
Validation loss decreased (0.835927 --> 0.830195).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.408940553665161
Epoch: 29, Steps: 64 | Train Loss: 0.1566553 Vali Loss: 0.8282264 Test Loss: 0.4773893
Validation loss decreased (0.830195 --> 0.828226).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 2.805981397628784
Epoch: 30, Steps: 64 | Train Loss: 0.1546454 Vali Loss: 0.8216901 Test Loss: 0.4748699
Validation loss decreased (0.828226 --> 0.821690).  Saving model ...
Updating learning rate to 0.00011296777049628277
train 8209
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=100, out_features=128, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  11468800.0
params:  12928.0
Trainable parameters:  12928
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.3728461265563965
Epoch: 1, Steps: 64 | Train Loss: 0.3751928 Vali Loss: 0.7130779 Test Loss: 0.3990833
Validation loss decreased (inf --> 0.713078).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 3.043698787689209
Epoch: 2, Steps: 64 | Train Loss: 0.3476438 Vali Loss: 0.6882672 Test Loss: 0.3804443
Validation loss decreased (0.713078 --> 0.688267).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.5331342220306396
Epoch: 3, Steps: 64 | Train Loss: 0.3411791 Vali Loss: 0.6810767 Test Loss: 0.3769360
Validation loss decreased (0.688267 --> 0.681077).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.438889741897583
Epoch: 4, Steps: 64 | Train Loss: 0.3393411 Vali Loss: 0.6742290 Test Loss: 0.3768533
Validation loss decreased (0.681077 --> 0.674229).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.602851152420044
Epoch: 5, Steps: 64 | Train Loss: 0.3387878 Vali Loss: 0.6776277 Test Loss: 0.3761646
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.091723442077637
Epoch: 6, Steps: 64 | Train Loss: 0.3383233 Vali Loss: 0.6785382 Test Loss: 0.3758744
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 4.024474382400513
Epoch: 7, Steps: 64 | Train Loss: 0.3382155 Vali Loss: 0.6750835 Test Loss: 0.3759786
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.8129353523254395
Epoch: 8, Steps: 64 | Train Loss: 0.3380211 Vali Loss: 0.6758264 Test Loss: 0.3760859
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.506193161010742
Epoch: 9, Steps: 64 | Train Loss: 0.3378648 Vali Loss: 0.6754948 Test Loss: 0.3757066
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTh1_336_96_FITS_ETTh1_ftM_sl336_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3757632374763489, mae:0.3968430161476135, rse:0.5822573900222778, corr:[0.27459484 0.27875882 0.27764195 0.27891287 0.27657944 0.27364907
 0.2735696  0.27378115 0.27263576 0.2722897  0.27315143 0.27321118
 0.272361   0.27185282 0.2720393  0.27234775 0.27216527 0.27179438
 0.27152705 0.27121058 0.27067685 0.27037367 0.2704331  0.27067497
 0.2701779  0.26994553 0.27021855 0.2699469  0.26918855 0.26897508
 0.2690333  0.2686328  0.26805285 0.26799464 0.26835734 0.26826862
 0.26803103 0.26820633 0.26837447 0.26820132 0.26839438 0.26871642
 0.26901743 0.26907626 0.26883662 0.26846033 0.26861668 0.26897886
 0.268691   0.26781246 0.2669384  0.2662193  0.26513246 0.26399973
 0.263156   0.2625021  0.2620914  0.26213625 0.26217377 0.2618408
 0.26166603 0.26184922 0.26190728 0.26181963 0.26209238 0.26245686
 0.2630015  0.2628685  0.26261976 0.26265246 0.26285827 0.26269236
 0.26227072 0.26125428 0.2599057  0.25930524 0.2592805  0.25878918
 0.25814602 0.25752193 0.25679442 0.25613374 0.2557002  0.2555813
 0.2554182  0.25518948 0.2550752  0.25487787 0.25482723 0.2547731
 0.25432184 0.2542137  0.25370288 0.2522199  0.25288513 0.25497028]

Args in experiment:
Namespace(is_training=1, model_id='ETTh1_96_720', model='iTransformer', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=8, e_layers=2, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=2, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)
Use GPU: cuda:2
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
MACs: 3947008.0
Params: 304720.0
3.95M MACs
>>>>>>>start training : ETTh1_96_720_iTransformer_ETTh1_M_ft96_sl48_ll720_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6897000
	speed: 0.0380s/iter; left time: 89.0678s
	iters: 200, epoch: 1 | loss: 0.6537427
	speed: 0.0259s/iter; left time: 58.1134s
Max Memory (MB): 16.318359375
Epoch: 1 cost time: 7.5366370677948
Epoch: 1, Steps: 244 | Train Loss: 0.7209591 Vali Loss: 1.6335262 Test Loss: 0.5504164
Validation loss decreased (inf --> 1.633526).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6120706
	speed: 0.1956s/iter; left time: 410.2416s
	iters: 200, epoch: 2 | loss: 0.6206538
	speed: 0.0267s/iter; left time: 53.3869s
Max Memory (MB): 16.318359375
Epoch: 2 cost time: 6.7814576625823975
Epoch: 2, Steps: 244 | Train Loss: 0.6409117 Vali Loss: 1.5712973 Test Loss: 0.5266052
Validation loss decreased (1.633526 --> 1.571297).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6170052
	speed: 0.1966s/iter; left time: 364.3878s
	iters: 200, epoch: 3 | loss: 0.5637309
	speed: 0.0256s/iter; left time: 44.9407s
Max Memory (MB): 16.318359375
Epoch: 3 cost time: 6.998153924942017
Epoch: 3, Steps: 244 | Train Loss: 0.6214524 Vali Loss: 1.5584407 Test Loss: 0.5194474
Validation loss decreased (1.571297 --> 1.558441).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6887643
	speed: 0.1987s/iter; left time: 319.7732s
	iters: 200, epoch: 4 | loss: 0.6628333
	speed: 0.0275s/iter; left time: 41.4316s
Max Memory (MB): 16.318359375
Epoch: 4 cost time: 7.251284599304199
Epoch: 4, Steps: 244 | Train Loss: 0.6139786 Vali Loss: 1.5532099 Test Loss: 0.5192809
Validation loss decreased (1.558441 --> 1.553210).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6217854
	speed: 0.2147s/iter; left time: 293.0769s
	iters: 200, epoch: 5 | loss: 0.6610736
	speed: 0.0305s/iter; left time: 38.6354s
Max Memory (MB): 16.318359375
Epoch: 5 cost time: 7.940961599349976
Epoch: 5, Steps: 244 | Train Loss: 0.6106830 Vali Loss: 1.5520146 Test Loss: 0.5164917
Validation loss decreased (1.553210 --> 1.552015).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5758268
	speed: 0.2199s/iter; left time: 246.5138s
	iters: 200, epoch: 6 | loss: 0.6872764
	speed: 0.0360s/iter; left time: 36.7413s
Max Memory (MB): 16.318359375
Epoch: 6 cost time: 8.723711967468262
Epoch: 6, Steps: 244 | Train Loss: 0.6092309 Vali Loss: 1.5528352 Test Loss: 0.5166408
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6146650
	speed: 0.2452s/iter; left time: 215.0789s
	iters: 200, epoch: 7 | loss: 0.5640029
	speed: 0.0315s/iter; left time: 24.5002s
Max Memory (MB): 16.318359375
Epoch: 7 cost time: 8.230136394500732
Epoch: 7, Steps: 244 | Train Loss: 0.6090464 Vali Loss: 1.5551293 Test Loss: 0.5169768
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6836420
	speed: 0.2199s/iter; left time: 139.2239s
	iters: 200, epoch: 8 | loss: 0.5764641
	speed: 0.0270s/iter; left time: 14.4153s
Max Memory (MB): 16.318359375
Epoch: 8 cost time: 7.082618713378906
Epoch: 8, Steps: 244 | Train Loss: 0.6081539 Vali Loss: 1.5563552 Test Loss: 0.5170446
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_96_720_iTransformer_ETTh1_M_ft96_sl48_ll720_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 1, 720, 7) (2161, 1, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.5164912343025208, mae:0.5005464553833008

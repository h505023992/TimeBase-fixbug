Args in experiment:
Namespace(is_training=1, model_id='ETTm1_96_192', model='FITS', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=40, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_96_192_FITS_ETTm1_ftM_sl96_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=40, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4300800.0
params:  4920.0
Trainable parameters:  4920
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5567394
	speed: 0.0666s/iter; left time: 526.5893s
	iters: 200, epoch: 1 | loss: 0.4400598
	speed: 0.0555s/iter; left time: 433.4628s
Epoch: 1 cost time: 16.153438806533813
Epoch: 1, Steps: 267 | Train Loss: 0.5255257 Vali Loss: 0.8824043 Test Loss: 0.7150525
Validation loss decreased (inf --> 0.882404).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3690341
	speed: 0.2475s/iter; left time: 1891.6502s
	iters: 200, epoch: 2 | loss: 0.3403574
	speed: 0.0673s/iter; left time: 507.7972s
Epoch: 2 cost time: 17.78468632698059
Epoch: 2, Steps: 267 | Train Loss: 0.3588319 Vali Loss: 0.7654809 Test Loss: 0.6044142
Validation loss decreased (0.882404 --> 0.765481).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3686970
	speed: 0.2983s/iter; left time: 2200.7026s
	iters: 200, epoch: 3 | loss: 0.2727971
	speed: 0.0626s/iter; left time: 455.8856s
Epoch: 3 cost time: 17.253916263580322
Epoch: 3, Steps: 267 | Train Loss: 0.3172302 Vali Loss: 0.6993271 Test Loss: 0.5411924
Validation loss decreased (0.765481 --> 0.699327).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2823493
	speed: 0.2429s/iter; left time: 1726.8940s
	iters: 200, epoch: 4 | loss: 0.2804612
	speed: 0.0517s/iter; left time: 362.4159s
Epoch: 4 cost time: 14.648493766784668
Epoch: 4, Steps: 267 | Train Loss: 0.2927309 Vali Loss: 0.6521604 Test Loss: 0.4960437
Validation loss decreased (0.699327 --> 0.652160).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2861699
	speed: 0.2498s/iter; left time: 1709.5463s
	iters: 200, epoch: 5 | loss: 0.2964835
	speed: 0.0603s/iter; left time: 406.3122s
Epoch: 5 cost time: 16.505571842193604
Epoch: 5, Steps: 267 | Train Loss: 0.2764331 Vali Loss: 0.6187065 Test Loss: 0.4638931
Validation loss decreased (0.652160 --> 0.618707).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2477320
	speed: 0.2815s/iter; left time: 1850.9298s
	iters: 200, epoch: 6 | loss: 0.2527481
	speed: 0.0608s/iter; left time: 393.7295s
Epoch: 6 cost time: 17.45021414756775
Epoch: 6, Steps: 267 | Train Loss: 0.2654869 Vali Loss: 0.5938084 Test Loss: 0.4404821
Validation loss decreased (0.618707 --> 0.593808).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2471498
	speed: 0.2791s/iter; left time: 1760.7257s
	iters: 200, epoch: 7 | loss: 0.2520863
	speed: 0.0480s/iter; left time: 298.2431s
Epoch: 7 cost time: 14.80051875114441
Epoch: 7, Steps: 267 | Train Loss: 0.2584167 Vali Loss: 0.5776867 Test Loss: 0.4249808
Validation loss decreased (0.593808 --> 0.577687).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2452220
	speed: 0.2585s/iter; left time: 1561.7743s
	iters: 200, epoch: 8 | loss: 0.2894548
	speed: 0.0556s/iter; left time: 330.6263s
Epoch: 8 cost time: 15.211340427398682
Epoch: 8, Steps: 267 | Train Loss: 0.2540128 Vali Loss: 0.5652101 Test Loss: 0.4139180
Validation loss decreased (0.577687 --> 0.565210).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2549285
	speed: 0.2605s/iter; left time: 1504.5928s
	iters: 200, epoch: 9 | loss: 0.2426316
	speed: 0.0655s/iter; left time: 371.4901s
Epoch: 9 cost time: 18.308146953582764
Epoch: 9, Steps: 267 | Train Loss: 0.2511181 Vali Loss: 0.5568919 Test Loss: 0.4064668
Validation loss decreased (0.565210 --> 0.556892).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2684426
	speed: 0.2958s/iter; left time: 1629.3502s
	iters: 200, epoch: 10 | loss: 0.2452007
	speed: 0.0683s/iter; left time: 369.3347s
Epoch: 10 cost time: 18.022520065307617
Epoch: 10, Steps: 267 | Train Loss: 0.2494414 Vali Loss: 0.5515632 Test Loss: 0.4012346
Validation loss decreased (0.556892 --> 0.551563).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2348677
	speed: 0.2569s/iter; left time: 1346.4007s
	iters: 200, epoch: 11 | loss: 0.2734903
	speed: 0.0556s/iter; left time: 285.9658s
Epoch: 11 cost time: 15.478908777236938
Epoch: 11, Steps: 267 | Train Loss: 0.2484932 Vali Loss: 0.5478420 Test Loss: 0.3978640
Validation loss decreased (0.551563 --> 0.547842).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2748070
	speed: 0.2404s/iter; left time: 1195.7107s
	iters: 200, epoch: 12 | loss: 0.2442924
	speed: 0.0565s/iter; left time: 275.6137s
Epoch: 12 cost time: 14.496190547943115
Epoch: 12, Steps: 267 | Train Loss: 0.2480703 Vali Loss: 0.5437059 Test Loss: 0.3955372
Validation loss decreased (0.547842 --> 0.543706).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2412918
	speed: 0.2734s/iter; left time: 1286.8417s
	iters: 200, epoch: 13 | loss: 0.2418303
	speed: 0.0664s/iter; left time: 305.9484s
Epoch: 13 cost time: 18.813931703567505
Epoch: 13, Steps: 267 | Train Loss: 0.2478234 Vali Loss: 0.5422952 Test Loss: 0.3936279
Validation loss decreased (0.543706 --> 0.542295).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2366750
	speed: 0.2862s/iter; left time: 1270.9047s
	iters: 200, epoch: 14 | loss: 0.2483620
	speed: 0.0512s/iter; left time: 222.3623s
Epoch: 14 cost time: 14.383335590362549
Epoch: 14, Steps: 267 | Train Loss: 0.2477560 Vali Loss: 0.5403414 Test Loss: 0.3927749
Validation loss decreased (0.542295 --> 0.540341).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2371232
	speed: 0.2381s/iter; left time: 993.6530s
	iters: 200, epoch: 15 | loss: 0.2361805
	speed: 0.0522s/iter; left time: 212.5206s
Epoch: 15 cost time: 14.085832834243774
Epoch: 15, Steps: 267 | Train Loss: 0.2476403 Vali Loss: 0.5406210 Test Loss: 0.3920985
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2616365
	speed: 0.2089s/iter; left time: 815.8719s
	iters: 200, epoch: 16 | loss: 0.2430552
	speed: 0.0453s/iter; left time: 172.4532s
Epoch: 16 cost time: 12.03699803352356
Epoch: 16, Steps: 267 | Train Loss: 0.2475663 Vali Loss: 0.5396803 Test Loss: 0.3915523
Validation loss decreased (0.540341 --> 0.539680).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2421749
	speed: 0.2435s/iter; left time: 886.0185s
	iters: 200, epoch: 17 | loss: 0.2399309
	speed: 0.0518s/iter; left time: 183.4904s
Epoch: 17 cost time: 15.513848781585693
Epoch: 17, Steps: 267 | Train Loss: 0.2476285 Vali Loss: 0.5400417 Test Loss: 0.3913960
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2566799
	speed: 0.2490s/iter; left time: 839.6411s
	iters: 200, epoch: 18 | loss: 0.2573425
	speed: 0.0429s/iter; left time: 140.4240s
Epoch: 18 cost time: 13.295067548751831
Epoch: 18, Steps: 267 | Train Loss: 0.2476215 Vali Loss: 0.5397635 Test Loss: 0.3914759
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2431150
	speed: 0.1923s/iter; left time: 597.1041s
	iters: 200, epoch: 19 | loss: 0.2277013
	speed: 0.0445s/iter; left time: 133.5793s
Epoch: 19 cost time: 13.068052768707275
Epoch: 19, Steps: 267 | Train Loss: 0.2475523 Vali Loss: 0.5388309 Test Loss: 0.3912080
Validation loss decreased (0.539680 --> 0.538831).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2553537
	speed: 0.2081s/iter; left time: 590.6684s
	iters: 200, epoch: 20 | loss: 0.2429957
	speed: 0.0529s/iter; left time: 144.7515s
Epoch: 20 cost time: 13.544824361801147
Epoch: 20, Steps: 267 | Train Loss: 0.2474855 Vali Loss: 0.5395533 Test Loss: 0.3913836
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2262904
	speed: 0.2675s/iter; left time: 687.8595s
	iters: 200, epoch: 21 | loss: 0.2556585
	speed: 0.0572s/iter; left time: 141.3579s
Epoch: 21 cost time: 15.9769287109375
Epoch: 21, Steps: 267 | Train Loss: 0.2476208 Vali Loss: 0.5395606 Test Loss: 0.3914545
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2444016
	speed: 0.2698s/iter; left time: 621.6372s
	iters: 200, epoch: 22 | loss: 0.2610058
	speed: 0.0572s/iter; left time: 126.0966s
Epoch: 22 cost time: 16.100587129592896
Epoch: 22, Steps: 267 | Train Loss: 0.2475152 Vali Loss: 0.5390264 Test Loss: 0.3912870
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2601099
	speed: 0.2847s/iter; left time: 579.9073s
	iters: 200, epoch: 23 | loss: 0.2672234
	speed: 0.0544s/iter; left time: 105.2984s
Epoch: 23 cost time: 16.17803120613098
Epoch: 23, Steps: 267 | Train Loss: 0.2474707 Vali Loss: 0.5395756 Test Loss: 0.3912612
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2502235
	speed: 0.2724s/iter; left time: 482.1052s
	iters: 200, epoch: 24 | loss: 0.2655391
	speed: 0.0595s/iter; left time: 99.4106s
Epoch: 24 cost time: 16.586394548416138
Epoch: 24, Steps: 267 | Train Loss: 0.2476266 Vali Loss: 0.5393681 Test Loss: 0.3911972
EarlyStopping counter: 5 out of 5
Early stopping
train 34273
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=40, out_features=120, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  4300800.0
params:  4920.0
Trainable parameters:  4920
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3725153
	speed: 0.0641s/iter; left time: 506.9210s
	iters: 200, epoch: 1 | loss: 0.3665736
	speed: 0.0503s/iter; left time: 392.9476s
Epoch: 1 cost time: 15.172669172286987
Epoch: 1, Steps: 267 | Train Loss: 0.3689793 Vali Loss: 0.5395224 Test Loss: 0.3912729
Validation loss decreased (inf --> 0.539522).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3819329
	speed: 0.2740s/iter; left time: 2094.6683s
	iters: 200, epoch: 2 | loss: 0.3419297
	speed: 0.0706s/iter; left time: 532.4784s
Epoch: 2 cost time: 18.287656784057617
Epoch: 2, Steps: 267 | Train Loss: 0.3691211 Vali Loss: 0.5387928 Test Loss: 0.3908553
Validation loss decreased (0.539522 --> 0.538793).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3845465
	speed: 0.2894s/iter; left time: 2135.1753s
	iters: 200, epoch: 3 | loss: 0.3672482
	speed: 0.0588s/iter; left time: 428.1049s
Epoch: 3 cost time: 17.25891661643982
Epoch: 3, Steps: 267 | Train Loss: 0.3688203 Vali Loss: 0.5394469 Test Loss: 0.3916882
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3828523
	speed: 0.2453s/iter; left time: 1744.4349s
	iters: 200, epoch: 4 | loss: 0.3763717
	speed: 0.0496s/iter; left time: 347.4029s
Epoch: 4 cost time: 15.188008546829224
Epoch: 4, Steps: 267 | Train Loss: 0.3687328 Vali Loss: 0.5387449 Test Loss: 0.3914282
Validation loss decreased (0.538793 --> 0.538745).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3627884
	speed: 0.2456s/iter; left time: 1680.5835s
	iters: 200, epoch: 5 | loss: 0.3614362
	speed: 0.0647s/iter; left time: 436.5300s
Epoch: 5 cost time: 16.18214702606201
Epoch: 5, Steps: 267 | Train Loss: 0.3686983 Vali Loss: 0.5387315 Test Loss: 0.3911030
Validation loss decreased (0.538745 --> 0.538732).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3797044
	speed: 0.3079s/iter; left time: 2024.7054s
	iters: 200, epoch: 6 | loss: 0.3693314
	speed: 0.0723s/iter; left time: 468.5082s
Epoch: 6 cost time: 19.288275718688965
Epoch: 6, Steps: 267 | Train Loss: 0.3688098 Vali Loss: 0.5396079 Test Loss: 0.3911737
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3878491
	speed: 0.2550s/iter; left time: 1608.7960s
	iters: 200, epoch: 7 | loss: 0.4012149
	speed: 0.0612s/iter; left time: 380.1556s
Epoch: 7 cost time: 15.858105421066284
Epoch: 7, Steps: 267 | Train Loss: 0.3688232 Vali Loss: 0.5378653 Test Loss: 0.3907768
Validation loss decreased (0.538732 --> 0.537865).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3438212
	speed: 0.2531s/iter; left time: 1529.0509s
	iters: 200, epoch: 8 | loss: 0.3235606
	speed: 0.0604s/iter; left time: 359.1773s
Epoch: 8 cost time: 17.32722520828247
Epoch: 8, Steps: 267 | Train Loss: 0.3686771 Vali Loss: 0.5390911 Test Loss: 0.3915384
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3916881
	speed: 0.2677s/iter; left time: 1546.1511s
	iters: 200, epoch: 9 | loss: 0.4155461
	speed: 0.0619s/iter; left time: 351.4776s
Epoch: 9 cost time: 17.025365829467773
Epoch: 9, Steps: 267 | Train Loss: 0.3686951 Vali Loss: 0.5392452 Test Loss: 0.3911862
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3708339
	speed: 0.2885s/iter; left time: 1589.2083s
	iters: 200, epoch: 10 | loss: 0.3589258
	speed: 0.0631s/iter; left time: 341.0050s
Epoch: 10 cost time: 18.624749183654785
Epoch: 10, Steps: 267 | Train Loss: 0.3685521 Vali Loss: 0.5394544 Test Loss: 0.3913180
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3739240
	speed: 0.2697s/iter; left time: 1413.6738s
	iters: 200, epoch: 11 | loss: 0.3726695
	speed: 0.0576s/iter; left time: 296.0691s
Epoch: 11 cost time: 15.909745931625366
Epoch: 11, Steps: 267 | Train Loss: 0.3686451 Vali Loss: 0.5391672 Test Loss: 0.3912149
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3924748
	speed: 0.2632s/iter; left time: 1309.3624s
	iters: 200, epoch: 12 | loss: 0.3659322
	speed: 0.0579s/iter; left time: 282.3162s
Epoch: 12 cost time: 15.560601234436035
Epoch: 12, Steps: 267 | Train Loss: 0.3686793 Vali Loss: 0.5387735 Test Loss: 0.3911924
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm1_96_192_FITS_ETTm1_ftM_sl96_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.39162197709083557, mae:0.3928954601287842, rse:0.5957102179527283, corr:[0.5513302  0.54884523 0.5486487  0.54605204 0.5442379  0.5433242
 0.5409656  0.5406326  0.5383764  0.53717285 0.5355728  0.5336743
 0.5323371  0.52980924 0.526917   0.5242545  0.5210439  0.5181455
 0.51570415 0.51269966 0.5103524  0.5080547  0.50521696 0.5019558
 0.49859872 0.49545085 0.4920765  0.48936653 0.48756793 0.48600164
 0.48494017 0.4840437  0.48379424 0.48442137 0.4844834  0.4849071
 0.48449358 0.48364422 0.4836753  0.48297325 0.48280966 0.48310575
 0.48301128 0.48324335 0.48318774 0.48297182 0.4828103  0.48286468
 0.48329407 0.48385733 0.4843396  0.48402435 0.48410887 0.4844339
 0.4847872  0.48518565 0.4856021  0.4858609  0.48565483 0.4853547
 0.4852429  0.48449278 0.4842525  0.4836037  0.4826193  0.48261404
 0.48264477 0.48337755 0.48483318 0.48541206 0.48577228 0.48706114
 0.48861873 0.48937383 0.4901525  0.49119335 0.49185732 0.49197778
 0.49253777 0.49334505 0.49381176 0.4941894  0.4952542  0.49634734
 0.49680895 0.49743927 0.49839872 0.49925232 0.50045544 0.50178987
 0.5028911  0.5039379  0.5049363  0.505549   0.5057226  0.50588894
 0.50554866 0.5046304  0.50351554 0.5018851  0.4996481  0.49854288
 0.49790505 0.49670532 0.4952697  0.4940001  0.49282864 0.49140978
 0.49008948 0.4887696  0.4878433  0.48696166 0.48595923 0.48528257
 0.48402172 0.4828087  0.48200217 0.4810151  0.48005283 0.478661
 0.4774335  0.47688374 0.47571462 0.47437844 0.47358575 0.47307405
 0.473104   0.47282103 0.47233057 0.4721841  0.47192064 0.4722243
 0.47234973 0.4718987  0.47147623 0.47154945 0.47126994 0.4709778
 0.47117302 0.4711972  0.4715697  0.4715083  0.4708687  0.4711405
 0.47136116 0.47154203 0.47212785 0.4719996  0.47224855 0.47283396
 0.47250792 0.47236523 0.4726428  0.47276026 0.47323513 0.4732842
 0.47265756 0.47284588 0.47249073 0.47189912 0.47257867 0.472523
 0.47266063 0.4736136  0.47383928 0.47464836 0.47608066 0.47669473
 0.47743368 0.47898015 0.47966158 0.48044595 0.4815198  0.48194864
 0.48258898 0.48371142 0.48459932 0.4856113  0.4870824  0.48866448
 0.4897426  0.49018425 0.49161613 0.49354866 0.49430603 0.4961917
 0.4975419  0.49988025 0.5019275  0.50408024 0.5057674  0.5070176 ]

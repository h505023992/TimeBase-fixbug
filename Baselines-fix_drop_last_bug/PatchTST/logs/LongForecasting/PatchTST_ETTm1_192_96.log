Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='192_96', model='PatchTST', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=96, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:1
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 68984832.0
Params: 694624.0
68.98M MACs
>>>>>>>start training : 192_96_PatchTST_ETTm1_ftM_sl192_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4703571
	speed: 0.1272s/iter; left time: 1010.3597s
	iters: 200, epoch: 1 | loss: 0.3995908
	speed: 0.1303s/iter; left time: 1021.5580s
Epoch: 1 cost time: 33.89823508262634
Epoch: 1, Steps: 268 | Train Loss: 0.4615995 Vali Loss: 0.4927918 Test Loss: 0.3992806
Validation loss decreased (inf --> 0.492792).  Saving model ...
Updating learning rate to 5.6365721298040346e-06
	iters: 100, epoch: 2 | loss: 0.3492717
	speed: 0.5449s/iter; left time: 4181.0042s
	iters: 200, epoch: 2 | loss: 0.3596385
	speed: 0.1197s/iter; left time: 906.1707s
Epoch: 2 cost time: 33.56164622306824
Epoch: 2, Steps: 268 | Train Loss: 0.3497388 Vali Loss: 0.4161388 Test Loss: 0.3302027
Validation loss decreased (0.492792 --> 0.416139).  Saving model ...
Updating learning rate to 1.043468983854729e-05
	iters: 100, epoch: 3 | loss: 0.2759306
	speed: 0.4755s/iter; left time: 3521.3331s
	iters: 200, epoch: 3 | loss: 0.3359452
	speed: 0.1022s/iter; left time: 746.6710s
Epoch: 3 cost time: 29.003422498703003
Epoch: 3, Steps: 268 | Train Loss: 0.3139509 Vali Loss: 0.3963024 Test Loss: 0.3131066
Validation loss decreased (0.416139 --> 0.396302).  Saving model ...
Updating learning rate to 1.806716705466112e-05
	iters: 100, epoch: 4 | loss: 0.3023734
	speed: 0.5287s/iter; left time: 3773.2652s
	iters: 200, epoch: 4 | loss: 0.2987685
	speed: 0.1101s/iter; left time: 774.5850s
Epoch: 4 cost time: 30.9518563747406
Epoch: 4, Steps: 268 | Train Loss: 0.2979379 Vali Loss: 0.3924400 Test Loss: 0.3061163
Validation loss decreased (0.396302 --> 0.392440).  Saving model ...
Updating learning rate to 2.8013541299259828e-05
	iters: 100, epoch: 5 | loss: 0.2717271
	speed: 0.4840s/iter; left time: 3324.5314s
	iters: 200, epoch: 5 | loss: 0.2483270
	speed: 0.1094s/iter; left time: 740.6072s
Epoch: 5 cost time: 31.111002445220947
Epoch: 5, Steps: 268 | Train Loss: 0.2864657 Vali Loss: 0.3878581 Test Loss: 0.3005025
Validation loss decreased (0.392440 --> 0.387858).  Saving model ...
Updating learning rate to 3.9595564285622165e-05
	iters: 100, epoch: 6 | loss: 0.2977283
	speed: 0.5107s/iter; left time: 3370.9991s
	iters: 200, epoch: 6 | loss: 0.2740901
	speed: 0.1214s/iter; left time: 788.8976s
Epoch: 6 cost time: 32.06007242202759
Epoch: 6, Steps: 268 | Train Loss: 0.2778191 Vali Loss: 0.3787447 Test Loss: 0.2974878
Validation loss decreased (0.387858 --> 0.378745).  Saving model ...
Updating learning rate to 5.202345201265517e-05
	iters: 100, epoch: 7 | loss: 0.2549675
	speed: 0.4936s/iter; left time: 3125.7344s
	iters: 200, epoch: 7 | loss: 0.2722711
	speed: 0.1100s/iter; left time: 685.6319s
Epoch: 7 cost time: 32.4671413898468
Epoch: 7, Steps: 268 | Train Loss: 0.2720619 Vali Loss: 0.3721147 Test Loss: 0.2975634
Validation loss decreased (0.378745 --> 0.372115).  Saving model ...
Updating learning rate to 6.444974053509239e-05
	iters: 100, epoch: 8 | loss: 0.2680447
	speed: 0.5369s/iter; left time: 3256.0559s
	iters: 200, epoch: 8 | loss: 0.2830874
	speed: 0.1132s/iter; left time: 675.1174s
Epoch: 8 cost time: 32.0142023563385
Epoch: 8, Steps: 268 | Train Loss: 0.2673339 Vali Loss: 0.3657766 Test Loss: 0.2940099
Validation loss decreased (0.372115 --> 0.365777).  Saving model ...
Updating learning rate to 7.602707495823693e-05
	iters: 100, epoch: 9 | loss: 0.2440580
	speed: 0.5035s/iter; left time: 2918.9209s
	iters: 200, epoch: 9 | loss: 0.2692826
	speed: 0.1229s/iter; left time: 700.4280s
Epoch: 9 cost time: 32.94274950027466
Epoch: 9, Steps: 268 | Train Loss: 0.2630372 Vali Loss: 0.3702825 Test Loss: 0.2948936
EarlyStopping counter: 1 out of 5
Updating learning rate to 8.596599099649138e-05
	iters: 100, epoch: 10 | loss: 0.2144670
	speed: 0.5181s/iter; left time: 2864.8294s
	iters: 200, epoch: 10 | loss: 0.2395169
	speed: 0.1061s/iter; left time: 576.2467s
Epoch: 10 cost time: 30.955054759979248
Epoch: 10, Steps: 268 | Train Loss: 0.2596228 Vali Loss: 0.3705450 Test Loss: 0.2937844
EarlyStopping counter: 2 out of 5
Updating learning rate to 9.35887489419945e-05
	iters: 100, epoch: 11 | loss: 0.2583156
	speed: 0.4939s/iter; left time: 2598.3282s
	iters: 200, epoch: 11 | loss: 0.2722344
	speed: 0.1234s/iter; left time: 637.1181s
Epoch: 11 cost time: 32.24998641014099
Epoch: 11, Steps: 268 | Train Loss: 0.2561409 Vali Loss: 0.3688214 Test Loss: 0.2925528
EarlyStopping counter: 3 out of 5
Updating learning rate to 9.837554907783572e-05
	iters: 100, epoch: 12 | loss: 0.2351563
	speed: 0.4774s/iter; left time: 2383.4228s
	iters: 200, epoch: 12 | loss: 0.2671794
	speed: 0.1097s/iter; left time: 536.6525s
Epoch: 12 cost time: 30.733420610427856
Epoch: 12, Steps: 268 | Train Loss: 0.2529305 Vali Loss: 0.3706333 Test Loss: 0.2916490
EarlyStopping counter: 4 out of 5
Updating learning rate to 9.999998939713082e-05
	iters: 100, epoch: 13 | loss: 0.2301483
	speed: 0.5140s/iter; left time: 2428.6811s
	iters: 200, epoch: 13 | loss: 0.2412259
	speed: 0.1159s/iter; left time: 536.0838s
Epoch: 13 cost time: 33.04043364524841
Epoch: 13, Steps: 268 | Train Loss: 0.2494942 Vali Loss: 0.3712993 Test Loss: 0.2912689
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : 192_96_PatchTST_ETTm1_ftM_sl192_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.2961054742336273, mae:0.34165340662002563, rse:0.517791748046875

Args in experiment:
Namespace(is_training=1, train_only=False, model_id='DLinear_ETTh2_96_720', model='DLinear', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DLinear_ETTh2_96_720_DLinear_ETTh2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 1.1022772
	speed: 0.0454s/iter; left time: 329.1875s
	iters: 200, epoch: 1 | loss: 1.1017423
	speed: 0.0278s/iter; left time: 199.1168s
Epoch: 1 cost time: 8.587616920471191
Epoch: 1, Steps: 245 | Train Loss: 0.8998376 Vali Loss: 0.7617660 Test Loss: 0.9597997
Validation loss decreased (inf --> 0.761766).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8124111
	speed: 0.1429s/iter; left time: 1001.3124s
	iters: 200, epoch: 2 | loss: 0.6277454
	speed: 0.0277s/iter; left time: 191.3915s
Epoch: 2 cost time: 7.493017911911011
Epoch: 2, Steps: 245 | Train Loss: 0.7631585 Vali Loss: 0.7300988 Test Loss: 0.8998047
Validation loss decreased (0.761766 --> 0.730099).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5711202
	speed: 0.1139s/iter; left time: 770.3183s
	iters: 200, epoch: 3 | loss: 0.5824599
	speed: 0.0230s/iter; left time: 152.9573s
Epoch: 3 cost time: 6.164784908294678
Epoch: 3, Steps: 245 | Train Loss: 0.7480450 Vali Loss: 0.7192284 Test Loss: 0.8762929
Validation loss decreased (0.730099 --> 0.719228).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9653309
	speed: 0.1130s/iter; left time: 736.2830s
	iters: 200, epoch: 4 | loss: 0.5857008
	speed: 0.0233s/iter; left time: 149.6040s
Epoch: 4 cost time: 6.327305793762207
Epoch: 4, Steps: 245 | Train Loss: 0.7429377 Vali Loss: 0.7174047 Test Loss: 0.8825114
Validation loss decreased (0.719228 --> 0.717405).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6273909
	speed: 0.1015s/iter; left time: 636.5292s
	iters: 200, epoch: 5 | loss: 1.2658304
	speed: 0.0206s/iter; left time: 127.0917s
Epoch: 5 cost time: 5.676820755004883
Epoch: 5, Steps: 245 | Train Loss: 0.7411310 Vali Loss: 0.7141358 Test Loss: 0.8683665
Validation loss decreased (0.717405 --> 0.714136).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 1.0322562
	speed: 0.1095s/iter; left time: 659.7624s
	iters: 200, epoch: 6 | loss: 0.5434423
	speed: 0.0241s/iter; left time: 142.6445s
Epoch: 6 cost time: 6.7994384765625
Epoch: 6, Steps: 245 | Train Loss: 0.7404943 Vali Loss: 0.7122844 Test Loss: 0.8629593
Validation loss decreased (0.714136 --> 0.712284).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7310358
	speed: 0.1307s/iter; left time: 755.8626s
	iters: 200, epoch: 7 | loss: 0.7840851
	speed: 0.0213s/iter; left time: 120.9560s
Epoch: 7 cost time: 6.782870769500732
Epoch: 7, Steps: 245 | Train Loss: 0.7391289 Vali Loss: 0.7117031 Test Loss: 0.8636824
Validation loss decreased (0.712284 --> 0.711703).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9212521
	speed: 0.1213s/iter; left time: 671.5778s
	iters: 200, epoch: 8 | loss: 0.8236688
	speed: 0.0253s/iter; left time: 137.4706s
Epoch: 8 cost time: 6.799237966537476
Epoch: 8, Steps: 245 | Train Loss: 0.7399919 Vali Loss: 0.7123345 Test Loss: 0.8627140
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6780472
	speed: 0.1303s/iter; left time: 689.1851s
	iters: 200, epoch: 9 | loss: 0.8133790
	speed: 0.0249s/iter; left time: 129.1104s
Epoch: 9 cost time: 6.890864610671997
Epoch: 9, Steps: 245 | Train Loss: 0.7399157 Vali Loss: 0.7116627 Test Loss: 0.8627883
Validation loss decreased (0.711703 --> 0.711663).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6824253
	speed: 0.1254s/iter; left time: 632.5829s
	iters: 200, epoch: 10 | loss: 0.7174336
	speed: 0.0262s/iter; left time: 129.6165s
Epoch: 10 cost time: 7.0273637771606445
Epoch: 10, Steps: 245 | Train Loss: 0.7390041 Vali Loss: 0.7115855 Test Loss: 0.8626437
Validation loss decreased (0.711663 --> 0.711586).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6533879
	speed: 0.1323s/iter; left time: 635.1907s
	iters: 200, epoch: 11 | loss: 0.5726210
	speed: 0.0314s/iter; left time: 147.8021s
Epoch: 11 cost time: 8.12333083152771
Epoch: 11, Steps: 245 | Train Loss: 0.7386808 Vali Loss: 0.7127209 Test Loss: 0.8624789
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.4624118
	speed: 0.1243s/iter; left time: 566.2251s
	iters: 200, epoch: 12 | loss: 1.0863783
	speed: 0.0294s/iter; left time: 131.0521s
Epoch: 12 cost time: 7.141083717346191
Epoch: 12, Steps: 245 | Train Loss: 0.7385492 Vali Loss: 0.7120667 Test Loss: 0.8624482
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.7041086
	speed: 0.1297s/iter; left time: 559.0470s
	iters: 200, epoch: 13 | loss: 0.5984669
	speed: 0.0221s/iter; left time: 93.0791s
Epoch: 13 cost time: 6.271453619003296
Epoch: 13, Steps: 245 | Train Loss: 0.7384921 Vali Loss: 0.7125083 Test Loss: 0.8624199
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : DLinear_ETTh2_96_720_DLinear_ETTh2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
mse:0.8615837693214417, mae:0.6705979108810425

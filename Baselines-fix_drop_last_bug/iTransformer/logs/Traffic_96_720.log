Args in experiment:
Namespace(is_training=1, model_id='traffic_96_720', model='iTransformer', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, enc_in=862, dec_in=862, c_out=862, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=2, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)
Use GPU: cuda:2
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
MACs: 868388864.0
Params: 1001936.0
868.39M MACs
>>>>>>>start training : traffic_96_720_iTransformer_custom_M_ft96_sl48_ll720_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11465
val 1037
test 2789
	iters: 100, epoch: 1 | loss: 0.5882907
	speed: 0.2141s/iter; left time: 745.1240s
	iters: 200, epoch: 1 | loss: 0.4942842
	speed: 0.1864s/iter; left time: 630.2512s
	iters: 300, epoch: 1 | loss: 0.4582814
	speed: 0.1841s/iter; left time: 604.1747s
Max Memory (MB): 5363.97216796875
Epoch: 1 cost time: 69.02724075317383
Epoch: 1, Steps: 358 | Train Loss: 0.5733740 Vali Loss: 0.6018559 Test Loss: 0.7187093
Validation loss decreased (inf --> 0.601856).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4471373
	speed: 1.7919s/iter; left time: 5595.9911s
	iters: 200, epoch: 2 | loss: 0.4150743
	speed: 0.1926s/iter; left time: 582.2270s
	iters: 300, epoch: 2 | loss: 0.4137204
	speed: 0.1938s/iter; left time: 566.6204s
Max Memory (MB): 5363.97216796875
Epoch: 2 cost time: 72.71298861503601
Epoch: 2, Steps: 358 | Train Loss: 0.4263954 Vali Loss: 0.5358698 Test Loss: 0.6295632
Validation loss decreased (0.601856 --> 0.535870).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3857011
	speed: 2.0523s/iter; left time: 5674.6674s
	iters: 200, epoch: 3 | loss: 0.4032405
	speed: 0.1930s/iter; left time: 514.2672s
	iters: 300, epoch: 3 | loss: 0.3922495
	speed: 0.1957s/iter; left time: 502.0500s
Max Memory (MB): 5363.97216796875
Epoch: 3 cost time: 74.29452872276306
Epoch: 3, Steps: 358 | Train Loss: 0.3932624 Vali Loss: 0.5179448 Test Loss: 0.6020586
Validation loss decreased (0.535870 --> 0.517945).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3841750
	speed: 2.0590s/iter; left time: 4956.0920s
	iters: 200, epoch: 4 | loss: 0.3657771
	speed: 0.2021s/iter; left time: 466.2272s
	iters: 300, epoch: 4 | loss: 0.3832082
	speed: 0.2008s/iter; left time: 443.1327s
Max Memory (MB): 5363.97216796875
Epoch: 4 cost time: 76.00532579421997
Epoch: 4, Steps: 358 | Train Loss: 0.3816530 Vali Loss: 0.5101363 Test Loss: 0.5902999
Validation loss decreased (0.517945 --> 0.510136).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3795976
	speed: 1.9889s/iter; left time: 4075.2332s
	iters: 200, epoch: 5 | loss: 0.3750476
	speed: 0.1857s/iter; left time: 361.9886s
	iters: 300, epoch: 5 | loss: 0.3733430
	speed: 0.1902s/iter; left time: 351.6770s
Max Memory (MB): 5363.97216796875
Epoch: 5 cost time: 71.60090661048889
Epoch: 5, Steps: 358 | Train Loss: 0.3767480 Vali Loss: 0.5074922 Test Loss: 0.5855128
Validation loss decreased (0.510136 --> 0.507492).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3862610
	speed: 2.0145s/iter; left time: 3406.4745s
	iters: 200, epoch: 6 | loss: 0.3852628
	speed: 0.2063s/iter; left time: 328.1603s
	iters: 300, epoch: 6 | loss: 0.3656202
	speed: 0.2007s/iter; left time: 299.3043s
Max Memory (MB): 5363.97216796875
Epoch: 6 cost time: 79.53517031669617
Epoch: 6, Steps: 358 | Train Loss: 0.3744261 Vali Loss: 0.5063893 Test Loss: 0.5834124
Validation loss decreased (0.507492 --> 0.506389).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3703238
	speed: 1.9453s/iter; left time: 2593.1240s
	iters: 200, epoch: 7 | loss: 0.3837827
	speed: 0.1877s/iter; left time: 231.4660s
	iters: 300, epoch: 7 | loss: 0.3746805
	speed: 0.1913s/iter; left time: 216.7522s
Max Memory (MB): 5363.97216796875
Epoch: 7 cost time: 74.35497522354126
Epoch: 7, Steps: 358 | Train Loss: 0.3732858 Vali Loss: 0.5056783 Test Loss: 0.5821475
Validation loss decreased (0.506389 --> 0.505678).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3797221
	speed: 2.1076s/iter; left time: 2054.8770s
	iters: 200, epoch: 8 | loss: 0.3568628
	speed: 0.2040s/iter; left time: 178.5186s
	iters: 300, epoch: 8 | loss: 0.3667634
	speed: 0.2030s/iter; left time: 157.3332s
Max Memory (MB): 5363.97216796875
Epoch: 8 cost time: 78.76894927024841
Epoch: 8, Steps: 358 | Train Loss: 0.3727411 Vali Loss: 0.5051753 Test Loss: 0.5815781
Validation loss decreased (0.505678 --> 0.505175).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3777111
	speed: 2.0919s/iter; left time: 1290.6861s
	iters: 200, epoch: 9 | loss: 0.3665470
	speed: 0.1880s/iter; left time: 97.1748s
	iters: 300, epoch: 9 | loss: 0.3817619
	speed: 0.1865s/iter; left time: 77.7511s
Max Memory (MB): 5363.97216796875
Epoch: 9 cost time: 73.77056050300598
Epoch: 9, Steps: 358 | Train Loss: 0.3724609 Vali Loss: 0.5050473 Test Loss: 0.5812699
Validation loss decreased (0.505175 --> 0.505047).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3659028
	speed: 2.0188s/iter; left time: 522.8705s
	iters: 200, epoch: 10 | loss: 0.3555826
	speed: 0.2001s/iter; left time: 31.8236s
	iters: 300, epoch: 10 | loss: 0.3712573
	speed: 0.2037s/iter; left time: 12.0192s
Max Memory (MB): 5363.97216796875
Epoch: 10 cost time: 79.20175957679749
Epoch: 10, Steps: 358 | Train Loss: 0.3723063 Vali Loss: 0.5046448 Test Loss: 0.5811441
Validation loss decreased (0.505047 --> 0.504645).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : traffic_96_720_iTransformer_custom_M_ft96_sl48_ll720_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2789
test shape: (2789, 1, 720, 862) (2789, 1, 720, 862)
test shape: (2789, 720, 862) (2789, 720, 862)
mse:0.5811421871185303, mae:0.38605478405952454

Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Autoformer_ETTm2_96_192', model='Autoformer', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Autoformer_ETTm2_96_192_Autoformer_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3255063
	speed: 0.1188s/iter; left time: 3808.8752s
	iters: 200, epoch: 1 | loss: 0.8389977
	speed: 0.0965s/iter; left time: 3084.9235s
	iters: 300, epoch: 1 | loss: 0.9416377
	speed: 0.0992s/iter; left time: 3160.1906s
	iters: 400, epoch: 1 | loss: 0.6393225
	speed: 0.1011s/iter; left time: 3212.5881s
	iters: 500, epoch: 1 | loss: 0.3844225
	speed: 0.1026s/iter; left time: 3248.4564s
	iters: 600, epoch: 1 | loss: 0.4375359
	speed: 0.0990s/iter; left time: 3123.3902s
	iters: 700, epoch: 1 | loss: 0.2291577
	speed: 0.0987s/iter; left time: 3105.6754s
	iters: 800, epoch: 1 | loss: 0.3343471
	speed: 0.1009s/iter; left time: 3164.0135s
	iters: 900, epoch: 1 | loss: 0.2516141
	speed: 0.0927s/iter; left time: 2896.7318s
	iters: 1000, epoch: 1 | loss: 0.2903651
	speed: 0.0972s/iter; left time: 3028.9760s
Epoch: 1 cost time: 107.66118574142456
Epoch: 1, Steps: 1072 | Train Loss: 0.3681393 Vali Loss: 0.1900928 Test Loss: 0.2733160
Validation loss decreased (inf --> 0.190093).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2170329
	speed: 0.6695s/iter; left time: 20748.3570s
	iters: 200, epoch: 2 | loss: 0.2082792
	speed: 0.0960s/iter; left time: 2966.8424s
	iters: 300, epoch: 2 | loss: 0.2324614
	speed: 0.0988s/iter; left time: 3040.9105s
	iters: 400, epoch: 2 | loss: 0.6107664
	speed: 0.0949s/iter; left time: 2913.2349s
	iters: 500, epoch: 2 | loss: 0.2030161
	speed: 0.0947s/iter; left time: 2896.5999s
	iters: 600, epoch: 2 | loss: 0.2532037
	speed: 0.0989s/iter; left time: 3014.3018s
	iters: 700, epoch: 2 | loss: 0.3080880
	speed: 0.0950s/iter; left time: 2887.8620s
	iters: 800, epoch: 2 | loss: 0.2579330
	speed: 0.0976s/iter; left time: 2957.5188s
	iters: 900, epoch: 2 | loss: 0.2461368
	speed: 0.0964s/iter; left time: 2909.4696s
	iters: 1000, epoch: 2 | loss: 0.2663918
	speed: 0.0959s/iter; left time: 2884.0442s
Epoch: 2 cost time: 104.53456807136536
Epoch: 2, Steps: 1072 | Train Loss: 0.3498735 Vali Loss: 0.1952143 Test Loss: 0.2866916
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4949426
	speed: 0.7231s/iter; left time: 21632.5263s
	iters: 200, epoch: 3 | loss: 0.2028675
	speed: 0.0975s/iter; left time: 2908.1950s
	iters: 300, epoch: 3 | loss: 0.6155132
	speed: 0.0977s/iter; left time: 2903.6945s
	iters: 400, epoch: 3 | loss: 0.3373894
	speed: 0.0942s/iter; left time: 2788.9152s
	iters: 500, epoch: 3 | loss: 0.3239739
	speed: 0.0960s/iter; left time: 2833.3790s
	iters: 600, epoch: 3 | loss: 0.2150029
	speed: 0.0973s/iter; left time: 2861.9386s
	iters: 700, epoch: 3 | loss: 0.5047290
	speed: 0.0965s/iter; left time: 2830.4027s
	iters: 800, epoch: 3 | loss: 0.2536474
	speed: 0.0964s/iter; left time: 2815.9664s
	iters: 900, epoch: 3 | loss: 0.1416802
	speed: 0.0966s/iter; left time: 2812.0057s
	iters: 1000, epoch: 3 | loss: 0.2276981
	speed: 0.0946s/iter; left time: 2746.3464s
Epoch: 3 cost time: 104.59671640396118
Epoch: 3, Steps: 1072 | Train Loss: 0.3291611 Vali Loss: 0.2010326 Test Loss: 0.2949884
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2244891
	speed: 0.7096s/iter; left time: 20467.5927s
	iters: 200, epoch: 4 | loss: 0.5814178
	speed: 0.0991s/iter; left time: 2849.2140s
	iters: 300, epoch: 4 | loss: 0.2035460
	speed: 0.0977s/iter; left time: 2797.7065s
	iters: 400, epoch: 4 | loss: 0.3806981
	speed: 0.0996s/iter; left time: 2842.7197s
	iters: 500, epoch: 4 | loss: 0.2342986
	speed: 0.0974s/iter; left time: 2769.4570s
	iters: 600, epoch: 4 | loss: 0.2933668
	speed: 0.0985s/iter; left time: 2792.9067s
	iters: 700, epoch: 4 | loss: 0.2444398
	speed: 0.1002s/iter; left time: 2829.8854s
	iters: 800, epoch: 4 | loss: 0.3721214
	speed: 0.1029s/iter; left time: 2895.9070s
	iters: 900, epoch: 4 | loss: 0.2308472
	speed: 0.1046s/iter; left time: 2933.6788s
	iters: 1000, epoch: 4 | loss: 0.2140158
	speed: 0.1012s/iter; left time: 2828.4031s
Epoch: 4 cost time: 108.70406818389893
Epoch: 4, Steps: 1072 | Train Loss: 0.3108099 Vali Loss: 0.2070825 Test Loss: 0.3404287
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Autoformer_ETTm2_96_192_Autoformer_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.2737712860107422, mae:0.33185890316963196

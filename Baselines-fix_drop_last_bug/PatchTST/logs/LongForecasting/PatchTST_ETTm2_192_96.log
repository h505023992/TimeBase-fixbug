Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='192_96', model='PatchTST', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=96, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:1
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 68984832.0
Params: 694624.0
68.98M MACs
>>>>>>>start training : 192_96_PatchTST_ETTm2_ftM_sl192_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.3292966
	speed: 0.1146s/iter; left time: 910.0970s
	iters: 200, epoch: 1 | loss: 0.3928364
	speed: 0.1059s/iter; left time: 829.9795s
Epoch: 1 cost time: 29.87328863143921
Epoch: 1, Steps: 268 | Train Loss: 0.3365222 Vali Loss: 0.1500906 Test Loss: 0.2074472
Validation loss decreased (inf --> 0.150091).  Saving model ...
Updating learning rate to 5.6365721298040346e-06
	iters: 100, epoch: 2 | loss: 0.2726034
	speed: 0.4501s/iter; left time: 3453.8532s
	iters: 200, epoch: 2 | loss: 0.4088033
	speed: 0.1012s/iter; left time: 766.4955s
Epoch: 2 cost time: 29.49519658088684
Epoch: 2, Steps: 268 | Train Loss: 0.2686756 Vali Loss: 0.1313020 Test Loss: 0.1811700
Validation loss decreased (0.150091 --> 0.131302).  Saving model ...
Updating learning rate to 1.043468983854729e-05
	iters: 100, epoch: 3 | loss: 0.2285158
	speed: 0.4502s/iter; left time: 3333.5600s
	iters: 200, epoch: 3 | loss: 0.2678844
	speed: 0.1055s/iter; left time: 770.9213s
Epoch: 3 cost time: 29.292961597442627
Epoch: 3, Steps: 268 | Train Loss: 0.2431109 Vali Loss: 0.1261707 Test Loss: 0.1719956
Validation loss decreased (0.131302 --> 0.126171).  Saving model ...
Updating learning rate to 1.806716705466112e-05
	iters: 100, epoch: 4 | loss: 0.2785904
	speed: 0.4402s/iter; left time: 3141.3632s
	iters: 200, epoch: 4 | loss: 0.2545803
	speed: 0.1024s/iter; left time: 720.4127s
Epoch: 4 cost time: 29.24262309074402
Epoch: 4, Steps: 268 | Train Loss: 0.2329192 Vali Loss: 0.1250101 Test Loss: 0.1702627
Validation loss decreased (0.126171 --> 0.125010).  Saving model ...
Updating learning rate to 2.8013541299259828e-05
	iters: 100, epoch: 5 | loss: 0.3324112
	speed: 0.4007s/iter; left time: 2752.5578s
	iters: 200, epoch: 5 | loss: 0.2383441
	speed: 0.1002s/iter; left time: 678.5799s
Epoch: 5 cost time: 27.207114934921265
Epoch: 5, Steps: 268 | Train Loss: 0.2274510 Vali Loss: 0.1250603 Test Loss: 0.1678021
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.9595564285622165e-05
	iters: 100, epoch: 6 | loss: 0.1605140
	speed: 0.4351s/iter; left time: 2871.8633s
	iters: 200, epoch: 6 | loss: 0.1595208
	speed: 0.1002s/iter; left time: 651.5099s
Epoch: 6 cost time: 27.816917181015015
Epoch: 6, Steps: 268 | Train Loss: 0.2241230 Vali Loss: 0.1239543 Test Loss: 0.1692037
Validation loss decreased (0.125010 --> 0.123954).  Saving model ...
Updating learning rate to 5.202345201265517e-05
	iters: 100, epoch: 7 | loss: 0.2108410
	speed: 0.4344s/iter; left time: 2750.8953s
	iters: 200, epoch: 7 | loss: 0.2970921
	speed: 0.0981s/iter; left time: 611.4443s
Epoch: 7 cost time: 27.529422283172607
Epoch: 7, Steps: 268 | Train Loss: 0.2215417 Vali Loss: 0.1226468 Test Loss: 0.1679381
Validation loss decreased (0.123954 --> 0.122647).  Saving model ...
Updating learning rate to 6.444974053509239e-05
	iters: 100, epoch: 8 | loss: 0.1914913
	speed: 0.4069s/iter; left time: 2467.9453s
	iters: 200, epoch: 8 | loss: 0.1975687
	speed: 0.0943s/iter; left time: 562.6283s
Epoch: 8 cost time: 27.152408838272095
Epoch: 8, Steps: 268 | Train Loss: 0.2185387 Vali Loss: 0.1256541 Test Loss: 0.1718710
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.602707495823693e-05
	iters: 100, epoch: 9 | loss: 0.1444688
	speed: 0.4072s/iter; left time: 2360.3595s
	iters: 200, epoch: 9 | loss: 0.3037826
	speed: 0.0991s/iter; left time: 564.3516s
Epoch: 9 cost time: 27.164647579193115
Epoch: 9, Steps: 268 | Train Loss: 0.2152847 Vali Loss: 0.1232248 Test Loss: 0.1687551
EarlyStopping counter: 2 out of 5
Updating learning rate to 8.596599099649138e-05
	iters: 100, epoch: 10 | loss: 0.2219553
	speed: 0.4160s/iter; left time: 2300.0315s
	iters: 200, epoch: 10 | loss: 0.1695819
	speed: 0.1003s/iter; left time: 544.3288s
Epoch: 10 cost time: 26.88949418067932
Epoch: 10, Steps: 268 | Train Loss: 0.2122164 Vali Loss: 0.1249134 Test Loss: 0.1691179
EarlyStopping counter: 3 out of 5
Updating learning rate to 9.35887489419945e-05
	iters: 100, epoch: 11 | loss: 0.1577172
	speed: 0.4287s/iter; left time: 2255.3041s
	iters: 200, epoch: 11 | loss: 0.2317017
	speed: 0.1014s/iter; left time: 523.3451s
Epoch: 11 cost time: 27.50937032699585
Epoch: 11, Steps: 268 | Train Loss: 0.2084207 Vali Loss: 0.1251451 Test Loss: 0.1734403
EarlyStopping counter: 4 out of 5
Updating learning rate to 9.837554907783572e-05
	iters: 100, epoch: 12 | loss: 0.1773313
	speed: 0.4371s/iter; left time: 2182.2909s
	iters: 200, epoch: 12 | loss: 0.2595787
	speed: 0.1040s/iter; left time: 509.0803s
Epoch: 12 cost time: 28.0702543258667
Epoch: 12, Steps: 268 | Train Loss: 0.2060219 Vali Loss: 0.1259170 Test Loss: 0.1701896
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : 192_96_PatchTST_ETTm2_ftM_sl192_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.16850537061691284, mae:0.25378552079200745, rse:0.33281514048576355

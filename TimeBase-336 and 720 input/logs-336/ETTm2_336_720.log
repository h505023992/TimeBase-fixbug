Args in experiment:
Namespace(is_training=1, model_id='ETTm2_336_720', model='LightTimeBaseTST', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, period_len=4, basis_num=32, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.02, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
8660
>>>>>>>start training : ETTm2_336_720_LightTimeBaseTST_ETTm2_ftM_sl336_pl720_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
Epoch: 1 cost time: 4.740647554397583
Epoch: 1, Steps: 66 | Train Loss: 0.6104449 Vali Loss: 0.3185168 Test Loss: 0.4382805
Validation loss decreased (inf --> 0.318517).  Saving model ...
Updating learning rate to 0.02
Epoch: 2 cost time: 4.093520879745483
Epoch: 2, Steps: 66 | Train Loss: 0.5744962 Vali Loss: 0.2838517 Test Loss: 0.4026773
Validation loss decreased (0.318517 --> 0.283852).  Saving model ...
Updating learning rate to 0.02
Epoch: 3 cost time: 4.08960485458374
Epoch: 3, Steps: 66 | Train Loss: 0.5501801 Vali Loss: 0.2933986 Test Loss: 0.4103357
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.02
Epoch: 4 cost time: 4.195528745651245
Epoch: 4, Steps: 66 | Train Loss: 0.5485743 Vali Loss: 0.2752413 Test Loss: 0.3957858
Validation loss decreased (0.283852 --> 0.275241).  Saving model ...
Updating learning rate to 0.016
Epoch: 5 cost time: 4.019692659378052
Epoch: 5, Steps: 66 | Train Loss: 0.5389409 Vali Loss: 0.2734607 Test Loss: 0.3892705
Validation loss decreased (0.275241 --> 0.273461).  Saving model ...
Updating learning rate to 0.012800000000000002
Epoch: 6 cost time: 3.9923171997070312
Epoch: 6, Steps: 66 | Train Loss: 0.5351984 Vali Loss: 0.2708159 Test Loss: 0.3895944
Validation loss decreased (0.273461 --> 0.270816).  Saving model ...
Updating learning rate to 0.010240000000000003
Epoch: 7 cost time: 4.106283903121948
Epoch: 7, Steps: 66 | Train Loss: 0.5347043 Vali Loss: 0.2724841 Test Loss: 0.3885643
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.008192000000000001
Epoch: 8 cost time: 4.017904758453369
Epoch: 8, Steps: 66 | Train Loss: 0.5309264 Vali Loss: 0.2675629 Test Loss: 0.3855091
Validation loss decreased (0.270816 --> 0.267563).  Saving model ...
Updating learning rate to 0.0065536000000000014
Epoch: 9 cost time: 3.7280218601226807
Epoch: 9, Steps: 66 | Train Loss: 0.5300014 Vali Loss: 0.2689660 Test Loss: 0.3854013
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.005242880000000002
Epoch: 10 cost time: 3.7352793216705322
Epoch: 10, Steps: 66 | Train Loss: 0.5276487 Vali Loss: 0.2741081 Test Loss: 0.3864355
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.004194304000000002
Epoch: 11 cost time: 3.7856526374816895
Epoch: 11, Steps: 66 | Train Loss: 0.5294284 Vali Loss: 0.2692870 Test Loss: 0.3873234
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.003355443200000002
Epoch: 12 cost time: 3.7840325832366943
Epoch: 12, Steps: 66 | Train Loss: 0.5286232 Vali Loss: 0.2696364 Test Loss: 0.3850573
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.002684354560000001
Epoch: 13 cost time: 3.6386537551879883
Epoch: 13, Steps: 66 | Train Loss: 0.5268276 Vali Loss: 0.2669094 Test Loss: 0.3845117
Validation loss decreased (0.267563 --> 0.266909).  Saving model ...
Updating learning rate to 0.0021474836480000013
Epoch: 14 cost time: 3.9017069339752197
Epoch: 14, Steps: 66 | Train Loss: 0.5263667 Vali Loss: 0.2702478 Test Loss: 0.3845260
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0017179869184000011
Epoch: 15 cost time: 3.7390060424804688
Epoch: 15, Steps: 66 | Train Loss: 0.5263475 Vali Loss: 0.2685111 Test Loss: 0.3844649
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0013743895347200009
Epoch: 16 cost time: 3.853774070739746
Epoch: 16, Steps: 66 | Train Loss: 0.5263353 Vali Loss: 0.2668285 Test Loss: 0.3845292
Validation loss decreased (0.266909 --> 0.266829).  Saving model ...
Updating learning rate to 0.0010995116277760007
Epoch: 17 cost time: 3.8544812202453613
Epoch: 17, Steps: 66 | Train Loss: 0.5261777 Vali Loss: 0.2689362 Test Loss: 0.3840846
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0008796093022208007
Epoch: 18 cost time: 3.927279472351074
Epoch: 18, Steps: 66 | Train Loss: 0.5241802 Vali Loss: 0.2656893 Test Loss: 0.3841745
Validation loss decreased (0.266829 --> 0.265689).  Saving model ...
Updating learning rate to 0.0007036874417766406
Epoch: 19 cost time: 3.8909313678741455
Epoch: 19, Steps: 66 | Train Loss: 0.5247558 Vali Loss: 0.2684434 Test Loss: 0.3842533
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0005629499534213125
Epoch: 20 cost time: 4.238882541656494
Epoch: 20, Steps: 66 | Train Loss: 0.5254707 Vali Loss: 0.2695194 Test Loss: 0.3837443
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0004503599627370501
Epoch: 21 cost time: 3.6158645153045654
Epoch: 21, Steps: 66 | Train Loss: 0.5246571 Vali Loss: 0.2667620 Test Loss: 0.3839990
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00036028797018964004
Epoch: 22 cost time: 3.6023406982421875
Epoch: 22, Steps: 66 | Train Loss: 0.5248858 Vali Loss: 0.2669227 Test Loss: 0.3838333
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00028823037615171204
Epoch: 23 cost time: 3.6987366676330566
Epoch: 23, Steps: 66 | Train Loss: 0.5244243 Vali Loss: 0.2698701 Test Loss: 0.3839569
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm2_336_720_LightTimeBaseTST_ETTm2_ftM_sl336_pl720_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.36858016657829285, mae:0.38307415556907654, rse:0.4893115758895874

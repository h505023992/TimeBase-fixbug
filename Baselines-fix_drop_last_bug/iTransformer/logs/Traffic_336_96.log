Args in experiment:
Namespace(is_training=1, model_id='traffic_336_96', model='iTransformer', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, enc_in=862, dec_in=862, c_out=862, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=2, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)
Use GPU: cuda:2
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
MACs: 783060992.0
Params: 903008.0
783.06M MACs
>>>>>>>start training : traffic_336_96_iTransformer_custom_M_ft336_sl48_ll96_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11849
val 1661
test 3413
	iters: 100, epoch: 1 | loss: 0.4172697
	speed: 0.1548s/iter; left time: 557.5026s
	iters: 200, epoch: 1 | loss: 0.3473571
	speed: 0.1363s/iter; left time: 477.0589s
	iters: 300, epoch: 1 | loss: 0.3158299
	speed: 0.1355s/iter; left time: 460.8892s
Max Memory (MB): 5153.30615234375
Epoch: 1 cost time: 52.312936782836914
Epoch: 1, Steps: 370 | Train Loss: 0.3941080 Vali Loss: 0.3803920 Test Loss: 0.4632425
Validation loss decreased (inf --> 0.380392).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2843108
	speed: 2.0684s/iter; left time: 6682.9413s
	iters: 200, epoch: 2 | loss: 0.2806112
	speed: 0.1427s/iter; left time: 446.7610s
	iters: 300, epoch: 2 | loss: 0.2498979
	speed: 0.1400s/iter; left time: 424.4870s
Max Memory (MB): 5153.30615234375
Epoch: 2 cost time: 54.349573850631714
Epoch: 2, Steps: 370 | Train Loss: 0.2835275 Vali Loss: 0.3564776 Test Loss: 0.4286976
Validation loss decreased (0.380392 --> 0.356478).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2606092
	speed: 1.9270s/iter; left time: 5513.1628s
	iters: 200, epoch: 3 | loss: 0.2995935
	speed: 0.1550s/iter; left time: 427.9877s
	iters: 300, epoch: 3 | loss: 0.2907895
	speed: 0.1547s/iter; left time: 411.7535s
Max Memory (MB): 5153.30615234375
Epoch: 3 cost time: 58.59611225128174
Epoch: 3, Steps: 370 | Train Loss: 0.2697058 Vali Loss: 0.3502982 Test Loss: 0.4202352
Validation loss decreased (0.356478 --> 0.350298).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2400976
	speed: 1.9097s/iter; left time: 4757.1125s
	iters: 200, epoch: 4 | loss: 0.2709881
	speed: 0.1459s/iter; left time: 348.7444s
	iters: 300, epoch: 4 | loss: 0.2471660
	speed: 0.1402s/iter; left time: 321.2669s
Max Memory (MB): 5153.30615234375
Epoch: 4 cost time: 54.4016592502594
Epoch: 4, Steps: 370 | Train Loss: 0.2652315 Vali Loss: 0.3484400 Test Loss: 0.4164155
Validation loss decreased (0.350298 --> 0.348440).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2742781
	speed: 1.9206s/iter; left time: 4073.5466s
	iters: 200, epoch: 5 | loss: 0.2526398
	speed: 0.1377s/iter; left time: 278.3316s
	iters: 300, epoch: 5 | loss: 0.2528729
	speed: 0.1360s/iter; left time: 261.2618s
Max Memory (MB): 5153.30615234375
Epoch: 5 cost time: 53.13643455505371
Epoch: 5, Steps: 370 | Train Loss: 0.2632356 Vali Loss: 0.3460729 Test Loss: 0.4145876
Validation loss decreased (0.348440 --> 0.346073).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2464431
	speed: 1.9103s/iter; left time: 3344.8578s
	iters: 200, epoch: 6 | loss: 0.2605825
	speed: 0.1360s/iter; left time: 224.5380s
	iters: 300, epoch: 6 | loss: 0.2674460
	speed: 0.1370s/iter; left time: 212.5001s
Max Memory (MB): 5153.30615234375
Epoch: 6 cost time: 52.24201321601868
Epoch: 6, Steps: 370 | Train Loss: 0.2622735 Vali Loss: 0.3461095 Test Loss: 0.4138635
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2763299
	speed: 2.0344s/iter; left time: 2809.4656s
	iters: 200, epoch: 7 | loss: 0.2580898
	speed: 0.1465s/iter; left time: 187.6690s
	iters: 300, epoch: 7 | loss: 0.2600306
	speed: 0.1444s/iter; left time: 170.5386s
Max Memory (MB): 5153.30615234375
Epoch: 7 cost time: 55.334871768951416
Epoch: 7, Steps: 370 | Train Loss: 0.2617334 Vali Loss: 0.3461298 Test Loss: 0.4136868
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2684253
	speed: 1.7956s/iter; left time: 1815.3090s
	iters: 200, epoch: 8 | loss: 0.2425101
	speed: 0.1452s/iter; left time: 132.3187s
	iters: 300, epoch: 8 | loss: 0.2726620
	speed: 0.1521s/iter; left time: 123.3532s
Max Memory (MB): 5153.30615234375
Epoch: 8 cost time: 56.23827314376831
Epoch: 8, Steps: 370 | Train Loss: 0.2614754 Vali Loss: 0.3457146 Test Loss: 0.4132595
Validation loss decreased (0.346073 --> 0.345715).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2388819
	speed: 2.1636s/iter; left time: 1386.8672s
	iters: 200, epoch: 9 | loss: 0.2762519
	speed: 0.1416s/iter; left time: 76.6178s
	iters: 300, epoch: 9 | loss: 0.2573812
	speed: 0.1424s/iter; left time: 62.8055s
Max Memory (MB): 5153.30615234375
Epoch: 9 cost time: 54.275068521499634
Epoch: 9, Steps: 370 | Train Loss: 0.2613896 Vali Loss: 0.3457035 Test Loss: 0.4131722
Validation loss decreased (0.345715 --> 0.345703).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2415689
	speed: 1.9643s/iter; left time: 532.3306s
	iters: 200, epoch: 10 | loss: 0.2696373
	speed: 0.1450s/iter; left time: 24.7892s
	iters: 300, epoch: 10 | loss: 0.2834451
	speed: 0.1413s/iter; left time: 10.0356s
Max Memory (MB): 5153.30615234375
Epoch: 10 cost time: 55.26473784446716
Epoch: 10, Steps: 370 | Train Loss: 0.2612862 Vali Loss: 0.3458710 Test Loss: 0.4131156
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : traffic_336_96_iTransformer_custom_M_ft336_sl48_ll96_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
test shape: (3413, 1, 96, 862) (3413, 1, 96, 862)
test shape: (3413, 96, 862) (3413, 96, 862)
mse:0.41317427158355713, mae:0.3025444447994232

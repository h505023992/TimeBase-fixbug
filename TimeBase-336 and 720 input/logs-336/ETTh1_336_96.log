Args in experiment:
Namespace(is_training=1, model_id='ETTh1_336_96', model='LightTimeBaseTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, period_len=24, basis_num=6, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.16, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.1, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=6, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:6
118
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 18144.0
Params: 118.0
18144.0 MACs
>>>>>>>start training : ETTh1_336_96_LightTimeBaseTST_ETTh1_ftM_sl336_pl96_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
Max Memory (MB): 47.22607421875
Epoch: 1 cost time: 3.396021842956543
Epoch: 1, Steps: 17 | Train Loss: 0.4810612 Vali Loss: 1.0173007 Test Loss: 0.4687237
Validation loss decreased (inf --> 1.017301).  Saving model ...
Updating learning rate to 0.1
Max Memory (MB): 47.22607421875
Epoch: 2 cost time: 4.036396026611328
Epoch: 2, Steps: 17 | Train Loss: 0.5066690 Vali Loss: 1.0884545 Test Loss: 0.5448723
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.1
Max Memory (MB): 47.22607421875
Epoch: 3 cost time: 3.470560312271118
Epoch: 3, Steps: 17 | Train Loss: 0.5596120 Vali Loss: 0.9978285 Test Loss: 0.4688721
Validation loss decreased (1.017301 --> 0.997828).  Saving model ...
Updating learning rate to 0.1
Max Memory (MB): 47.22607421875
Epoch: 4 cost time: 3.1595802307128906
Epoch: 4, Steps: 17 | Train Loss: 0.4437219 Vali Loss: 0.9237557 Test Loss: 0.4249945
Validation loss decreased (0.997828 --> 0.923756).  Saving model ...
Updating learning rate to 0.08000000000000002
Max Memory (MB): 47.22607421875
Epoch: 5 cost time: 3.158435583114624
Epoch: 5, Steps: 17 | Train Loss: 0.4024053 Vali Loss: 0.8728177 Test Loss: 0.3968086
Validation loss decreased (0.923756 --> 0.872818).  Saving model ...
Updating learning rate to 0.06400000000000002
Max Memory (MB): 47.22607421875
Epoch: 6 cost time: 3.237353563308716
Epoch: 6, Steps: 17 | Train Loss: 0.3884649 Vali Loss: 0.8833439 Test Loss: 0.3968647
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.051200000000000016
Max Memory (MB): 47.22607421875
Epoch: 7 cost time: 3.2767043113708496
Epoch: 7, Steps: 17 | Train Loss: 0.3809912 Vali Loss: 0.8157017 Test Loss: 0.3814488
Validation loss decreased (0.872818 --> 0.815702).  Saving model ...
Updating learning rate to 0.04096000000000001
Max Memory (MB): 47.22607421875
Epoch: 8 cost time: 2.9538185596466064
Epoch: 8, Steps: 17 | Train Loss: 0.3686100 Vali Loss: 0.8165083 Test Loss: 0.3808227
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.03276800000000001
Max Memory (MB): 47.22607421875
Epoch: 9 cost time: 3.312972068786621
Epoch: 9, Steps: 17 | Train Loss: 0.3713708 Vali Loss: 0.8030605 Test Loss: 0.3790256
Validation loss decreased (0.815702 --> 0.803061).  Saving model ...
Updating learning rate to 0.026214400000000013
Max Memory (MB): 47.22607421875
Epoch: 10 cost time: 2.7407195568084717
Epoch: 10, Steps: 17 | Train Loss: 0.3601336 Vali Loss: 0.7596118 Test Loss: 0.3763867
Validation loss decreased (0.803061 --> 0.759612).  Saving model ...
Updating learning rate to 0.020971520000000007
Max Memory (MB): 47.22607421875
Epoch: 11 cost time: 3.1304447650909424
Epoch: 11, Steps: 17 | Train Loss: 0.3666146 Vali Loss: 0.7568629 Test Loss: 0.3749398
Validation loss decreased (0.759612 --> 0.756863).  Saving model ...
Updating learning rate to 0.016777216000000008
Max Memory (MB): 47.22607421875
Epoch: 12 cost time: 3.0720489025115967
Epoch: 12, Steps: 17 | Train Loss: 0.3577357 Vali Loss: 0.7452276 Test Loss: 0.3731837
Validation loss decreased (0.756863 --> 0.745228).  Saving model ...
Updating learning rate to 0.013421772800000007
Max Memory (MB): 47.22607421875
Epoch: 13 cost time: 2.7209348678588867
Epoch: 13, Steps: 17 | Train Loss: 0.3624683 Vali Loss: 0.7464580 Test Loss: 0.3741314
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.010737418240000006
Max Memory (MB): 47.22607421875
Epoch: 14 cost time: 3.160961866378784
Epoch: 14, Steps: 17 | Train Loss: 0.3620785 Vali Loss: 0.7418882 Test Loss: 0.3734807
Validation loss decreased (0.745228 --> 0.741888).  Saving model ...
Updating learning rate to 0.008589934592000005
Max Memory (MB): 47.22607421875
Epoch: 15 cost time: 3.0891733169555664
Epoch: 15, Steps: 17 | Train Loss: 0.3604205 Vali Loss: 0.7489657 Test Loss: 0.3739055
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0068719476736000045
Max Memory (MB): 47.22607421875
Epoch: 16 cost time: 3.0758047103881836
Epoch: 16, Steps: 17 | Train Loss: 0.3626273 Vali Loss: 0.7426770 Test Loss: 0.3730240
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.005497558138880004
Max Memory (MB): 47.22607421875
Epoch: 17 cost time: 2.963230609893799
Epoch: 17, Steps: 17 | Train Loss: 0.3595783 Vali Loss: 0.7453107 Test Loss: 0.3736691
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.004398046511104004
Max Memory (MB): 47.22607421875
Epoch: 18 cost time: 2.845491409301758
Epoch: 18, Steps: 17 | Train Loss: 0.3624743 Vali Loss: 0.7505149 Test Loss: 0.3738434
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0035184372088832034
Max Memory (MB): 47.22607421875
Epoch: 19 cost time: 1.9709019660949707
Epoch: 19, Steps: 17 | Train Loss: 0.3587412 Vali Loss: 0.7524789 Test Loss: 0.3734704
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 47.22607421875
>>>>>>>testing : ETTh1_336_96_LightTimeBaseTST_ETTh1_ftM_sl336_pl96_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3626962900161743, mae:0.3826998472213745, rse:0.5720439553260803

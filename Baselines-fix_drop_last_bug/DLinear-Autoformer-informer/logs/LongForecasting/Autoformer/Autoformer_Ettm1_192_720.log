Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Autoformer_ETTm1_192_720', model='Autoformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=720, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Autoformer_ETTm1_192_720_Autoformer_ETTm1_ftM_sl192_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5021948
	speed: 0.2563s/iter; left time: 8063.0787s
	iters: 200, epoch: 1 | loss: 0.5115851
	speed: 0.2271s/iter; left time: 7123.4935s
	iters: 300, epoch: 1 | loss: 0.5344239
	speed: 0.2245s/iter; left time: 7017.0148s
	iters: 400, epoch: 1 | loss: 0.4894950
	speed: 0.2233s/iter; left time: 6958.5376s
	iters: 500, epoch: 1 | loss: 0.3894043
	speed: 0.2233s/iter; left time: 6934.5224s
	iters: 600, epoch: 1 | loss: 0.4089918
	speed: 0.2287s/iter; left time: 7079.5662s
	iters: 700, epoch: 1 | loss: 0.3914885
	speed: 0.2290s/iter; left time: 7066.1453s
	iters: 800, epoch: 1 | loss: 0.4197021
	speed: 0.2281s/iter; left time: 7015.3626s
	iters: 900, epoch: 1 | loss: 0.4256098
	speed: 0.2277s/iter; left time: 6981.6723s
	iters: 1000, epoch: 1 | loss: 0.3993737
	speed: 0.2237s/iter; left time: 6837.0437s
Epoch: 1 cost time: 240.92474102973938
Epoch: 1, Steps: 1052 | Train Loss: 0.4496326 Vali Loss: 1.0220433 Test Loss: 0.5072120
Validation loss decreased (inf --> 1.022043).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3768100
	speed: 1.6344s/iter; left time: 49701.1439s
	iters: 200, epoch: 2 | loss: 0.3824230
	speed: 0.2231s/iter; left time: 6760.6234s
	iters: 300, epoch: 2 | loss: 0.3425089
	speed: 0.2207s/iter; left time: 6667.1619s
	iters: 400, epoch: 2 | loss: 0.3525624
	speed: 0.2245s/iter; left time: 6760.6640s
	iters: 500, epoch: 2 | loss: 0.3490315
	speed: 0.2257s/iter; left time: 6773.1581s
	iters: 600, epoch: 2 | loss: 0.3525905
	speed: 0.2273s/iter; left time: 6798.4950s
	iters: 700, epoch: 2 | loss: 0.3456151
	speed: 0.2277s/iter; left time: 6787.5838s
	iters: 800, epoch: 2 | loss: 0.3720397
	speed: 0.2229s/iter; left time: 6622.3308s
	iters: 900, epoch: 2 | loss: 0.3538954
	speed: 0.2216s/iter; left time: 6560.5444s
	iters: 1000, epoch: 2 | loss: 0.3382013
	speed: 0.2231s/iter; left time: 6582.9659s
Epoch: 2 cost time: 237.0711009502411
Epoch: 2, Steps: 1052 | Train Loss: 0.3676517 Vali Loss: 1.0613143 Test Loss: 0.5479640
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3171805
	speed: 1.7293s/iter; left time: 50767.4186s
	iters: 200, epoch: 3 | loss: 0.3152026
	speed: 0.2288s/iter; left time: 6695.0853s
	iters: 300, epoch: 3 | loss: 0.3195290
	speed: 0.2241s/iter; left time: 6533.8700s
	iters: 400, epoch: 3 | loss: 0.3285266
	speed: 0.2236s/iter; left time: 6496.5992s
	iters: 500, epoch: 3 | loss: 0.3211571
	speed: 0.2215s/iter; left time: 6414.0303s
	iters: 600, epoch: 3 | loss: 0.3219786
	speed: 0.2233s/iter; left time: 6442.4066s
	iters: 700, epoch: 3 | loss: 0.3160592
	speed: 0.2218s/iter; left time: 6378.1833s
	iters: 800, epoch: 3 | loss: 0.2782661
	speed: 0.2227s/iter; left time: 6381.9703s
	iters: 900, epoch: 3 | loss: 0.2824362
	speed: 0.2256s/iter; left time: 6442.7816s
	iters: 1000, epoch: 3 | loss: 0.2871635
	speed: 0.2254s/iter; left time: 6415.1830s
Epoch: 3 cost time: 237.0469126701355
Epoch: 3, Steps: 1052 | Train Loss: 0.3193377 Vali Loss: 1.0728976 Test Loss: 0.5588282
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3219777
	speed: 1.4988s/iter; left time: 42423.0845s
	iters: 200, epoch: 4 | loss: 0.2710749
	speed: 0.2203s/iter; left time: 6213.5825s
	iters: 300, epoch: 4 | loss: 0.3054512
	speed: 0.2213s/iter; left time: 6220.4379s
	iters: 400, epoch: 4 | loss: 0.2816665
	speed: 0.2201s/iter; left time: 6164.3342s
	iters: 500, epoch: 4 | loss: 0.3131438
	speed: 0.2232s/iter; left time: 6229.7305s
	iters: 600, epoch: 4 | loss: 0.2759678
	speed: 0.2201s/iter; left time: 6119.1671s
	iters: 700, epoch: 4 | loss: 0.3062688
	speed: 0.2202s/iter; left time: 6101.2975s
	iters: 800, epoch: 4 | loss: 0.2781859
	speed: 0.2281s/iter; left time: 6296.8461s
	iters: 900, epoch: 4 | loss: 0.2913156
	speed: 0.2245s/iter; left time: 6174.9998s
	iters: 1000, epoch: 4 | loss: 0.3165960
	speed: 0.2207s/iter; left time: 6047.7370s
Epoch: 4 cost time: 233.8768491744995
Epoch: 4, Steps: 1052 | Train Loss: 0.2944714 Vali Loss: 1.0697614 Test Loss: 0.5606210
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Autoformer_ETTm1_192_720_Autoformer_ETTm1_ftM_sl192_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.5069815516471863, mae:0.48868218064308167

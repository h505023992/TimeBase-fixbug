Args in experiment:
Namespace(is_training=1, train_only=False, model_id='ETTm1_720_336', model='Autoformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_336_Autoformer_ETTm1_ftM_sl720_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4510523
	speed: 0.3064s/iter; left time: 9603.7460s
	iters: 200, epoch: 1 | loss: 0.3760976
	speed: 0.2819s/iter; left time: 8806.5241s
	iters: 300, epoch: 1 | loss: 0.3492061
	speed: 0.2819s/iter; left time: 8777.1503s
	iters: 400, epoch: 1 | loss: 0.3464934
	speed: 0.2810s/iter; left time: 8721.2448s
	iters: 500, epoch: 1 | loss: 0.3091898
	speed: 0.2839s/iter; left time: 8783.2830s
	iters: 600, epoch: 1 | loss: 0.3304992
	speed: 0.2872s/iter; left time: 8858.2201s
	iters: 700, epoch: 1 | loss: 0.3667316
	speed: 0.2896s/iter; left time: 8903.1017s
	iters: 800, epoch: 1 | loss: 0.3620335
	speed: 0.2884s/iter; left time: 8836.8845s
	iters: 900, epoch: 1 | loss: 0.3039933
	speed: 0.2866s/iter; left time: 8752.4067s
	iters: 1000, epoch: 1 | loss: 0.3530707
	speed: 0.2840s/iter; left time: 8646.1930s
Epoch: 1 cost time: 301.3188922405243
Epoch: 1, Steps: 1048 | Train Loss: 0.3736688 Vali Loss: 1.1090448 Test Loss: 0.7376325
Validation loss decreased (inf --> 1.109045).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2661964
	speed: 1.9336s/iter; left time: 58573.8594s
	iters: 200, epoch: 2 | loss: 0.2769897
	speed: 0.2823s/iter; left time: 8522.8216s
	iters: 300, epoch: 2 | loss: 0.2685477
	speed: 0.2839s/iter; left time: 8544.4704s
	iters: 400, epoch: 2 | loss: 0.2415627
	speed: 0.2834s/iter; left time: 8499.8351s
	iters: 500, epoch: 2 | loss: 0.2677090
	speed: 0.2837s/iter; left time: 8479.2445s
	iters: 600, epoch: 2 | loss: 0.2845809
	speed: 0.2839s/iter; left time: 8457.6986s
	iters: 700, epoch: 2 | loss: 0.2333282
	speed: 0.2858s/iter; left time: 8487.2169s
	iters: 800, epoch: 2 | loss: 0.2298396
	speed: 0.2864s/iter; left time: 8474.0231s
	iters: 900, epoch: 2 | loss: 0.2184169
	speed: 0.2875s/iter; left time: 8479.4775s
	iters: 1000, epoch: 2 | loss: 0.2049077
	speed: 0.2884s/iter; left time: 8478.3992s
Epoch: 2 cost time: 300.097092628479
Epoch: 2, Steps: 1048 | Train Loss: 0.2573931 Vali Loss: 1.1912606 Test Loss: 0.6947848
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2057635
	speed: 1.8499s/iter; left time: 54100.7211s
	iters: 200, epoch: 3 | loss: 0.2002497
	speed: 0.2780s/iter; left time: 8101.7183s
	iters: 300, epoch: 3 | loss: 0.2427836
	speed: 0.2804s/iter; left time: 8143.7263s
	iters: 400, epoch: 3 | loss: 0.2108630
	speed: 0.2764s/iter; left time: 7999.8039s
	iters: 500, epoch: 3 | loss: 0.1962941
	speed: 0.2768s/iter; left time: 7985.4770s
	iters: 600, epoch: 3 | loss: 0.2022475
	speed: 0.2790s/iter; left time: 8019.7154s
	iters: 700, epoch: 3 | loss: 0.1880031
	speed: 0.2833s/iter; left time: 8113.8992s
	iters: 800, epoch: 3 | loss: 0.1764858
	speed: 0.2783s/iter; left time: 7943.7018s
	iters: 900, epoch: 3 | loss: 0.1949460
	speed: 0.2803s/iter; left time: 7973.0912s
	iters: 1000, epoch: 3 | loss: 0.1744336
	speed: 0.2767s/iter; left time: 7844.1135s
Epoch: 3 cost time: 292.38684582710266
Epoch: 3, Steps: 1048 | Train Loss: 0.2055083 Vali Loss: 1.1278292 Test Loss: 0.7009478
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1680949
	speed: 1.8670s/iter; left time: 52642.5065s
	iters: 200, epoch: 4 | loss: 0.1692181
	speed: 0.2799s/iter; left time: 7863.7442s
	iters: 300, epoch: 4 | loss: 0.2022311
	speed: 0.2840s/iter; left time: 7952.0577s
	iters: 400, epoch: 4 | loss: 0.1744358
	speed: 0.2830s/iter; left time: 7895.4797s
	iters: 500, epoch: 4 | loss: 0.1888990
	speed: 0.2854s/iter; left time: 7933.5950s
	iters: 600, epoch: 4 | loss: 0.1571688
	speed: 0.2783s/iter; left time: 7707.8608s
	iters: 700, epoch: 4 | loss: 0.1871250
	speed: 0.2791s/iter; left time: 7702.4643s
	iters: 800, epoch: 4 | loss: 0.1836946
	speed: 0.2712s/iter; left time: 7456.2621s
	iters: 900, epoch: 4 | loss: 0.1772195
	speed: 0.2723s/iter; left time: 7460.4644s
	iters: 1000, epoch: 4 | loss: 0.1762629
	speed: 0.2815s/iter; left time: 7683.9910s
Epoch: 4 cost time: 293.6068334579468
Epoch: 4, Steps: 1048 | Train Loss: 0.1782386 Vali Loss: 1.1291914 Test Loss: 0.6976779
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_720_336_Autoformer_ETTm1_ftM_sl720_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.7371770143508911, mae:0.6081652641296387

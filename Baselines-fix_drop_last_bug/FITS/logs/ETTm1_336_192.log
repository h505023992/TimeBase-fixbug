Args in experiment:
Namespace(is_training=1, model_id='ETTm1_336_192', model='FITS', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=100, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_336_192_FITS_ETTm1_ftM_sl336_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=100, out_features=157, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  14067200.0
params:  15857.0
Trainable parameters:  15857
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3988345
	speed: 0.0843s/iter; left time: 661.6330s
	iters: 200, epoch: 1 | loss: 0.2835196
	speed: 0.0915s/iter; left time: 709.4750s
Epoch: 1 cost time: 23.093470335006714
Epoch: 1, Steps: 265 | Train Loss: 0.3839328 Vali Loss: 0.6955990 Test Loss: 0.5057088
Validation loss decreased (inf --> 0.695599).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2233206
	speed: 0.3946s/iter; left time: 2993.4775s
	iters: 200, epoch: 2 | loss: 0.2131071
	speed: 0.0826s/iter; left time: 618.2269s
Epoch: 2 cost time: 22.99578309059143
Epoch: 2, Steps: 265 | Train Loss: 0.2288182 Vali Loss: 0.6172822 Test Loss: 0.4484980
Validation loss decreased (0.695599 --> 0.617282).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1900109
	speed: 0.3677s/iter; left time: 2691.9251s
	iters: 200, epoch: 3 | loss: 0.1789671
	speed: 0.0804s/iter; left time: 580.8139s
Epoch: 3 cost time: 23.072092056274414
Epoch: 3, Steps: 265 | Train Loss: 0.1849931 Vali Loss: 0.5846697 Test Loss: 0.4173864
Validation loss decreased (0.617282 --> 0.584670).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1640644
	speed: 0.3616s/iter; left time: 2551.6883s
	iters: 200, epoch: 4 | loss: 0.1550515
	speed: 0.0835s/iter; left time: 581.0905s
Epoch: 4 cost time: 23.1383216381073
Epoch: 4, Steps: 265 | Train Loss: 0.1616964 Vali Loss: 0.5663583 Test Loss: 0.3986849
Validation loss decreased (0.584670 --> 0.566358).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1435414
	speed: 0.3763s/iter; left time: 2555.5692s
	iters: 200, epoch: 5 | loss: 0.1455069
	speed: 0.0723s/iter; left time: 483.8687s
Epoch: 5 cost time: 21.173380613327026
Epoch: 5, Steps: 265 | Train Loss: 0.1473030 Vali Loss: 0.5527979 Test Loss: 0.3838885
Validation loss decreased (0.566358 --> 0.552798).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1458846
	speed: 0.3796s/iter; left time: 2477.2571s
	iters: 200, epoch: 6 | loss: 0.1344936
	speed: 0.0764s/iter; left time: 491.0493s
Epoch: 6 cost time: 21.809216499328613
Epoch: 6, Steps: 265 | Train Loss: 0.1381612 Vali Loss: 0.5426897 Test Loss: 0.3732306
Validation loss decreased (0.552798 --> 0.542690).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1366326
	speed: 0.3688s/iter; left time: 2308.7455s
	iters: 200, epoch: 7 | loss: 0.1287337
	speed: 0.0863s/iter; left time: 531.4828s
Epoch: 7 cost time: 23.27918767929077
Epoch: 7, Steps: 265 | Train Loss: 0.1320894 Vali Loss: 0.5365318 Test Loss: 0.3661345
Validation loss decreased (0.542690 --> 0.536532).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1261223
	speed: 0.3761s/iter; left time: 2255.3190s
	iters: 200, epoch: 8 | loss: 0.1323111
	speed: 0.0775s/iter; left time: 457.1044s
Epoch: 8 cost time: 22.988549947738647
Epoch: 8, Steps: 265 | Train Loss: 0.1280490 Vali Loss: 0.5329150 Test Loss: 0.3603784
Validation loss decreased (0.536532 --> 0.532915).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1156898
	speed: 0.3869s/iter; left time: 2217.1298s
	iters: 200, epoch: 9 | loss: 0.1267786
	speed: 0.0783s/iter; left time: 441.0334s
Epoch: 9 cost time: 22.99331307411194
Epoch: 9, Steps: 265 | Train Loss: 0.1253972 Vali Loss: 0.5290577 Test Loss: 0.3561198
Validation loss decreased (0.532915 --> 0.529058).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1454581
	speed: 0.3710s/iter; left time: 2027.6252s
	iters: 200, epoch: 10 | loss: 0.1244432
	speed: 0.0837s/iter; left time: 448.9484s
Epoch: 10 cost time: 22.95100212097168
Epoch: 10, Steps: 265 | Train Loss: 0.1235685 Vali Loss: 0.5272749 Test Loss: 0.3532168
Validation loss decreased (0.529058 --> 0.527275).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1175135
	speed: 0.3623s/iter; left time: 1884.1691s
	iters: 200, epoch: 11 | loss: 0.1204002
	speed: 0.0789s/iter; left time: 402.4757s
Epoch: 11 cost time: 22.61884045600891
Epoch: 11, Steps: 265 | Train Loss: 0.1222964 Vali Loss: 0.5264844 Test Loss: 0.3501730
Validation loss decreased (0.527275 --> 0.526484).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1193688
	speed: 0.3801s/iter; left time: 1876.2569s
	iters: 200, epoch: 12 | loss: 0.1235477
	speed: 0.0786s/iter; left time: 380.1516s
Epoch: 12 cost time: 22.578908443450928
Epoch: 12, Steps: 265 | Train Loss: 0.1214946 Vali Loss: 0.5242751 Test Loss: 0.3486210
Validation loss decreased (0.526484 --> 0.524275).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1217440
	speed: 0.3700s/iter; left time: 1728.0834s
	iters: 200, epoch: 13 | loss: 0.1204924
	speed: 0.0859s/iter; left time: 392.8057s
Epoch: 13 cost time: 23.001251935958862
Epoch: 13, Steps: 265 | Train Loss: 0.1208750 Vali Loss: 0.5244254 Test Loss: 0.3472549
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1168374
	speed: 0.3490s/iter; left time: 1537.6692s
	iters: 200, epoch: 14 | loss: 0.1182472
	speed: 0.0745s/iter; left time: 320.7180s
Epoch: 14 cost time: 21.458551168441772
Epoch: 14, Steps: 265 | Train Loss: 0.1204443 Vali Loss: 0.5225379 Test Loss: 0.3464060
Validation loss decreased (0.524275 --> 0.522538).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1262854
	speed: 0.3603s/iter; left time: 1492.1512s
	iters: 200, epoch: 15 | loss: 0.1052494
	speed: 0.0779s/iter; left time: 314.8700s
Epoch: 15 cost time: 22.070487022399902
Epoch: 15, Steps: 265 | Train Loss: 0.1202481 Vali Loss: 0.5220402 Test Loss: 0.3452304
Validation loss decreased (0.522538 --> 0.522040).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1322620
	speed: 0.3609s/iter; left time: 1398.7479s
	iters: 200, epoch: 16 | loss: 0.1252731
	speed: 0.0738s/iter; left time: 278.6755s
Epoch: 16 cost time: 21.87166666984558
Epoch: 16, Steps: 265 | Train Loss: 0.1200805 Vali Loss: 0.5219199 Test Loss: 0.3447679
Validation loss decreased (0.522040 --> 0.521920).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1238081
	speed: 0.3441s/iter; left time: 1242.3711s
	iters: 200, epoch: 17 | loss: 0.1207935
	speed: 0.0850s/iter; left time: 298.6039s
Epoch: 17 cost time: 23.279608011245728
Epoch: 17, Steps: 265 | Train Loss: 0.1199941 Vali Loss: 0.5221617 Test Loss: 0.3442564
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1213416
	speed: 0.3497s/iter; left time: 1170.1026s
	iters: 200, epoch: 18 | loss: 0.1172942
	speed: 0.0751s/iter; left time: 243.8173s
Epoch: 18 cost time: 21.616665363311768
Epoch: 18, Steps: 265 | Train Loss: 0.1199412 Vali Loss: 0.5214816 Test Loss: 0.3441083
Validation loss decreased (0.521920 --> 0.521482).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1229789
	speed: 0.3825s/iter; left time: 1178.6061s
	iters: 200, epoch: 19 | loss: 0.1131731
	speed: 0.0709s/iter; left time: 211.3140s
Epoch: 19 cost time: 20.72641611099243
Epoch: 19, Steps: 265 | Train Loss: 0.1198829 Vali Loss: 0.5212141 Test Loss: 0.3437374
Validation loss decreased (0.521482 --> 0.521214).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1192325
	speed: 0.2736s/iter; left time: 770.4581s
	iters: 200, epoch: 20 | loss: 0.1289262
	speed: 0.0767s/iter; left time: 208.3317s
Epoch: 20 cost time: 18.95198678970337
Epoch: 20, Steps: 265 | Train Loss: 0.1198725 Vali Loss: 0.5207990 Test Loss: 0.3437518
Validation loss decreased (0.521214 --> 0.520799).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1212914
	speed: 0.3746s/iter; left time: 955.7088s
	iters: 200, epoch: 21 | loss: 0.1239123
	speed: 0.0811s/iter; left time: 198.8150s
Epoch: 21 cost time: 23.019148588180542
Epoch: 21, Steps: 265 | Train Loss: 0.1198618 Vali Loss: 0.5206944 Test Loss: 0.3435066
Validation loss decreased (0.520799 --> 0.520694).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1254331
	speed: 0.3648s/iter; left time: 834.0287s
	iters: 200, epoch: 22 | loss: 0.1258071
	speed: 0.0744s/iter; left time: 162.6483s
Epoch: 22 cost time: 22.74976396560669
Epoch: 22, Steps: 265 | Train Loss: 0.1197969 Vali Loss: 0.5211171 Test Loss: 0.3435013
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1245607
	speed: 0.3675s/iter; left time: 742.7363s
	iters: 200, epoch: 23 | loss: 0.1302919
	speed: 0.0779s/iter; left time: 149.6789s
Epoch: 23 cost time: 22.220622539520264
Epoch: 23, Steps: 265 | Train Loss: 0.1198410 Vali Loss: 0.5209537 Test Loss: 0.3432263
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1205887
	speed: 0.3504s/iter; left time: 615.3746s
	iters: 200, epoch: 24 | loss: 0.1163962
	speed: 0.0461s/iter; left time: 76.4195s
Epoch: 24 cost time: 15.745989799499512
Epoch: 24, Steps: 265 | Train Loss: 0.1198204 Vali Loss: 0.5201278 Test Loss: 0.3432400
Validation loss decreased (0.520694 --> 0.520128).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1215748
	speed: 0.3008s/iter; left time: 448.5556s
	iters: 200, epoch: 25 | loss: 0.1228831
	speed: 0.0755s/iter; left time: 105.0747s
Epoch: 25 cost time: 20.830432176589966
Epoch: 25, Steps: 265 | Train Loss: 0.1198135 Vali Loss: 0.5215283 Test Loss: 0.3430060
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1214745
	speed: 0.3673s/iter; left time: 450.2614s
	iters: 200, epoch: 26 | loss: 0.1298638
	speed: 0.0792s/iter; left time: 89.1454s
Epoch: 26 cost time: 22.50963282585144
Epoch: 26, Steps: 265 | Train Loss: 0.1198673 Vali Loss: 0.5207820 Test Loss: 0.3429662
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1259252
	speed: 0.3642s/iter; left time: 349.9869s
	iters: 200, epoch: 27 | loss: 0.1193650
	speed: 0.0759s/iter; left time: 65.3370s
Epoch: 27 cost time: 20.673372745513916
Epoch: 27, Steps: 265 | Train Loss: 0.1198195 Vali Loss: 0.5203526 Test Loss: 0.3432284
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.1200567
	speed: 0.3580s/iter; left time: 249.1485s
	iters: 200, epoch: 28 | loss: 0.1138762
	speed: 0.0938s/iter; left time: 55.9198s
Epoch: 28 cost time: 22.692720413208008
Epoch: 28, Steps: 265 | Train Loss: 0.1198005 Vali Loss: 0.5204411 Test Loss: 0.3431946
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1115426
	speed: 0.3518s/iter; left time: 151.6146s
	iters: 200, epoch: 29 | loss: 0.1183109
	speed: 0.0847s/iter; left time: 28.0252s
Epoch: 29 cost time: 22.615506887435913
Epoch: 29, Steps: 265 | Train Loss: 0.1197841 Vali Loss: 0.5202773 Test Loss: 0.3431374
EarlyStopping counter: 5 out of 5
Early stopping
train 34033
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=100, out_features=157, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  14067200.0
params:  15857.0
Trainable parameters:  15857
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2875559
	speed: 0.0861s/iter; left time: 675.9595s
	iters: 200, epoch: 1 | loss: 0.3102689
	speed: 0.0802s/iter; left time: 621.5676s
Epoch: 1 cost time: 21.025243043899536
Epoch: 1, Steps: 265 | Train Loss: 0.3111819 Vali Loss: 0.5124553 Test Loss: 0.3384178
Validation loss decreased (inf --> 0.512455).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3209389
	speed: 0.3196s/iter; left time: 2424.7703s
	iters: 200, epoch: 2 | loss: 0.2873661
	speed: 0.0663s/iter; left time: 496.5981s
Epoch: 2 cost time: 19.559849977493286
Epoch: 2, Steps: 265 | Train Loss: 0.3097295 Vali Loss: 0.5108229 Test Loss: 0.3368932
Validation loss decreased (0.512455 --> 0.510823).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3102348
	speed: 0.3361s/iter; left time: 2460.6096s
	iters: 200, epoch: 3 | loss: 0.3567395
	speed: 0.0759s/iter; left time: 547.9186s
Epoch: 3 cost time: 21.450280904769897
Epoch: 3, Steps: 265 | Train Loss: 0.3092459 Vali Loss: 0.5088443 Test Loss: 0.3370774
Validation loss decreased (0.510823 --> 0.508844).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2974110
	speed: 0.3444s/iter; left time: 2430.2277s
	iters: 200, epoch: 4 | loss: 0.3233419
	speed: 0.0751s/iter; left time: 522.2969s
Epoch: 4 cost time: 21.810009002685547
Epoch: 4, Steps: 265 | Train Loss: 0.3090419 Vali Loss: 0.5102373 Test Loss: 0.3367185
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3148301
	speed: 0.3541s/iter; left time: 2404.4915s
	iters: 200, epoch: 5 | loss: 0.3031507
	speed: 0.0771s/iter; left time: 516.1378s
Epoch: 5 cost time: 21.289231777191162
Epoch: 5, Steps: 265 | Train Loss: 0.3085705 Vali Loss: 0.5099567 Test Loss: 0.3366345
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2999091
	speed: 0.3641s/iter; left time: 2375.8241s
	iters: 200, epoch: 6 | loss: 0.2844249
	speed: 0.0736s/iter; left time: 473.1851s
Epoch: 6 cost time: 21.038013458251953
Epoch: 6, Steps: 265 | Train Loss: 0.3085530 Vali Loss: 0.5104239 Test Loss: 0.3362629
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3226724
	speed: 0.3462s/iter; left time: 2167.8499s
	iters: 200, epoch: 7 | loss: 0.3102557
	speed: 0.0756s/iter; left time: 466.0547s
Epoch: 7 cost time: 21.34254288673401
Epoch: 7, Steps: 265 | Train Loss: 0.3085236 Vali Loss: 0.5095235 Test Loss: 0.3367147
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2773525
	speed: 0.3623s/iter; left time: 2172.3372s
	iters: 200, epoch: 8 | loss: 0.2777697
	speed: 0.0797s/iter; left time: 469.8165s
Epoch: 8 cost time: 21.660224437713623
Epoch: 8, Steps: 265 | Train Loss: 0.3084464 Vali Loss: 0.5091202 Test Loss: 0.3365962
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm1_336_192_FITS_ETTm1_ftM_sl336_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.33801695704460144, mae:0.36570486426353455, rse:0.553440272808075, corr:[0.5438529  0.5541577  0.5538     0.55790395 0.55879754 0.5571122
 0.5578078  0.55840653 0.5575998  0.5580207  0.5585379  0.55787396
 0.55760884 0.5572473  0.55545664 0.5534079  0.55196226 0.55050176
 0.54889226 0.5472367  0.54529357 0.5432562  0.5418624  0.54041916
 0.53799886 0.5356402  0.53454    0.5336688  0.53310674 0.5332912
 0.5339884  0.5344955  0.5347101  0.53525007 0.53623754 0.53705645
 0.5364885  0.53555673 0.5363923  0.5378479  0.53850156 0.5389914
 0.53953207 0.53930306 0.5386387  0.5392181  0.5401897  0.5404221
 0.54044414 0.5407023  0.54102486 0.54123515 0.5409272  0.54014957
 0.5399557  0.54021573 0.5399248  0.5393537  0.5392081  0.5388814
 0.53825086 0.53801197 0.53810984 0.5376883  0.5370338  0.537006
 0.53729844 0.5374667  0.5376378  0.53782743 0.53832096 0.5391355
 0.53915405 0.53819054 0.5378426  0.5384962  0.5385136  0.53775734
 0.53763515 0.538255   0.5383058  0.5380063  0.5382904  0.53832555
 0.53753906 0.5368604  0.5371126  0.5374447  0.5373541  0.53708196
 0.5367736  0.5366245  0.53701264 0.53766805 0.53780156 0.5371873
 0.53629845 0.53551316 0.534425   0.5328936  0.531626   0.53134614
 0.53174925 0.5317896  0.53130895 0.5311178  0.5311152  0.53080094
 0.53027374 0.53003854 0.5301538  0.53017014 0.5300387  0.5294224
 0.5283628  0.5277536  0.5276925  0.5274772  0.5273146  0.5274771
 0.52712846 0.526118   0.52556056 0.5255964  0.5254861  0.52552235
 0.52596986 0.5262937  0.5265587  0.526829   0.5267219  0.52677447
 0.5276953  0.52905786 0.52966577 0.52997774 0.5302814  0.5302281
 0.5302497  0.5308909  0.53154814 0.5318976  0.53221923 0.53283757
 0.5334354  0.53339434 0.5325844  0.5322977  0.53301233 0.53300565
 0.5320655  0.5319799  0.53263664 0.5324158  0.5317877  0.5318358
 0.5314371  0.53039765 0.5308829  0.5319982  0.5312159  0.52957004
 0.52996975 0.5311028  0.53128743 0.5313474  0.53178775 0.5319161
 0.53193074 0.5321823  0.5319533  0.53135717 0.5314295  0.53171563
 0.53130025 0.5310137  0.5310701  0.5305797  0.53021914 0.5308328
 0.5306159  0.52950287 0.5297147  0.53018135 0.5288812  0.5284509
 0.52990323 0.53002745 0.5299206  0.53159446 0.5316692  0.53244686]

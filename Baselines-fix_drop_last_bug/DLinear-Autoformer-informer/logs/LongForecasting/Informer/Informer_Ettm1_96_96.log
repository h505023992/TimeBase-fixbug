Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Informer_ETTm1_96_96', model='Informer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Informer_ETTm1_96_96_Informer_ETTm1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4239067
	speed: 0.3181s/iter; left time: 10226.5874s
	iters: 200, epoch: 1 | loss: 0.3412978
	speed: 0.2495s/iter; left time: 7998.1946s
	iters: 300, epoch: 1 | loss: 0.3528545
	speed: 0.2444s/iter; left time: 7809.1371s
	iters: 400, epoch: 1 | loss: 0.2808966
	speed: 0.2456s/iter; left time: 7823.1107s
	iters: 500, epoch: 1 | loss: 0.3658017
	speed: 0.2420s/iter; left time: 7684.5848s
	iters: 600, epoch: 1 | loss: 0.2549296
	speed: 0.2503s/iter; left time: 7921.3367s
	iters: 700, epoch: 1 | loss: 0.2983804
	speed: 0.2328s/iter; left time: 7346.6301s
	iters: 800, epoch: 1 | loss: 0.2787132
	speed: 0.2314s/iter; left time: 7276.4960s
	iters: 900, epoch: 1 | loss: 0.2244778
	speed: 0.2384s/iter; left time: 7474.8009s
	iters: 1000, epoch: 1 | loss: 0.2987623
	speed: 0.2419s/iter; left time: 7559.5543s
Epoch: 1 cost time: 268.3834936618805
Epoch: 1, Steps: 1075 | Train Loss: 0.3108654 Vali Loss: 0.6732129 Test Loss: 0.6306984
Validation loss decreased (inf --> 0.673213).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2172594
	speed: 1.3091s/iter; left time: 40680.4123s
	iters: 200, epoch: 2 | loss: 0.2309061
	speed: 0.2667s/iter; left time: 8261.1445s
	iters: 300, epoch: 2 | loss: 0.2532169
	speed: 0.2585s/iter; left time: 7980.2306s
	iters: 400, epoch: 2 | loss: 0.2357427
	speed: 0.2506s/iter; left time: 7713.5768s
	iters: 500, epoch: 2 | loss: 0.2377862
	speed: 0.2623s/iter; left time: 8046.4169s
	iters: 600, epoch: 2 | loss: 0.1970533
	speed: 0.2397s/iter; left time: 7330.2757s
	iters: 700, epoch: 2 | loss: 0.2181420
	speed: 0.2494s/iter; left time: 7600.4550s
	iters: 800, epoch: 2 | loss: 0.2526079
	speed: 0.2494s/iter; left time: 7576.5680s
	iters: 900, epoch: 2 | loss: 0.2325741
	speed: 0.2461s/iter; left time: 7449.9980s
	iters: 1000, epoch: 2 | loss: 0.2283720
	speed: 0.2483s/iter; left time: 7493.9320s
Epoch: 2 cost time: 272.71315479278564
Epoch: 2, Steps: 1075 | Train Loss: 0.2291890 Vali Loss: 0.7007629 Test Loss: 0.6237605
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1837688
	speed: 1.2653s/iter; left time: 37961.3922s
	iters: 200, epoch: 3 | loss: 0.1759628
	speed: 0.2358s/iter; left time: 7051.9030s
	iters: 300, epoch: 3 | loss: 0.2036800
	speed: 0.2417s/iter; left time: 7204.0789s
	iters: 400, epoch: 3 | loss: 0.1945448
	speed: 0.2554s/iter; left time: 7586.1883s
	iters: 500, epoch: 3 | loss: 0.1665005
	speed: 0.2499s/iter; left time: 7398.5893s
	iters: 600, epoch: 3 | loss: 0.1945588
	speed: 0.2620s/iter; left time: 7730.1926s
	iters: 700, epoch: 3 | loss: 0.1806178
	speed: 0.2536s/iter; left time: 7456.0889s
	iters: 800, epoch: 3 | loss: 0.1661763
	speed: 0.2607s/iter; left time: 7637.9332s
	iters: 900, epoch: 3 | loss: 0.1494242
	speed: 0.2766s/iter; left time: 8077.4622s
	iters: 1000, epoch: 3 | loss: 0.1642298
	speed: 0.2701s/iter; left time: 7859.2132s
Epoch: 3 cost time: 275.4873914718628
Epoch: 3, Steps: 1075 | Train Loss: 0.1835971 Vali Loss: 0.8114271 Test Loss: 0.7825657
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1587597
	speed: 1.3440s/iter; left time: 38875.9638s
	iters: 200, epoch: 4 | loss: 0.1667708
	speed: 0.2541s/iter; left time: 7325.6699s
	iters: 300, epoch: 4 | loss: 0.1487501
	speed: 0.2500s/iter; left time: 7181.9948s
	iters: 400, epoch: 4 | loss: 0.1641730
	speed: 0.2519s/iter; left time: 7210.7519s
	iters: 500, epoch: 4 | loss: 0.1442885
	speed: 0.2474s/iter; left time: 7058.5155s
	iters: 600, epoch: 4 | loss: 0.1267534
	speed: 0.2535s/iter; left time: 7205.6800s
	iters: 700, epoch: 4 | loss: 0.1411514
	speed: 0.2592s/iter; left time: 7341.6080s
	iters: 800, epoch: 4 | loss: 0.1446517
	speed: 0.2467s/iter; left time: 6962.9311s
	iters: 900, epoch: 4 | loss: 0.1777420
	speed: 0.2466s/iter; left time: 6935.4288s
	iters: 1000, epoch: 4 | loss: 0.1523288
	speed: 0.2507s/iter; left time: 7026.4040s
Epoch: 4 cost time: 271.77946305274963
Epoch: 4, Steps: 1075 | Train Loss: 0.1577259 Vali Loss: 0.8300338 Test Loss: 0.7943317
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Informer_ETTm1_96_96_Informer_ETTm1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.6305805444717407, mae:0.5662747621536255

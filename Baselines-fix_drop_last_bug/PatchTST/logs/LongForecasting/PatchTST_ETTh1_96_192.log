Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='96_192', model='PatchTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, fc_dropout=0.3, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:1
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 1602048.0
Params: 53504.0
1.60M MACs
>>>>>>>start training : 96_192_PatchTST_ETTh1_ftM_sl96_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
Epoch: 1 cost time: 9.71618366241455
Epoch: 1, Steps: 66 | Train Loss: 0.7429908 Vali Loss: 1.5094012 Test Loss: 0.8510990
Validation loss decreased (inf --> 1.509401).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 8.874820470809937
Epoch: 2, Steps: 66 | Train Loss: 0.6664002 Vali Loss: 1.2450469 Test Loss: 0.6243972
Validation loss decreased (1.509401 --> 1.245047).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 8.955169677734375
Epoch: 3, Steps: 66 | Train Loss: 0.5618109 Vali Loss: 1.0945619 Test Loss: 0.5315247
Validation loss decreased (1.245047 --> 1.094562).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 8.389677286148071
Epoch: 4, Steps: 66 | Train Loss: 0.5151116 Vali Loss: 1.1820704 Test Loss: 0.4947218
EarlyStopping counter: 1 out of 5
Updating learning rate to 9e-05
Epoch: 5 cost time: 8.205948114395142
Epoch: 5, Steps: 66 | Train Loss: 0.4934111 Vali Loss: 1.0426986 Test Loss: 0.4765733
Validation loss decreased (1.094562 --> 1.042699).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 8.590500354766846
Epoch: 6, Steps: 66 | Train Loss: 0.4792827 Vali Loss: 1.0630161 Test Loss: 0.4670482
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 8.531447410583496
Epoch: 7, Steps: 66 | Train Loss: 0.4711148 Vali Loss: 1.0143543 Test Loss: 0.4610728
Validation loss decreased (1.042699 --> 1.014354).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 9.241895914077759
Epoch: 8, Steps: 66 | Train Loss: 0.4652481 Vali Loss: 1.0202547 Test Loss: 0.4578698
EarlyStopping counter: 1 out of 5
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 8.8521146774292
Epoch: 9, Steps: 66 | Train Loss: 0.4609368 Vali Loss: 1.0025151 Test Loss: 0.4556103
Validation loss decreased (1.014354 --> 1.002515).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 8.424496412277222
Epoch: 10, Steps: 66 | Train Loss: 0.4577065 Vali Loss: 1.0579947 Test Loss: 0.4540257
EarlyStopping counter: 1 out of 5
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 8.281283140182495
Epoch: 11, Steps: 66 | Train Loss: 0.4566826 Vali Loss: 1.0052842 Test Loss: 0.4527201
EarlyStopping counter: 2 out of 5
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 8.665504932403564
Epoch: 12, Steps: 66 | Train Loss: 0.4527296 Vali Loss: 0.9984193 Test Loss: 0.4518470
Validation loss decreased (1.002515 --> 0.998419).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 8.571525812149048
Epoch: 13, Steps: 66 | Train Loss: 0.4521159 Vali Loss: 1.0622791 Test Loss: 0.4509860
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 8.447218894958496
Epoch: 14, Steps: 66 | Train Loss: 0.4511361 Vali Loss: 0.9935236 Test Loss: 0.4502842
Validation loss decreased (0.998419 --> 0.993524).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 8.763349056243896
Epoch: 15, Steps: 66 | Train Loss: 0.4492425 Vali Loss: 1.0061851 Test Loss: 0.4495343
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 8.601516008377075
Epoch: 16, Steps: 66 | Train Loss: 0.4482534 Vali Loss: 0.9924942 Test Loss: 0.4491921
Validation loss decreased (0.993524 --> 0.992494).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 8.862430572509766
Epoch: 17, Steps: 66 | Train Loss: 0.4488137 Vali Loss: 1.0317314 Test Loss: 0.4488827
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 8.730926752090454
Epoch: 18, Steps: 66 | Train Loss: 0.4481461 Vali Loss: 1.0011777 Test Loss: 0.4486269
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 8.406955003738403
Epoch: 19, Steps: 66 | Train Loss: 0.4469085 Vali Loss: 0.9800287 Test Loss: 0.4484378
Validation loss decreased (0.992494 --> 0.980029).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 8.752166271209717
Epoch: 20, Steps: 66 | Train Loss: 0.4474806 Vali Loss: 0.9985464 Test Loss: 0.4480223
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 6.841256856918335
Epoch: 21, Steps: 66 | Train Loss: 0.4463018 Vali Loss: 1.0073969 Test Loss: 0.4478067
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 6.284305572509766
Epoch: 22, Steps: 66 | Train Loss: 0.4464665 Vali Loss: 1.0531478 Test Loss: 0.4476016
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 8.713321924209595
Epoch: 23, Steps: 66 | Train Loss: 0.4459213 Vali Loss: 1.0730965 Test Loss: 0.4476832
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 9.330400705337524
Epoch: 24, Steps: 66 | Train Loss: 0.4449521 Vali Loss: 0.9978642 Test Loss: 0.4473113
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : 96_192_PatchTST_ETTh1_ftM_sl96_ll48_pl192_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.4480142593383789, mae:0.43636539578437805, rse:0.635628342628479

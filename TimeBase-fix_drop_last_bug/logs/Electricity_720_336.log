Args in experiment:
Namespace(is_training=1, model_id='Electricity_720_336', model='LightTimeBaseTST', data='custom', root_path='./dataset/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=336, period_len=24, basis_num=6, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=321, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.02, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=3, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:3
284
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 2033856.0
Params: 284.0
2.03M MACs
>>>>>>>start training : Electricity_720_336_LightTimeBaseTST_custom_ftM_sl720_pl336_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 2297
test 4925
	iters: 100, epoch: 1 | loss: 0.3010885
	speed: 0.1549s/iter; left time: 616.7336s
Max Memory (MB): 604.44873046875
Epoch: 1 cost time: 20.57385563850403
Epoch: 1, Steps: 136 | Train Loss: 0.2971089 Vali Loss: 0.2346601 Test Loss: 0.2648081
Validation loss decreased (inf --> 0.234660).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 2 | loss: 0.2025055
	speed: 0.3475s/iter; left time: 1336.0772s
Max Memory (MB): 662.7021484375
Epoch: 2 cost time: 21.019731283187866
Epoch: 2, Steps: 136 | Train Loss: 0.2162333 Vali Loss: 0.1583151 Test Loss: 0.1853514
Validation loss decreased (0.234660 --> 0.158315).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 3 | loss: 0.1751234
	speed: 0.3446s/iter; left time: 1277.9506s
Max Memory (MB): 662.7021484375
Epoch: 3 cost time: 20.461883783340454
Epoch: 3, Steps: 136 | Train Loss: 0.1861516 Vali Loss: 0.1508615 Test Loss: 0.1764039
Validation loss decreased (0.158315 --> 0.150861).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 4 | loss: 0.1812687
	speed: 0.3437s/iter; left time: 1228.2123s
Max Memory (MB): 662.7021484375
Epoch: 4 cost time: 20.734187602996826
Epoch: 4, Steps: 136 | Train Loss: 0.1824828 Vali Loss: 0.1497457 Test Loss: 0.1754911
Validation loss decreased (0.150861 --> 0.149746).  Saving model ...
Updating learning rate to 0.016
	iters: 100, epoch: 5 | loss: 0.1758540
	speed: 0.3399s/iter; left time: 1168.1096s
Max Memory (MB): 662.7021484375
Epoch: 5 cost time: 20.77223491668701
Epoch: 5, Steps: 136 | Train Loss: 0.1811650 Vali Loss: 0.1490735 Test Loss: 0.1760700
Validation loss decreased (0.149746 --> 0.149073).  Saving model ...
Updating learning rate to 0.012800000000000002
	iters: 100, epoch: 6 | loss: 0.1876068
	speed: 0.3456s/iter; left time: 1140.9456s
Max Memory (MB): 662.7021484375
Epoch: 6 cost time: 21.037275314331055
Epoch: 6, Steps: 136 | Train Loss: 0.1803018 Vali Loss: 0.1484278 Test Loss: 0.1740302
Validation loss decreased (0.149073 --> 0.148428).  Saving model ...
Updating learning rate to 0.010240000000000003
	iters: 100, epoch: 7 | loss: 0.1710250
	speed: 0.3503s/iter; left time: 1108.6258s
Max Memory (MB): 662.7021484375
Epoch: 7 cost time: 21.426268577575684
Epoch: 7, Steps: 136 | Train Loss: 0.1799448 Vali Loss: 0.1473167 Test Loss: 0.1732736
Validation loss decreased (0.148428 --> 0.147317).  Saving model ...
Updating learning rate to 0.008192000000000001
	iters: 100, epoch: 8 | loss: 0.1863521
	speed: 0.3482s/iter; left time: 1054.6933s
Max Memory (MB): 662.7021484375
Epoch: 8 cost time: 20.89973759651184
Epoch: 8, Steps: 136 | Train Loss: 0.1794092 Vali Loss: 0.1478642 Test Loss: 0.1739799
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0065536000000000014
	iters: 100, epoch: 9 | loss: 0.1764782
	speed: 0.3435s/iter; left time: 993.7640s
Max Memory (MB): 662.7021484375
Epoch: 9 cost time: 20.95508575439453
Epoch: 9, Steps: 136 | Train Loss: 0.1792026 Vali Loss: 0.1479517 Test Loss: 0.1741734
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.005242880000000002
	iters: 100, epoch: 10 | loss: 0.1719882
	speed: 0.3471s/iter; left time: 956.9380s
Max Memory (MB): 662.7021484375
Epoch: 10 cost time: 20.721310138702393
Epoch: 10, Steps: 136 | Train Loss: 0.1789902 Vali Loss: 0.1481165 Test Loss: 0.1732726
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.004194304000000002
	iters: 100, epoch: 11 | loss: 0.1924679
	speed: 0.3462s/iter; left time: 907.4621s
Max Memory (MB): 662.7021484375
Epoch: 11 cost time: 20.635273456573486
Epoch: 11, Steps: 136 | Train Loss: 0.1788860 Vali Loss: 0.1473351 Test Loss: 0.1728846
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.003355443200000002
	iters: 100, epoch: 12 | loss: 0.1900849
	speed: 0.3412s/iter; left time: 847.8169s
Max Memory (MB): 662.7021484375
Epoch: 12 cost time: 20.365674018859863
Epoch: 12, Steps: 136 | Train Loss: 0.1787645 Vali Loss: 0.1469098 Test Loss: 0.1728322
Validation loss decreased (0.147317 --> 0.146910).  Saving model ...
Updating learning rate to 0.002684354560000001
	iters: 100, epoch: 13 | loss: 0.1797831
	speed: 0.3342s/iter; left time: 785.0041s
Max Memory (MB): 662.7021484375
Epoch: 13 cost time: 19.614826440811157
Epoch: 13, Steps: 136 | Train Loss: 0.1786146 Vali Loss: 0.1473470 Test Loss: 0.1726813
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0021474836480000013
	iters: 100, epoch: 14 | loss: 0.1741327
	speed: 0.3270s/iter; left time: 723.7333s
Max Memory (MB): 662.7021484375
Epoch: 14 cost time: 19.636308193206787
Epoch: 14, Steps: 136 | Train Loss: 0.1784624 Vali Loss: 0.1466615 Test Loss: 0.1722082
Validation loss decreased (0.146910 --> 0.146661).  Saving model ...
Updating learning rate to 0.0017179869184000011
	iters: 100, epoch: 15 | loss: 0.1653478
	speed: 0.3278s/iter; left time: 680.7721s
Max Memory (MB): 662.7021484375
Epoch: 15 cost time: 19.456011295318604
Epoch: 15, Steps: 136 | Train Loss: 0.1784475 Vali Loss: 0.1467882 Test Loss: 0.1725457
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0013743895347200009
	iters: 100, epoch: 16 | loss: 0.1749285
	speed: 0.3315s/iter; left time: 643.4357s
Max Memory (MB): 662.7021484375
Epoch: 16 cost time: 19.616631269454956
Epoch: 16, Steps: 136 | Train Loss: 0.1783121 Vali Loss: 0.1467636 Test Loss: 0.1725299
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0010995116277760007
	iters: 100, epoch: 17 | loss: 0.1846203
	speed: 0.3272s/iter; left time: 590.6350s
Max Memory (MB): 662.7021484375
Epoch: 17 cost time: 19.540018796920776
Epoch: 17, Steps: 136 | Train Loss: 0.1782911 Vali Loss: 0.1467946 Test Loss: 0.1726299
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0008796093022208007
	iters: 100, epoch: 18 | loss: 0.1750487
	speed: 0.3319s/iter; left time: 553.8883s
Max Memory (MB): 662.7021484375
Epoch: 18 cost time: 20.178983211517334
Epoch: 18, Steps: 136 | Train Loss: 0.1782467 Vali Loss: 0.1467249 Test Loss: 0.1724271
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0007036874417766406
	iters: 100, epoch: 19 | loss: 0.1715677
	speed: 0.3282s/iter; left time: 503.1508s
Max Memory (MB): 662.7021484375
Epoch: 19 cost time: 19.20364499092102
Epoch: 19, Steps: 136 | Train Loss: 0.1782688 Vali Loss: 0.1466462 Test Loss: 0.1721066
Validation loss decreased (0.146661 --> 0.146646).  Saving model ...
Updating learning rate to 0.0005629499534213125
	iters: 100, epoch: 20 | loss: 0.1672767
	speed: 0.3255s/iter; left time: 454.6541s
Max Memory (MB): 662.7021484375
Epoch: 20 cost time: 19.39105224609375
Epoch: 20, Steps: 136 | Train Loss: 0.1781761 Vali Loss: 0.1466984 Test Loss: 0.1722678
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0004503599627370501
	iters: 100, epoch: 21 | loss: 0.1806697
	speed: 0.3235s/iter; left time: 407.9281s
Max Memory (MB): 662.7021484375
Epoch: 21 cost time: 19.558258295059204
Epoch: 21, Steps: 136 | Train Loss: 0.1781595 Vali Loss: 0.1464790 Test Loss: 0.1721452
Validation loss decreased (0.146646 --> 0.146479).  Saving model ...
Updating learning rate to 0.00036028797018964004
	iters: 100, epoch: 22 | loss: 0.1653027
	speed: 0.3291s/iter; left time: 370.2390s
Max Memory (MB): 662.7021484375
Epoch: 22 cost time: 19.761127948760986
Epoch: 22, Steps: 136 | Train Loss: 0.1780970 Vali Loss: 0.1466665 Test Loss: 0.1721277
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00028823037615171204
	iters: 100, epoch: 23 | loss: 0.1704759
	speed: 0.3289s/iter; left time: 325.2435s
Max Memory (MB): 662.7021484375
Epoch: 23 cost time: 19.27435803413391
Epoch: 23, Steps: 136 | Train Loss: 0.1780867 Vali Loss: 0.1466399 Test Loss: 0.1722402
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00023058430092136968
	iters: 100, epoch: 24 | loss: 0.1668616
	speed: 0.3243s/iter; left time: 276.6226s
Max Memory (MB): 662.7021484375
Epoch: 24 cost time: 19.3583664894104
Epoch: 24, Steps: 136 | Train Loss: 0.1780489 Vali Loss: 0.1464710 Test Loss: 0.1721310
Validation loss decreased (0.146479 --> 0.146471).  Saving model ...
Updating learning rate to 0.00018446744073709575
	iters: 100, epoch: 25 | loss: 0.1766100
	speed: 0.3289s/iter; left time: 235.8185s
Max Memory (MB): 662.7021484375
Epoch: 25 cost time: 19.705403804779053
Epoch: 25, Steps: 136 | Train Loss: 0.1780652 Vali Loss: 0.1464416 Test Loss: 0.1719588
Validation loss decreased (0.146471 --> 0.146442).  Saving model ...
Updating learning rate to 0.0001475739525896766
	iters: 100, epoch: 26 | loss: 0.1630170
	speed: 0.3331s/iter; left time: 193.5596s
Max Memory (MB): 662.7021484375
Epoch: 26 cost time: 20.189295768737793
Epoch: 26, Steps: 136 | Train Loss: 0.1781072 Vali Loss: 0.1466057 Test Loss: 0.1721387
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00011805916207174128
	iters: 100, epoch: 27 | loss: 0.1769343
	speed: 0.3334s/iter; left time: 148.3614s
Max Memory (MB): 662.7021484375
Epoch: 27 cost time: 19.79658603668213
Epoch: 27, Steps: 136 | Train Loss: 0.1780048 Vali Loss: 0.1465314 Test Loss: 0.1721566
EarlyStopping counter: 2 out of 5
Updating learning rate to 9.444732965739304e-05
	iters: 100, epoch: 28 | loss: 0.1865568
	speed: 0.3239s/iter; left time: 100.0872s
Max Memory (MB): 662.7021484375
Epoch: 28 cost time: 19.225823879241943
Epoch: 28, Steps: 136 | Train Loss: 0.1780294 Vali Loss: 0.1464211 Test Loss: 0.1721000
Validation loss decreased (0.146442 --> 0.146421).  Saving model ...
Updating learning rate to 7.555786372591443e-05
	iters: 100, epoch: 29 | loss: 0.1765921
	speed: 0.3214s/iter; left time: 55.5970s
Max Memory (MB): 662.7021484375
Epoch: 29 cost time: 19.1804461479187
Epoch: 29, Steps: 136 | Train Loss: 0.1780219 Vali Loss: 0.1464822 Test Loss: 0.1720899
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.044629098073155e-05
	iters: 100, epoch: 30 | loss: 0.1687100
	speed: 0.3270s/iter; left time: 12.0980s
Max Memory (MB): 662.7021484375
Epoch: 30 cost time: 19.43792963027954
Epoch: 30, Steps: 136 | Train Loss: 0.1780168 Vali Loss: 0.1465098 Test Loss: 0.1721531
EarlyStopping counter: 2 out of 5
Updating learning rate to 4.835703278458524e-05
Final Max Memory (MB): 662.7021484375
>>>>>>>testing : Electricity_720_336_LightTimeBaseTST_custom_ftM_sl720_pl336_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4925
mse:0.16989868879318237, mae:0.26253581047058105, rse:0.4102384150028229

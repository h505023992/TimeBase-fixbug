Args in experiment:
Namespace(is_training=1, model_id='ETTm1_336_720', model='LightTimeBaseTST', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, period_len=6, basis_num=48, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.08, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.05, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:1
8616
>>>>>>>start training : ETTm1_336_720_LightTimeBaseTST_ETTm1_ftM_sl336_pl720_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
Epoch: 1 cost time: 5.156290054321289
Epoch: 1, Steps: 66 | Train Loss: 0.5971150 Vali Loss: 1.3466014 Test Loss: 0.6956446
Validation loss decreased (inf --> 1.346601).  Saving model ...
Updating learning rate to 0.05
Epoch: 2 cost time: 5.40105938911438
Epoch: 2, Steps: 66 | Train Loss: 0.5138872 Vali Loss: 1.0742435 Test Loss: 0.4944178
Validation loss decreased (1.346601 --> 1.074244).  Saving model ...
Updating learning rate to 0.05
Epoch: 3 cost time: 5.490565299987793
Epoch: 3, Steps: 66 | Train Loss: 0.4534563 Vali Loss: 1.0125442 Test Loss: 0.4610566
Validation loss decreased (1.074244 --> 1.012544).  Saving model ...
Updating learning rate to 0.05
Epoch: 4 cost time: 5.6777660846710205
Epoch: 4, Steps: 66 | Train Loss: 0.4460141 Vali Loss: 0.9886763 Test Loss: 0.4520982
Validation loss decreased (1.012544 --> 0.988676).  Saving model ...
Updating learning rate to 0.04000000000000001
Epoch: 5 cost time: 5.510452747344971
Epoch: 5, Steps: 66 | Train Loss: 0.4380542 Vali Loss: 1.0648160 Test Loss: 0.4898159
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.03200000000000001
Epoch: 6 cost time: 5.515823602676392
Epoch: 6, Steps: 66 | Train Loss: 0.4365278 Vali Loss: 0.9935156 Test Loss: 0.4421508
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.025600000000000008
Epoch: 7 cost time: 5.404462814331055
Epoch: 7, Steps: 66 | Train Loss: 0.4292296 Vali Loss: 0.9862513 Test Loss: 0.4423527
Validation loss decreased (0.988676 --> 0.986251).  Saving model ...
Updating learning rate to 0.020480000000000005
Epoch: 8 cost time: 5.464854955673218
Epoch: 8, Steps: 66 | Train Loss: 0.4279264 Vali Loss: 0.9861770 Test Loss: 0.4372039
Validation loss decreased (0.986251 --> 0.986177).  Saving model ...
Updating learning rate to 0.016384000000000006
Epoch: 9 cost time: 5.5714240074157715
Epoch: 9, Steps: 66 | Train Loss: 0.4273359 Vali Loss: 0.9849567 Test Loss: 0.4396493
Validation loss decreased (0.986177 --> 0.984957).  Saving model ...
Updating learning rate to 0.013107200000000006
Epoch: 10 cost time: 5.547101974487305
Epoch: 10, Steps: 66 | Train Loss: 0.4260096 Vali Loss: 0.9846968 Test Loss: 0.4399605
Validation loss decreased (0.984957 --> 0.984697).  Saving model ...
Updating learning rate to 0.010485760000000004
Epoch: 11 cost time: 5.499961853027344
Epoch: 11, Steps: 66 | Train Loss: 0.4255261 Vali Loss: 0.9724218 Test Loss: 0.4405808
Validation loss decreased (0.984697 --> 0.972422).  Saving model ...
Updating learning rate to 0.008388608000000004
Epoch: 12 cost time: 5.521776914596558
Epoch: 12, Steps: 66 | Train Loss: 0.4252456 Vali Loss: 0.9726568 Test Loss: 0.4368098
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.006710886400000004
Epoch: 13 cost time: 5.3529438972473145
Epoch: 13, Steps: 66 | Train Loss: 0.4242289 Vali Loss: 0.9742770 Test Loss: 0.4324659
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.005368709120000003
Epoch: 14 cost time: 5.429671764373779
Epoch: 14, Steps: 66 | Train Loss: 0.4239826 Vali Loss: 0.9733242 Test Loss: 0.4346544
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0042949672960000025
Epoch: 15 cost time: 5.547476291656494
Epoch: 15, Steps: 66 | Train Loss: 0.4235736 Vali Loss: 0.9748331 Test Loss: 0.4353201
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0034359738368000023
Epoch: 16 cost time: 5.551183700561523
Epoch: 16, Steps: 66 | Train Loss: 0.4231294 Vali Loss: 0.9713823 Test Loss: 0.4335181
Validation loss decreased (0.972422 --> 0.971382).  Saving model ...
Updating learning rate to 0.002748779069440002
Epoch: 17 cost time: 5.537337064743042
Epoch: 17, Steps: 66 | Train Loss: 0.4231404 Vali Loss: 0.9690164 Test Loss: 0.4345288
Validation loss decreased (0.971382 --> 0.969016).  Saving model ...
Updating learning rate to 0.002199023255552002
Epoch: 18 cost time: 5.473089218139648
Epoch: 18, Steps: 66 | Train Loss: 0.4226757 Vali Loss: 0.9833456 Test Loss: 0.4318959
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0017592186044416017
Epoch: 19 cost time: 5.597861289978027
Epoch: 19, Steps: 66 | Train Loss: 0.4221412 Vali Loss: 0.9752800 Test Loss: 0.4312290
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0014073748835532812
Epoch: 20 cost time: 5.503024339675903
Epoch: 20, Steps: 66 | Train Loss: 0.4219449 Vali Loss: 0.9735054 Test Loss: 0.4314418
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0011258999068426252
Epoch: 21 cost time: 5.352535009384155
Epoch: 21, Steps: 66 | Train Loss: 0.4222451 Vali Loss: 0.9791172 Test Loss: 0.4307857
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0009007199254741002
Epoch: 22 cost time: 5.263660430908203
Epoch: 22, Steps: 66 | Train Loss: 0.4217438 Vali Loss: 0.9667147 Test Loss: 0.4317417
Validation loss decreased (0.969016 --> 0.966715).  Saving model ...
Updating learning rate to 0.0007205759403792802
Epoch: 23 cost time: 5.134533405303955
Epoch: 23, Steps: 66 | Train Loss: 0.4216830 Vali Loss: 0.9761605 Test Loss: 0.4302674
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0005764607523034242
Epoch: 24 cost time: 5.231608629226685
Epoch: 24, Steps: 66 | Train Loss: 0.4213754 Vali Loss: 0.9612391 Test Loss: 0.4312227
Validation loss decreased (0.966715 --> 0.961239).  Saving model ...
Updating learning rate to 0.00046116860184273935
Epoch: 25 cost time: 5.233270168304443
Epoch: 25, Steps: 66 | Train Loss: 0.4215065 Vali Loss: 0.9725975 Test Loss: 0.4301235
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003689348814741915
Epoch: 26 cost time: 4.3517420291900635
Epoch: 26, Steps: 66 | Train Loss: 0.4214676 Vali Loss: 0.9698847 Test Loss: 0.4303533
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00029514790517935324
Epoch: 27 cost time: 4.148464918136597
Epoch: 27, Steps: 66 | Train Loss: 0.4214627 Vali Loss: 0.9774983 Test Loss: 0.4303007
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002361183241434826
Epoch: 28 cost time: 4.947727203369141
Epoch: 28, Steps: 66 | Train Loss: 0.4215925 Vali Loss: 0.9719133 Test Loss: 0.4305488
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001888946593147861
Epoch: 29 cost time: 5.074709415435791
Epoch: 29, Steps: 66 | Train Loss: 0.4211324 Vali Loss: 0.9789963 Test Loss: 0.4303239
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm1_336_720_LightTimeBaseTST_ETTm1_ftM_sl336_pl720_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.42875179648399353, mae:0.42133867740631104, rse:0.6229794025421143

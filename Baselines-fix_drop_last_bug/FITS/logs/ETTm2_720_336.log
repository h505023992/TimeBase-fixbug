Args in experiment:
Namespace(is_training=1, model_id='ETTm2_720_336', model='FITS', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=196, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=196, out_features=287, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  50401792.0
params:  56539.0
Trainable parameters:  56539
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3257673
	speed: 0.0990s/iter; left time: 765.3318s
	iters: 200, epoch: 1 | loss: 0.2316207
	speed: 0.0835s/iter; left time: 637.5368s
Epoch: 1 cost time: 23.317530870437622
Epoch: 1, Steps: 261 | Train Loss: 0.3185703 Vali Loss: 0.2315541 Test Loss: 0.3104028
Validation loss decreased (inf --> 0.231554).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2304511
	speed: 0.3189s/iter; left time: 2382.1336s
	iters: 200, epoch: 2 | loss: 0.1535720
	speed: 0.0926s/iter; left time: 682.2932s
Epoch: 2 cost time: 22.60949969291687
Epoch: 2, Steps: 261 | Train Loss: 0.2084627 Vali Loss: 0.2174089 Test Loss: 0.2933328
Validation loss decreased (0.231554 --> 0.217409).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1327496
	speed: 0.3521s/iter; left time: 2538.5847s
	iters: 200, epoch: 3 | loss: 0.1533665
	speed: 0.0847s/iter; left time: 602.3401s
Epoch: 3 cost time: 22.512746810913086
Epoch: 3, Steps: 261 | Train Loss: 0.1709995 Vali Loss: 0.2101580 Test Loss: 0.2850051
Validation loss decreased (0.217409 --> 0.210158).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2152896
	speed: 0.3853s/iter; left time: 2676.8334s
	iters: 200, epoch: 4 | loss: 0.1312125
	speed: 0.0832s/iter; left time: 570.0397s
Epoch: 4 cost time: 23.785162448883057
Epoch: 4, Steps: 261 | Train Loss: 0.1512485 Vali Loss: 0.2055933 Test Loss: 0.2797171
Validation loss decreased (0.210158 --> 0.205593).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1022287
	speed: 0.4102s/iter; left time: 2743.0411s
	iters: 200, epoch: 5 | loss: 0.1131638
	speed: 0.0873s/iter; left time: 575.2222s
Epoch: 5 cost time: 24.249300003051758
Epoch: 5, Steps: 261 | Train Loss: 0.1404759 Vali Loss: 0.2020947 Test Loss: 0.2761303
Validation loss decreased (0.205593 --> 0.202095).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1546278
	speed: 0.3844s/iter; left time: 2469.9478s
	iters: 200, epoch: 6 | loss: 0.1206411
	speed: 0.0943s/iter; left time: 596.3791s
Epoch: 6 cost time: 24.011539220809937
Epoch: 6, Steps: 261 | Train Loss: 0.1344125 Vali Loss: 0.1999095 Test Loss: 0.2742232
Validation loss decreased (0.202095 --> 0.199910).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1403027
	speed: 0.3622s/iter; left time: 2233.0256s
	iters: 200, epoch: 7 | loss: 0.1222582
	speed: 0.0711s/iter; left time: 430.9315s
Epoch: 7 cost time: 20.230303287506104
Epoch: 7, Steps: 261 | Train Loss: 0.1308847 Vali Loss: 0.1985249 Test Loss: 0.2731518
Validation loss decreased (0.199910 --> 0.198525).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1260823
	speed: 0.3839s/iter; left time: 2266.6753s
	iters: 200, epoch: 8 | loss: 0.1392776
	speed: 0.0936s/iter; left time: 543.1862s
Epoch: 8 cost time: 25.341403245925903
Epoch: 8, Steps: 261 | Train Loss: 0.1288385 Vali Loss: 0.1975175 Test Loss: 0.2725373
Validation loss decreased (0.198525 --> 0.197518).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1095928
	speed: 0.3884s/iter; left time: 2191.4845s
	iters: 200, epoch: 9 | loss: 0.1306867
	speed: 0.0848s/iter; left time: 470.1981s
Epoch: 9 cost time: 23.146982431411743
Epoch: 9, Steps: 261 | Train Loss: 0.1278306 Vali Loss: 0.1970547 Test Loss: 0.2724132
Validation loss decreased (0.197518 --> 0.197055).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.0864113
	speed: 0.3983s/iter; left time: 2143.8300s
	iters: 200, epoch: 10 | loss: 0.1102727
	speed: 0.0896s/iter; left time: 473.2058s
Epoch: 10 cost time: 25.377491235733032
Epoch: 10, Steps: 261 | Train Loss: 0.1269146 Vali Loss: 0.1963957 Test Loss: 0.2719925
Validation loss decreased (0.197055 --> 0.196396).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.0881464
	speed: 0.3891s/iter; left time: 1992.5846s
	iters: 200, epoch: 11 | loss: 0.1487956
	speed: 0.0875s/iter; left time: 439.1320s
Epoch: 11 cost time: 22.94974136352539
Epoch: 11, Steps: 261 | Train Loss: 0.1266230 Vali Loss: 0.1963894 Test Loss: 0.2720984
Validation loss decreased (0.196396 --> 0.196389).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1160450
	speed: 0.3564s/iter; left time: 1731.9453s
	iters: 200, epoch: 12 | loss: 0.0986785
	speed: 0.0869s/iter; left time: 413.8546s
Epoch: 12 cost time: 23.970248460769653
Epoch: 12, Steps: 261 | Train Loss: 0.1264775 Vali Loss: 0.1961604 Test Loss: 0.2719393
Validation loss decreased (0.196389 --> 0.196160).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1212863
	speed: 0.3868s/iter; left time: 1778.7480s
	iters: 200, epoch: 13 | loss: 0.1519862
	speed: 0.0843s/iter; left time: 379.2561s
Epoch: 13 cost time: 24.264041900634766
Epoch: 13, Steps: 261 | Train Loss: 0.1263621 Vali Loss: 0.1960937 Test Loss: 0.2717785
Validation loss decreased (0.196160 --> 0.196094).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1617415
	speed: 0.3916s/iter; left time: 1698.6423s
	iters: 200, epoch: 14 | loss: 0.1530139
	speed: 0.0887s/iter; left time: 375.8705s
Epoch: 14 cost time: 24.219905376434326
Epoch: 14, Steps: 261 | Train Loss: 0.1262242 Vali Loss: 0.1960890 Test Loss: 0.2718387
Validation loss decreased (0.196094 --> 0.196089).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1546000
	speed: 0.3684s/iter; left time: 1501.9079s
	iters: 200, epoch: 15 | loss: 0.0932461
	speed: 0.0829s/iter; left time: 329.6776s
Epoch: 15 cost time: 21.355446100234985
Epoch: 15, Steps: 261 | Train Loss: 0.1261020 Vali Loss: 0.1960627 Test Loss: 0.2718986
Validation loss decreased (0.196089 --> 0.196063).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1387893
	speed: 0.3480s/iter; left time: 1328.1214s
	iters: 200, epoch: 16 | loss: 0.1122030
	speed: 0.0792s/iter; left time: 294.2519s
Epoch: 16 cost time: 23.372124195098877
Epoch: 16, Steps: 261 | Train Loss: 0.1261478 Vali Loss: 0.1958912 Test Loss: 0.2716967
Validation loss decreased (0.196063 --> 0.195891).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0981665
	speed: 0.3788s/iter; left time: 1346.6950s
	iters: 200, epoch: 17 | loss: 0.1374082
	speed: 0.0930s/iter; left time: 321.3496s
Epoch: 17 cost time: 24.48206090927124
Epoch: 17, Steps: 261 | Train Loss: 0.1260186 Vali Loss: 0.1960243 Test Loss: 0.2717817
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0919848
	speed: 0.3837s/iter; left time: 1263.7889s
	iters: 200, epoch: 18 | loss: 0.1598659
	speed: 0.0871s/iter; left time: 278.2049s
Epoch: 18 cost time: 22.787768125534058
Epoch: 18, Steps: 261 | Train Loss: 0.1260173 Vali Loss: 0.1958847 Test Loss: 0.2717873
Validation loss decreased (0.195891 --> 0.195885).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1459479
	speed: 0.3925s/iter; left time: 1190.3504s
	iters: 200, epoch: 19 | loss: 0.1387628
	speed: 0.0888s/iter; left time: 260.5422s
Epoch: 19 cost time: 25.337729692459106
Epoch: 19, Steps: 261 | Train Loss: 0.1258588 Vali Loss: 0.1956193 Test Loss: 0.2715392
Validation loss decreased (0.195885 --> 0.195619).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1315172
	speed: 0.3506s/iter; left time: 971.8146s
	iters: 200, epoch: 20 | loss: 0.1483752
	speed: 0.0740s/iter; left time: 197.6252s
Epoch: 20 cost time: 21.142788648605347
Epoch: 20, Steps: 261 | Train Loss: 0.1259101 Vali Loss: 0.1958767 Test Loss: 0.2717513
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1567591
	speed: 0.3677s/iter; left time: 923.3078s
	iters: 200, epoch: 21 | loss: 0.1148141
	speed: 0.0835s/iter; left time: 201.3816s
Epoch: 21 cost time: 23.34860849380493
Epoch: 21, Steps: 261 | Train Loss: 0.1259628 Vali Loss: 0.1958556 Test Loss: 0.2716876
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1245305
	speed: 0.3538s/iter; left time: 796.0901s
	iters: 200, epoch: 22 | loss: 0.1158951
	speed: 0.0785s/iter; left time: 168.8111s
Epoch: 22 cost time: 20.605791807174683
Epoch: 22, Steps: 261 | Train Loss: 0.1259502 Vali Loss: 0.1956690 Test Loss: 0.2714459
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0804949
	speed: 0.3736s/iter; left time: 743.1801s
	iters: 200, epoch: 23 | loss: 0.1360109
	speed: 0.0909s/iter; left time: 171.6351s
Epoch: 23 cost time: 24.601173639297485
Epoch: 23, Steps: 261 | Train Loss: 0.1260155 Vali Loss: 0.1956563 Test Loss: 0.2715663
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1143749
	speed: 0.3900s/iter; left time: 673.9227s
	iters: 200, epoch: 24 | loss: 0.1514418
	speed: 0.0822s/iter; left time: 133.7819s
Epoch: 24 cost time: 23.42590570449829
Epoch: 24, Steps: 261 | Train Loss: 0.1259382 Vali Loss: 0.1957378 Test Loss: 0.2715587
EarlyStopping counter: 5 out of 5
Early stopping
train 33505
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=196, out_features=287, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  50401792.0
params:  56539.0
Trainable parameters:  56539
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3878940
	speed: 0.1015s/iter; left time: 784.9563s
	iters: 200, epoch: 1 | loss: 0.3027609
	speed: 0.0809s/iter; left time: 617.5411s
Epoch: 1 cost time: 23.382007122039795
Epoch: 1, Steps: 261 | Train Loss: 0.3792571 Vali Loss: 0.1939217 Test Loss: 0.2706725
Validation loss decreased (inf --> 0.193922).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3360321
	speed: 0.3840s/iter; left time: 2868.7927s
	iters: 200, epoch: 2 | loss: 0.4965850
	speed: 0.0933s/iter; left time: 687.8918s
Epoch: 2 cost time: 23.44802451133728
Epoch: 2, Steps: 261 | Train Loss: 0.3773901 Vali Loss: 0.1933612 Test Loss: 0.2699932
Validation loss decreased (0.193922 --> 0.193361).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4805381
	speed: 0.3352s/iter; left time: 2416.4939s
	iters: 200, epoch: 3 | loss: 0.4156964
	speed: 0.0888s/iter; left time: 631.3045s
Epoch: 3 cost time: 22.36791467666626
Epoch: 3, Steps: 261 | Train Loss: 0.3762045 Vali Loss: 0.1930389 Test Loss: 0.2694683
Validation loss decreased (0.193361 --> 0.193039).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3371150
	speed: 0.3957s/iter; left time: 2749.1910s
	iters: 200, epoch: 4 | loss: 0.3146911
	speed: 0.0929s/iter; left time: 636.3445s
Epoch: 4 cost time: 25.645657062530518
Epoch: 4, Steps: 261 | Train Loss: 0.3752914 Vali Loss: 0.1929923 Test Loss: 0.2692326
Validation loss decreased (0.193039 --> 0.192992).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4113683
	speed: 0.3913s/iter; left time: 2616.3163s
	iters: 200, epoch: 5 | loss: 0.3380955
	speed: 0.0930s/iter; left time: 612.7136s
Epoch: 5 cost time: 23.909848928451538
Epoch: 5, Steps: 261 | Train Loss: 0.3753134 Vali Loss: 0.1930444 Test Loss: 0.2695124
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3985360
	speed: 0.4020s/iter; left time: 2583.2900s
	iters: 200, epoch: 6 | loss: 0.3338850
	speed: 0.0869s/iter; left time: 549.5104s
Epoch: 6 cost time: 24.282756328582764
Epoch: 6, Steps: 261 | Train Loss: 0.3748805 Vali Loss: 0.1927500 Test Loss: 0.2692755
Validation loss decreased (0.192992 --> 0.192750).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3291511
	speed: 0.3864s/iter; left time: 2382.0517s
	iters: 200, epoch: 7 | loss: 0.3186096
	speed: 0.0874s/iter; left time: 530.1782s
Epoch: 7 cost time: 23.986085891723633
Epoch: 7, Steps: 261 | Train Loss: 0.3748141 Vali Loss: 0.1924132 Test Loss: 0.2694091
Validation loss decreased (0.192750 --> 0.192413).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3072084
	speed: 0.3914s/iter; left time: 2310.7089s
	iters: 200, epoch: 8 | loss: 0.3551421
	speed: 0.0967s/iter; left time: 561.0623s
Epoch: 8 cost time: 25.15442991256714
Epoch: 8, Steps: 261 | Train Loss: 0.3742337 Vali Loss: 0.1925728 Test Loss: 0.2690438
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.4661553
	speed: 0.3852s/iter; left time: 2173.8029s
	iters: 200, epoch: 9 | loss: 0.3738585
	speed: 0.0814s/iter; left time: 451.0779s
Epoch: 9 cost time: 23.559240579605103
Epoch: 9, Steps: 261 | Train Loss: 0.3743419 Vali Loss: 0.1928318 Test Loss: 0.2699774
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2479972
	speed: 0.4068s/iter; left time: 2189.2326s
	iters: 200, epoch: 10 | loss: 0.2648608
	speed: 0.0858s/iter; left time: 453.2772s
Epoch: 10 cost time: 23.559281826019287
Epoch: 10, Steps: 261 | Train Loss: 0.3738277 Vali Loss: 0.1922458 Test Loss: 0.2695350
Validation loss decreased (0.192413 --> 0.192246).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3632314
	speed: 0.3838s/iter; left time: 1965.4003s
	iters: 200, epoch: 11 | loss: 0.4604033
	speed: 0.0981s/iter; left time: 492.4811s
Epoch: 11 cost time: 24.826812744140625
Epoch: 11, Steps: 261 | Train Loss: 0.3739993 Vali Loss: 0.1926579 Test Loss: 0.2699262
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3007892
	speed: 0.3969s/iter; left time: 1928.8351s
	iters: 200, epoch: 12 | loss: 0.3780560
	speed: 0.0930s/iter; left time: 442.8475s
Epoch: 12 cost time: 25.342493534088135
Epoch: 12, Steps: 261 | Train Loss: 0.3740307 Vali Loss: 0.1921659 Test Loss: 0.2694540
Validation loss decreased (0.192246 --> 0.192166).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4728743
	speed: 0.3775s/iter; left time: 1735.9889s
	iters: 200, epoch: 13 | loss: 0.4776105
	speed: 0.0880s/iter; left time: 396.1017s
Epoch: 13 cost time: 24.45806121826172
Epoch: 13, Steps: 261 | Train Loss: 0.3738433 Vali Loss: 0.1923640 Test Loss: 0.2694845
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4484070
	speed: 0.4183s/iter; left time: 1814.5189s
	iters: 200, epoch: 14 | loss: 0.3493462
	speed: 0.0711s/iter; left time: 301.1856s
Epoch: 14 cost time: 20.749749660491943
Epoch: 14, Steps: 261 | Train Loss: 0.3732579 Vali Loss: 0.1921638 Test Loss: 0.2692514
Validation loss decreased (0.192166 --> 0.192164).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.3924777
	speed: 0.3368s/iter; left time: 1373.1534s
	iters: 200, epoch: 15 | loss: 0.4422436
	speed: 0.0933s/iter; left time: 371.0929s
Epoch: 15 cost time: 22.84186339378357
Epoch: 15, Steps: 261 | Train Loss: 0.3734550 Vali Loss: 0.1918017 Test Loss: 0.2691449
Validation loss decreased (0.192164 --> 0.191802).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.3249715
	speed: 0.3468s/iter; left time: 1323.4933s
	iters: 200, epoch: 16 | loss: 0.3221656
	speed: 0.0854s/iter; left time: 317.2348s
Epoch: 16 cost time: 22.292497396469116
Epoch: 16, Steps: 261 | Train Loss: 0.3736411 Vali Loss: 0.1922515 Test Loss: 0.2694080
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2837119
	speed: 0.4012s/iter; left time: 1426.2214s
	iters: 200, epoch: 17 | loss: 0.3579927
	speed: 0.0859s/iter; left time: 296.6877s
Epoch: 17 cost time: 23.935221672058105
Epoch: 17, Steps: 261 | Train Loss: 0.3733475 Vali Loss: 0.1919492 Test Loss: 0.2692914
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2839334
	speed: 0.3793s/iter; left time: 1249.3309s
	iters: 200, epoch: 18 | loss: 0.2511226
	speed: 0.0797s/iter; left time: 254.6551s
Epoch: 18 cost time: 23.226619482040405
Epoch: 18, Steps: 261 | Train Loss: 0.3732878 Vali Loss: 0.1920648 Test Loss: 0.2690594
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3736424
	speed: 0.3592s/iter; left time: 1089.5863s
	iters: 200, epoch: 19 | loss: 0.2290578
	speed: 0.0798s/iter; left time: 234.1635s
Epoch: 19 cost time: 22.46760630607605
Epoch: 19, Steps: 261 | Train Loss: 0.3731065 Vali Loss: 0.1921615 Test Loss: 0.2693588
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.3567582
	speed: 0.3758s/iter; left time: 1041.7772s
	iters: 200, epoch: 20 | loss: 0.3509192
	speed: 0.0995s/iter; left time: 265.9590s
Epoch: 20 cost time: 25.115437269210815
Epoch: 20, Steps: 261 | Train Loss: 0.3732119 Vali Loss: 0.1923343 Test Loss: 0.2693790
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm2_720_336_FITS_ETTm2_ftM_sl720_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.27066439628601074, mae:0.3277500231266022, rse:0.4182743430137634, corr:[0.5657981  0.5586394  0.5564981  0.55769086 0.5555405  0.55474204
 0.5557211  0.55492413 0.5537757  0.55408436 0.55402243 0.55305666
 0.5529221  0.5533305  0.55290264 0.55231804 0.5523575  0.5519637
 0.5509027  0.55032897 0.55005264 0.54911613 0.54817754 0.5480962
 0.5480006  0.5471363  0.5463517  0.5462057  0.5459273  0.54512364
 0.5444018  0.54402214 0.5435507  0.54300416 0.54258907 0.5420384
 0.54128784 0.5407204  0.540303   0.5395546  0.5386541  0.5381573
 0.5379249  0.5374253  0.5367045  0.5360144  0.53524023 0.53435856
 0.5337257  0.5333283  0.5325464  0.5313053  0.53037614 0.5301899
 0.52997804 0.52937615 0.5287533  0.52832013 0.5279022  0.5274116
 0.5270029  0.526731   0.526494   0.52640086 0.52650124 0.5265229
 0.52635753 0.52629846 0.52630335 0.5260471  0.52558845 0.5253259
 0.5252888  0.5251373  0.5246358  0.5239936  0.52339345 0.5228883
 0.5223663  0.5218484  0.52132595 0.52081525 0.520203   0.51961505
 0.5191666  0.5186826  0.51811063 0.5176707  0.5173744  0.5170273
 0.51659685 0.5161528  0.5155532  0.5147106  0.51378626 0.51292026
 0.51178837 0.51013947 0.50845814 0.507364   0.5065524  0.5054203
 0.5042853  0.50344586 0.5023948  0.5007325  0.49912933 0.49821067
 0.4975036  0.4966204  0.49592224 0.49555165 0.4950539  0.49411264
 0.49299312 0.4919672  0.49092388 0.48987362 0.488945   0.48803902
 0.4873788  0.48703766 0.4866057  0.48544824 0.48384973 0.48284137
 0.48245013 0.48170432 0.480526   0.4797121  0.47944823 0.4791022
 0.47838092 0.47738138 0.47633365 0.4756263  0.47527292 0.47465673
 0.47350466 0.47270733 0.47284353 0.47286266 0.47189993 0.47054988
 0.469493   0.4684027  0.4674184  0.46712184 0.4670965  0.46617398
 0.464654   0.46396393 0.46406868 0.46391582 0.46346173 0.46315908
 0.46256167 0.46141496 0.4606663  0.46097502 0.46131074 0.46092927
 0.46027038 0.45983154 0.45931154 0.45886913 0.45914194 0.459876
 0.46014017 0.45977205 0.4592828  0.45890227 0.45831034 0.4575881
 0.45720086 0.45701894 0.4565628  0.4558453  0.45541796 0.455488
 0.45517558 0.45376468 0.45167723 0.45029736 0.45035163 0.45080402
 0.45053536 0.44983855 0.44935566 0.44874316 0.44744357 0.445982
 0.44515836 0.44457117 0.44322506 0.441477   0.4403714  0.43978295
 0.43893132 0.43757698 0.4362939  0.43529803 0.4340539  0.43205497
 0.4299518  0.42877406 0.4283659  0.4278201  0.42732477 0.42758268
 0.4277148  0.42626765 0.42365408 0.42232394 0.42291248 0.42305285
 0.4215818  0.41958776 0.41835043 0.4173767  0.41622275 0.4154199
 0.415026   0.4144777  0.41376147 0.41294897 0.41194692 0.41079944
 0.40979916 0.40890253 0.40737423 0.40566376 0.40494505 0.40514597
 0.40495333 0.40436098 0.40424463 0.40426385 0.40330836 0.40171996
 0.40107095 0.40122595 0.4008179  0.39964068 0.39857972 0.39830446
 0.39837375 0.3986502  0.39927348 0.39961344 0.39898995 0.39822865
 0.39909533 0.4009964  0.4013721  0.40000102 0.3990946  0.39956442
 0.3994116  0.39785495 0.39682376 0.39737272 0.3978997  0.39751217
 0.39693418 0.39650044 0.39590904 0.39553744 0.39588657 0.39600316
 0.39532652 0.39506802 0.39560488 0.3954782  0.3941874  0.39369577
 0.39474645 0.39489692 0.39322832 0.39164877 0.3914445  0.39198458
 0.3925333  0.39300293 0.39275518 0.39155596 0.39063376 0.39060095
 0.3904806  0.3896692  0.3884366  0.38696662 0.38513553 0.38363218
 0.3836676  0.38435507 0.38423514 0.38368756 0.38373756 0.38387337
 0.38376895 0.3831954  0.38210398 0.38074452 0.38041186 0.38079157
 0.37998137 0.3779007  0.3774364  0.3792692  0.38055378 0.38034594
 0.37985268 0.3798527  0.37940508 0.37866673 0.37838003 0.37760565
 0.37584025 0.37550443 0.37734187 0.3785526  0.3778432  0.37719417
 0.37749544 0.37750572 0.37710884 0.3769807  0.3766477  0.37544098
 0.37528697 0.3760361  0.37437043 0.3704665  0.37019718 0.3664581 ]

Args in experiment:
Namespace(is_training=1, model_id='ETTm2_96_336', model='LightTimeBaseTST', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, period_len=4, basis_num=40, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=1, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.05, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
31108
>>>>>>>start training : ETTm2_96_336_LightTimeBaseTST_ETTm2_ftM_sl96_pl336_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
Epoch: 1 cost time: 10.44635272026062
Epoch: 1, Steps: 67 | Train Loss: 0.4782474 Vali Loss: 0.2341951 Test Loss: 0.3263758
Validation loss decreased (inf --> 0.234195).  Saving model ...
Updating learning rate to 0.05
Epoch: 2 cost time: 9.32969069480896
Epoch: 2, Steps: 67 | Train Loss: 0.4666510 Vali Loss: 0.2303490 Test Loss: 0.3180647
Validation loss decreased (0.234195 --> 0.230349).  Saving model ...
Updating learning rate to 0.05
Epoch: 3 cost time: 6.88272762298584
Epoch: 3, Steps: 67 | Train Loss: 0.4524434 Vali Loss: 0.2222145 Test Loss: 0.3118350
Validation loss decreased (0.230349 --> 0.222215).  Saving model ...
Updating learning rate to 0.05
Epoch: 4 cost time: 9.580759286880493
Epoch: 4, Steps: 67 | Train Loss: 0.4489162 Vali Loss: 0.2206863 Test Loss: 0.3108035
Validation loss decreased (0.222215 --> 0.220686).  Saving model ...
Updating learning rate to 0.04000000000000001
Epoch: 5 cost time: 8.824119567871094
Epoch: 5, Steps: 67 | Train Loss: 0.4454426 Vali Loss: 0.2257447 Test Loss: 0.3129843
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.03200000000000001
Epoch: 6 cost time: 7.275078058242798
Epoch: 6, Steps: 67 | Train Loss: 0.4432283 Vali Loss: 0.2247591 Test Loss: 0.3118353
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.025600000000000008
Epoch: 7 cost time: 9.048004388809204
Epoch: 7, Steps: 67 | Train Loss: 0.4420732 Vali Loss: 0.2207354 Test Loss: 0.3096097
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.020480000000000005
Epoch: 8 cost time: 9.229114294052124
Epoch: 8, Steps: 67 | Train Loss: 0.4406636 Vali Loss: 0.2210370 Test Loss: 0.3091162
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.016384000000000006
Epoch: 9 cost time: 7.549248933792114
Epoch: 9, Steps: 67 | Train Loss: 0.4400351 Vali Loss: 0.2191745 Test Loss: 0.3067214
Validation loss decreased (0.220686 --> 0.219174).  Saving model ...
Updating learning rate to 0.013107200000000006
Epoch: 10 cost time: 8.168013572692871
Epoch: 10, Steps: 67 | Train Loss: 0.4391741 Vali Loss: 0.2198669 Test Loss: 0.3069434
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.010485760000000004
Epoch: 11 cost time: 7.113967418670654
Epoch: 11, Steps: 67 | Train Loss: 0.4388832 Vali Loss: 0.2204085 Test Loss: 0.3073688
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.008388608000000004
Epoch: 12 cost time: 9.270637035369873
Epoch: 12, Steps: 67 | Train Loss: 0.4383987 Vali Loss: 0.2198476 Test Loss: 0.3074874
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.006710886400000004
Epoch: 13 cost time: 8.790163516998291
Epoch: 13, Steps: 67 | Train Loss: 0.4387833 Vali Loss: 0.2189818 Test Loss: 0.3060547
Validation loss decreased (0.219174 --> 0.218982).  Saving model ...
Updating learning rate to 0.005368709120000003
Epoch: 14 cost time: 7.054062843322754
Epoch: 14, Steps: 67 | Train Loss: 0.4382358 Vali Loss: 0.2189142 Test Loss: 0.3057920
Validation loss decreased (0.218982 --> 0.218914).  Saving model ...
Updating learning rate to 0.0042949672960000025
Epoch: 15 cost time: 8.604304075241089
Epoch: 15, Steps: 67 | Train Loss: 0.4376509 Vali Loss: 0.2184204 Test Loss: 0.3058275
Validation loss decreased (0.218914 --> 0.218420).  Saving model ...
Updating learning rate to 0.0034359738368000023
Epoch: 16 cost time: 9.480735778808594
Epoch: 16, Steps: 67 | Train Loss: 0.4374274 Vali Loss: 0.2187559 Test Loss: 0.3055433
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.002748779069440002
Epoch: 17 cost time: 7.856133937835693
Epoch: 17, Steps: 67 | Train Loss: 0.4370141 Vali Loss: 0.2180224 Test Loss: 0.3049239
Validation loss decreased (0.218420 --> 0.218022).  Saving model ...
Updating learning rate to 0.002199023255552002
Epoch: 18 cost time: 9.574171543121338
Epoch: 18, Steps: 67 | Train Loss: 0.4375247 Vali Loss: 0.2179185 Test Loss: 0.3048641
Validation loss decreased (0.218022 --> 0.217918).  Saving model ...
Updating learning rate to 0.0017592186044416017
Epoch: 19 cost time: 9.374155282974243
Epoch: 19, Steps: 67 | Train Loss: 0.4373991 Vali Loss: 0.2181894 Test Loss: 0.3051773
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0014073748835532812
Epoch: 20 cost time: 6.770843982696533
Epoch: 20, Steps: 67 | Train Loss: 0.4365304 Vali Loss: 0.2187246 Test Loss: 0.3054850
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0011258999068426252
Epoch: 21 cost time: 8.572664260864258
Epoch: 21, Steps: 67 | Train Loss: 0.4363547 Vali Loss: 0.2181737 Test Loss: 0.3048830
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0009007199254741002
Epoch: 22 cost time: 9.227086544036865
Epoch: 22, Steps: 67 | Train Loss: 0.4363261 Vali Loss: 0.2179144 Test Loss: 0.3048619
Validation loss decreased (0.217918 --> 0.217914).  Saving model ...
Updating learning rate to 0.0007205759403792802
Epoch: 23 cost time: 9.560218572616577
Epoch: 23, Steps: 67 | Train Loss: 0.4361030 Vali Loss: 0.2181718 Test Loss: 0.3049594
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0005764607523034242
Epoch: 24 cost time: 8.345296621322632
Epoch: 24, Steps: 67 | Train Loss: 0.4364509 Vali Loss: 0.2178912 Test Loss: 0.3047794
Validation loss decreased (0.217914 --> 0.217891).  Saving model ...
Updating learning rate to 0.00046116860184273935
Epoch: 25 cost time: 6.60491156578064
Epoch: 25, Steps: 67 | Train Loss: 0.4365301 Vali Loss: 0.2179519 Test Loss: 0.3047929
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003689348814741915
Epoch: 26 cost time: 7.200559854507446
Epoch: 26, Steps: 67 | Train Loss: 0.4362985 Vali Loss: 0.2182211 Test Loss: 0.3049309
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00029514790517935324
Epoch: 27 cost time: 7.95496940612793
Epoch: 27, Steps: 67 | Train Loss: 0.4361561 Vali Loss: 0.2181927 Test Loss: 0.3049966
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002361183241434826
Epoch: 28 cost time: 9.884228467941284
Epoch: 28, Steps: 67 | Train Loss: 0.4364203 Vali Loss: 0.2181847 Test Loss: 0.3050123
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001888946593147861
Epoch: 29 cost time: 9.771115779876709
Epoch: 29, Steps: 67 | Train Loss: 0.4362653 Vali Loss: 0.2181574 Test Loss: 0.3049037
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm2_96_336_LightTimeBaseTST_ETTm2_ftM_sl96_pl336_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3054848313331604, mae:0.3407602906227112, rse:0.4464321732521057

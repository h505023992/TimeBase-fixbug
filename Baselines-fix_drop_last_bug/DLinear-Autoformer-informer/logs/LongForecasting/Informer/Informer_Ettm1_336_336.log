Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Informer_ETTm1_336_336', model='Informer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Informer_ETTm1_336_336_Informer_ETTm1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4149835
	speed: 0.3872s/iter; left time: 12273.6976s
	iters: 200, epoch: 1 | loss: 0.4072866
	speed: 0.3565s/iter; left time: 11266.4591s
	iters: 300, epoch: 1 | loss: 0.4664454
	speed: 0.3715s/iter; left time: 11701.6576s
	iters: 400, epoch: 1 | loss: 0.4637761
	speed: 0.3737s/iter; left time: 11733.5180s
	iters: 500, epoch: 1 | loss: 0.3744277
	speed: 0.3898s/iter; left time: 12200.8633s
	iters: 600, epoch: 1 | loss: 0.3904233
	speed: 0.3746s/iter; left time: 11687.4777s
	iters: 700, epoch: 1 | loss: 0.3466633
	speed: 0.3811s/iter; left time: 11851.7602s
	iters: 800, epoch: 1 | loss: 0.2834627
	speed: 0.3545s/iter; left time: 10989.2444s
	iters: 900, epoch: 1 | loss: 0.3217748
	speed: 0.3601s/iter; left time: 11126.6555s
	iters: 1000, epoch: 1 | loss: 0.2854668
	speed: 0.3548s/iter; left time: 10928.1269s
Epoch: 1 cost time: 391.81030082702637
Epoch: 1, Steps: 1060 | Train Loss: 0.3941796 Vali Loss: 1.1818732 Test Loss: 1.5244336
Validation loss decreased (inf --> 1.181873).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2784322
	speed: 2.0660s/iter; left time: 63304.5889s
	iters: 200, epoch: 2 | loss: 0.2865634
	speed: 0.3734s/iter; left time: 11402.6915s
	iters: 300, epoch: 2 | loss: 0.2842034
	speed: 0.3751s/iter; left time: 11419.0700s
	iters: 400, epoch: 2 | loss: 0.2759728
	speed: 0.3635s/iter; left time: 11030.4057s
	iters: 500, epoch: 2 | loss: 0.2709000
	speed: 0.3535s/iter; left time: 10690.6257s
	iters: 600, epoch: 2 | loss: 0.2461842
	speed: 0.3544s/iter; left time: 10681.4271s
	iters: 700, epoch: 2 | loss: 0.2211824
	speed: 0.3662s/iter; left time: 11000.7038s
	iters: 800, epoch: 2 | loss: 0.2233612
	speed: 0.3487s/iter; left time: 10441.5378s
	iters: 900, epoch: 2 | loss: 0.2656476
	speed: 0.3594s/iter; left time: 10726.2801s
	iters: 1000, epoch: 2 | loss: 0.2531817
	speed: 0.3668s/iter; left time: 10908.3421s
Epoch: 2 cost time: 385.39134907722473
Epoch: 2, Steps: 1060 | Train Loss: 0.2632311 Vali Loss: 1.1834856 Test Loss: 1.3604730
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2177911
	speed: 2.0111s/iter; left time: 59489.7683s
	iters: 200, epoch: 3 | loss: 0.2014375
	speed: 0.3970s/iter; left time: 11705.0475s
	iters: 300, epoch: 3 | loss: 0.2288821
	speed: 0.3687s/iter; left time: 10833.0830s
	iters: 400, epoch: 3 | loss: 0.2175790
	speed: 0.3671s/iter; left time: 10748.4933s
	iters: 500, epoch: 3 | loss: 0.2054584
	speed: 0.3597s/iter; left time: 10497.4561s
	iters: 600, epoch: 3 | loss: 0.1984108
	speed: 0.3698s/iter; left time: 10753.8824s
	iters: 700, epoch: 3 | loss: 0.2060556
	speed: 0.3827s/iter; left time: 11090.9649s
	iters: 800, epoch: 3 | loss: 0.1890306
	speed: 0.3542s/iter; left time: 10230.9576s
	iters: 900, epoch: 3 | loss: 0.1896715
	speed: 0.3488s/iter; left time: 10039.2521s
	iters: 1000, epoch: 3 | loss: 0.1858042
	speed: 0.3478s/iter; left time: 9976.3637s
Epoch: 3 cost time: 390.15575790405273
Epoch: 3, Steps: 1060 | Train Loss: 0.2090086 Vali Loss: 1.1933486 Test Loss: 1.4377002
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1689755
	speed: 2.0441s/iter; left time: 58300.6507s
	iters: 200, epoch: 4 | loss: 0.1960048
	speed: 0.3425s/iter; left time: 9734.9375s
	iters: 300, epoch: 4 | loss: 0.1880272
	speed: 0.3513s/iter; left time: 9948.2630s
	iters: 400, epoch: 4 | loss: 0.1774007
	speed: 0.3584s/iter; left time: 10115.5103s
	iters: 500, epoch: 4 | loss: 0.1787083
	speed: 0.3674s/iter; left time: 10332.2332s
	iters: 600, epoch: 4 | loss: 0.1734128
	speed: 0.3583s/iter; left time: 10038.7281s
	iters: 700, epoch: 4 | loss: 0.1892298
	speed: 0.3581s/iter; left time: 9998.9693s
	iters: 800, epoch: 4 | loss: 0.1864492
	speed: 0.3622s/iter; left time: 10076.9661s
	iters: 900, epoch: 4 | loss: 0.1866525
	speed: 0.3674s/iter; left time: 10185.3116s
	iters: 1000, epoch: 4 | loss: 0.1751047
	speed: 0.3781s/iter; left time: 10442.8813s
Epoch: 4 cost time: 382.9159986972809
Epoch: 4, Steps: 1060 | Train Loss: 0.1829841 Vali Loss: 1.2086132 Test Loss: 1.5289985
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Informer_ETTm1_336_336_Informer_ETTm1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:1.5238571166992188, mae:0.9877640604972839

Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='192_720', model='PatchTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=720, fc_dropout=0.3, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:1
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 4623360.0
Params: 293648.0
4.62M MACs
>>>>>>>start training : 192_720_PatchTST_ETTh1_ftM_sl192_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2161
test 2161
Epoch: 1 cost time: 9.132096767425537
Epoch: 1, Steps: 61 | Train Loss: 0.8881014 Vali Loss: 2.0125203 Test Loss: 0.8088758
Validation loss decreased (inf --> 2.012520).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 8.138554334640503
Epoch: 2, Steps: 61 | Train Loss: 0.7915005 Vali Loss: 1.6422129 Test Loss: 0.5527800
Validation loss decreased (2.012520 --> 1.642213).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 7.680016279220581
Epoch: 3, Steps: 61 | Train Loss: 0.6936381 Vali Loss: 1.5651020 Test Loss: 0.4999629
Validation loss decreased (1.642213 --> 1.565102).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 7.916130781173706
Epoch: 4, Steps: 61 | Train Loss: 0.6561822 Vali Loss: 1.5276638 Test Loss: 0.4791702
Validation loss decreased (1.565102 --> 1.527664).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 7.347850799560547
Epoch: 5, Steps: 61 | Train Loss: 0.6355113 Vali Loss: 1.5103190 Test Loss: 0.4701326
Validation loss decreased (1.527664 --> 1.510319).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 6.78684139251709
Epoch: 6, Steps: 61 | Train Loss: 0.6250512 Vali Loss: 1.5003546 Test Loss: 0.4655296
Validation loss decreased (1.510319 --> 1.500355).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 8.087886333465576
Epoch: 7, Steps: 61 | Train Loss: 0.6185269 Vali Loss: 1.4940419 Test Loss: 0.4625809
Validation loss decreased (1.500355 --> 1.494042).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 7.9221532344818115
Epoch: 8, Steps: 61 | Train Loss: 0.6149403 Vali Loss: 1.4904811 Test Loss: 0.4611529
Validation loss decreased (1.494042 --> 1.490481).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 6.560317277908325
Epoch: 9, Steps: 61 | Train Loss: 0.6104167 Vali Loss: 1.4876521 Test Loss: 0.4603913
Validation loss decreased (1.490481 --> 1.487652).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 6.908382177352905
Epoch: 10, Steps: 61 | Train Loss: 0.6087746 Vali Loss: 1.4864708 Test Loss: 0.4601314
Validation loss decreased (1.487652 --> 1.486471).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 6.943265438079834
Epoch: 11, Steps: 61 | Train Loss: 0.6064738 Vali Loss: 1.4859626 Test Loss: 0.4593311
Validation loss decreased (1.486471 --> 1.485963).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 7.565174579620361
Epoch: 12, Steps: 61 | Train Loss: 0.6060315 Vali Loss: 1.4847431 Test Loss: 0.4594975
Validation loss decreased (1.485963 --> 1.484743).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 7.605098247528076
Epoch: 13, Steps: 61 | Train Loss: 0.6043504 Vali Loss: 1.4845828 Test Loss: 0.4594429
Validation loss decreased (1.484743 --> 1.484583).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 7.2510085105896
Epoch: 14, Steps: 61 | Train Loss: 0.6030734 Vali Loss: 1.4850739 Test Loss: 0.4591739
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 7.632244825363159
Epoch: 15, Steps: 61 | Train Loss: 0.6021220 Vali Loss: 1.4850696 Test Loss: 0.4594425
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 7.6948113441467285
Epoch: 16, Steps: 61 | Train Loss: 0.6011295 Vali Loss: 1.4831946 Test Loss: 0.4593404
Validation loss decreased (1.484583 --> 1.483195).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 7.143378257751465
Epoch: 17, Steps: 61 | Train Loss: 0.6011216 Vali Loss: 1.4842902 Test Loss: 0.4593361
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 7.609170198440552
Epoch: 18, Steps: 61 | Train Loss: 0.6005628 Vali Loss: 1.4846640 Test Loss: 0.4596315
EarlyStopping counter: 2 out of 5
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 7.406660318374634
Epoch: 19, Steps: 61 | Train Loss: 0.5997828 Vali Loss: 1.4839044 Test Loss: 0.4594498
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 7.0262815952301025
Epoch: 20, Steps: 61 | Train Loss: 0.5998349 Vali Loss: 1.4837259 Test Loss: 0.4594994
EarlyStopping counter: 4 out of 5
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 7.765760183334351
Epoch: 21, Steps: 61 | Train Loss: 0.5991258 Vali Loss: 1.4833363 Test Loss: 0.4596122
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : 192_720_PatchTST_ETTh1_ftM_sl192_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
mse:0.4584311246871948, mae:0.4646819531917572, rse:0.6481701135635376

Args in experiment:
Namespace(is_training=1, model_id='ETTm2_96_720', model='LightTimeBaseTST', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, period_len=4, basis_num=40, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=1, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.05, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
58660
>>>>>>>start training : ETTm2_96_720_LightTimeBaseTST_ETTm2_ftM_sl96_pl720_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
Epoch: 1 cost time: 8.761211633682251
Epoch: 1, Steps: 66 | Train Loss: 0.6180884 Vali Loss: 0.3085536 Test Loss: 0.4389305
Validation loss decreased (inf --> 0.308554).  Saving model ...
Updating learning rate to 0.05
Epoch: 2 cost time: 10.029133081436157
Epoch: 2, Steps: 66 | Train Loss: 0.6093526 Vali Loss: 0.3012754 Test Loss: 0.4334278
Validation loss decreased (0.308554 --> 0.301275).  Saving model ...
Updating learning rate to 0.05
Epoch: 3 cost time: 8.68477201461792
Epoch: 3, Steps: 66 | Train Loss: 0.5977538 Vali Loss: 0.2976873 Test Loss: 0.4298799
Validation loss decreased (0.301275 --> 0.297687).  Saving model ...
Updating learning rate to 0.05
Epoch: 4 cost time: 9.924794435501099
Epoch: 4, Steps: 66 | Train Loss: 0.5943564 Vali Loss: 0.2913322 Test Loss: 0.4244881
Validation loss decreased (0.297687 --> 0.291332).  Saving model ...
Updating learning rate to 0.04000000000000001
Epoch: 5 cost time: 9.477073192596436
Epoch: 5, Steps: 66 | Train Loss: 0.5902840 Vali Loss: 0.2954695 Test Loss: 0.4253094
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.03200000000000001
Epoch: 6 cost time: 9.956841945648193
Epoch: 6, Steps: 66 | Train Loss: 0.5884240 Vali Loss: 0.2932347 Test Loss: 0.4240622
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.025600000000000008
Epoch: 7 cost time: 8.7559814453125
Epoch: 7, Steps: 66 | Train Loss: 0.5869143 Vali Loss: 0.2933217 Test Loss: 0.4233895
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.020480000000000005
Epoch: 8 cost time: 8.90157961845398
Epoch: 8, Steps: 66 | Train Loss: 0.5866480 Vali Loss: 0.2897567 Test Loss: 0.4223471
Validation loss decreased (0.291332 --> 0.289757).  Saving model ...
Updating learning rate to 0.016384000000000006
Epoch: 9 cost time: 9.088733673095703
Epoch: 9, Steps: 66 | Train Loss: 0.5850552 Vali Loss: 0.2910430 Test Loss: 0.4231488
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.013107200000000006
Epoch: 10 cost time: 8.570270299911499
Epoch: 10, Steps: 66 | Train Loss: 0.5844899 Vali Loss: 0.2893567 Test Loss: 0.4220037
Validation loss decreased (0.289757 --> 0.289357).  Saving model ...
Updating learning rate to 0.010485760000000004
Epoch: 11 cost time: 8.47824215888977
Epoch: 11, Steps: 66 | Train Loss: 0.5835332 Vali Loss: 0.2922975 Test Loss: 0.4212458
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.008388608000000004
Epoch: 12 cost time: 9.33902907371521
Epoch: 12, Steps: 66 | Train Loss: 0.5832066 Vali Loss: 0.2924781 Test Loss: 0.4221549
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.006710886400000004
Epoch: 13 cost time: 10.043739795684814
Epoch: 13, Steps: 66 | Train Loss: 0.5826558 Vali Loss: 0.2897417 Test Loss: 0.4213661
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.005368709120000003
Epoch: 14 cost time: 9.722794771194458
Epoch: 14, Steps: 66 | Train Loss: 0.5824185 Vali Loss: 0.2923986 Test Loss: 0.4201827
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0042949672960000025
Epoch: 15 cost time: 7.819977045059204
Epoch: 15, Steps: 66 | Train Loss: 0.5825504 Vali Loss: 0.2886615 Test Loss: 0.4210816
Validation loss decreased (0.289357 --> 0.288662).  Saving model ...
Updating learning rate to 0.0034359738368000023
Epoch: 16 cost time: 10.816647291183472
Epoch: 16, Steps: 66 | Train Loss: 0.5821101 Vali Loss: 0.2894267 Test Loss: 0.4211312
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.002748779069440002
Epoch: 17 cost time: 9.752721548080444
Epoch: 17, Steps: 66 | Train Loss: 0.5820686 Vali Loss: 0.2890949 Test Loss: 0.4212219
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.002199023255552002
Epoch: 18 cost time: 8.612399578094482
Epoch: 18, Steps: 66 | Train Loss: 0.5820431 Vali Loss: 0.2913490 Test Loss: 0.4211183
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0017592186044416017
Epoch: 19 cost time: 8.059266567230225
Epoch: 19, Steps: 66 | Train Loss: 0.5816347 Vali Loss: 0.2899597 Test Loss: 0.4207066
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0014073748835532812
Epoch: 20 cost time: 8.995014190673828
Epoch: 20, Steps: 66 | Train Loss: 0.5815849 Vali Loss: 0.2883994 Test Loss: 0.4214930
Validation loss decreased (0.288662 --> 0.288399).  Saving model ...
Updating learning rate to 0.0011258999068426252
Epoch: 21 cost time: 10.116565942764282
Epoch: 21, Steps: 66 | Train Loss: 0.5814597 Vali Loss: 0.2907194 Test Loss: 0.4206412
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0009007199254741002
Epoch: 22 cost time: 10.549894571304321
Epoch: 22, Steps: 66 | Train Loss: 0.5816102 Vali Loss: 0.2895055 Test Loss: 0.4205436
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0007205759403792802
Epoch: 23 cost time: 10.644519329071045
Epoch: 23, Steps: 66 | Train Loss: 0.5813662 Vali Loss: 0.2895893 Test Loss: 0.4204589
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0005764607523034242
Epoch: 24 cost time: 9.956642389297485
Epoch: 24, Steps: 66 | Train Loss: 0.5813944 Vali Loss: 0.2869704 Test Loss: 0.4208920
Validation loss decreased (0.288399 --> 0.286970).  Saving model ...
Updating learning rate to 0.00046116860184273935
Epoch: 25 cost time: 9.081933498382568
Epoch: 25, Steps: 66 | Train Loss: 0.5812337 Vali Loss: 0.2901574 Test Loss: 0.4204612
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003689348814741915
Epoch: 26 cost time: 9.960756063461304
Epoch: 26, Steps: 66 | Train Loss: 0.5812744 Vali Loss: 0.2910644 Test Loss: 0.4203327
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00029514790517935324
Epoch: 27 cost time: 8.587406396865845
Epoch: 27, Steps: 66 | Train Loss: 0.5811514 Vali Loss: 0.2914962 Test Loss: 0.4204940
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002361183241434826
Epoch: 28 cost time: 9.430455446243286
Epoch: 28, Steps: 66 | Train Loss: 0.5812235 Vali Loss: 0.2900079 Test Loss: 0.4204957
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001888946593147861
Epoch: 29 cost time: 9.249072551727295
Epoch: 29, Steps: 66 | Train Loss: 0.5810017 Vali Loss: 0.2923416 Test Loss: 0.4205295
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm2_96_720_LightTimeBaseTST_ETTm2_ftM_sl96_pl720_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.4066890776157379, mae:0.39775729179382324, rse:0.5125965476036072

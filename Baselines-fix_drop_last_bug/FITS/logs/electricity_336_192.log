Args in experiment:
Namespace(is_training=1, model_id='electricity_336_192', model='FITS', data='custom', root_path='./dataset/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=321, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=130, base_T=24, H_order=8)
Use GPU: cuda:0
>>>>>>>start training : electricity_336_192_FITS_custom_ftM_sl336_ll48_pl192_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17885
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=130, out_features=204, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1089653760.0
params:  26724.0
Trainable parameters:  26724
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8334453
	speed: 0.2132s/iter; left time: 867.7682s
Epoch: 1 cost time: 29.117552042007446
Epoch: 1, Steps: 139 | Train Loss: 0.9544497 Vali Loss: 0.6892066 Test Loss: 0.7930305
Validation loss decreased (inf --> 0.689207).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6740947
	speed: 0.4972s/iter; left time: 1954.9474s
Epoch: 2 cost time: 30.228593111038208
Epoch: 2, Steps: 139 | Train Loss: 0.6842565 Vali Loss: 0.5966992 Test Loss: 0.6887615
Validation loss decreased (0.689207 --> 0.596699).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5640045
	speed: 0.5180s/iter; left time: 1964.7643s
Epoch: 3 cost time: 30.666227340698242
Epoch: 3, Steps: 139 | Train Loss: 0.5839993 Vali Loss: 0.5345833 Test Loss: 0.6186168
Validation loss decreased (0.596699 --> 0.534583).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4907373
	speed: 0.5105s/iter; left time: 1865.1884s
Epoch: 4 cost time: 30.447280883789062
Epoch: 4, Steps: 139 | Train Loss: 0.5080884 Vali Loss: 0.4788507 Test Loss: 0.5560282
Validation loss decreased (0.534583 --> 0.478851).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.4368188
	speed: 0.5085s/iter; left time: 1787.2418s
Epoch: 5 cost time: 30.262024879455566
Epoch: 5, Steps: 139 | Train Loss: 0.4448767 Vali Loss: 0.4301091 Test Loss: 0.5011294
Validation loss decreased (0.478851 --> 0.430109).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3846258
	speed: 0.5166s/iter; left time: 1744.0570s
Epoch: 6 cost time: 31.140933752059937
Epoch: 6, Steps: 139 | Train Loss: 0.3917785 Vali Loss: 0.3909291 Test Loss: 0.4569404
Validation loss decreased (0.430109 --> 0.390929).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3405908
	speed: 0.5175s/iter; left time: 1675.1933s
Epoch: 7 cost time: 31.69123339653015
Epoch: 7, Steps: 139 | Train Loss: 0.3468907 Vali Loss: 0.3564418 Test Loss: 0.4180410
Validation loss decreased (0.390929 --> 0.356442).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3039837
	speed: 0.5232s/iter; left time: 1620.9615s
Epoch: 8 cost time: 31.823049306869507
Epoch: 8, Steps: 139 | Train Loss: 0.3086659 Vali Loss: 0.3262801 Test Loss: 0.3839895
Validation loss decreased (0.356442 --> 0.326280).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2703001
	speed: 0.5196s/iter; left time: 1537.6433s
Epoch: 9 cost time: 31.73336625099182
Epoch: 9, Steps: 139 | Train Loss: 0.2761378 Vali Loss: 0.3010495 Test Loss: 0.3554184
Validation loss decreased (0.326280 --> 0.301049).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2392514
	speed: 0.5205s/iter; left time: 1467.8396s
Epoch: 10 cost time: 30.786191701889038
Epoch: 10, Steps: 139 | Train Loss: 0.2482908 Vali Loss: 0.2785779 Test Loss: 0.3298575
Validation loss decreased (0.301049 --> 0.278578).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2176215
	speed: 0.5091s/iter; left time: 1364.8044s
Epoch: 11 cost time: 31.074954509735107
Epoch: 11, Steps: 139 | Train Loss: 0.2243458 Vali Loss: 0.2601865 Test Loss: 0.3089834
Validation loss decreased (0.278578 --> 0.260186).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1963531
	speed: 0.5206s/iter; left time: 1323.3223s
Epoch: 12 cost time: 31.273635625839233
Epoch: 12, Steps: 139 | Train Loss: 0.2036873 Vali Loss: 0.2438694 Test Loss: 0.2902386
Validation loss decreased (0.260186 --> 0.243869).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1831497
	speed: 0.5087s/iter; left time: 1222.3337s
Epoch: 13 cost time: 30.98423671722412
Epoch: 13, Steps: 139 | Train Loss: 0.1858778 Vali Loss: 0.2302319 Test Loss: 0.2746428
Validation loss decreased (0.243869 --> 0.230232).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1677364
	speed: 0.5164s/iter; left time: 1169.2249s
Epoch: 14 cost time: 31.370609045028687
Epoch: 14, Steps: 139 | Train Loss: 0.1704655 Vali Loss: 0.2175001 Test Loss: 0.2599863
Validation loss decreased (0.230232 --> 0.217500).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1578300
	speed: 0.5129s/iter; left time: 1089.9738s
Epoch: 15 cost time: 29.982866764068604
Epoch: 15, Steps: 139 | Train Loss: 0.1571066 Vali Loss: 0.2074600 Test Loss: 0.2483895
Validation loss decreased (0.217500 --> 0.207460).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1459039
	speed: 0.4791s/iter; left time: 951.4625s
Epoch: 16 cost time: 28.89749002456665
Epoch: 16, Steps: 139 | Train Loss: 0.1454993 Vali Loss: 0.1986208 Test Loss: 0.2382419
Validation loss decreased (0.207460 --> 0.198621).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1317100
	speed: 0.4822s/iter; left time: 890.6171s
Epoch: 17 cost time: 28.656084060668945
Epoch: 17, Steps: 139 | Train Loss: 0.1353778 Vali Loss: 0.1902959 Test Loss: 0.2284555
Validation loss decreased (0.198621 --> 0.190296).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1243425
	speed: 0.4741s/iter; left time: 809.6985s
Epoch: 18 cost time: 28.057494640350342
Epoch: 18, Steps: 139 | Train Loss: 0.1265868 Vali Loss: 0.1835057 Test Loss: 0.2206000
Validation loss decreased (0.190296 --> 0.183506).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1146783
	speed: 0.4772s/iter; left time: 748.6931s
Epoch: 19 cost time: 28.314555168151855
Epoch: 19, Steps: 139 | Train Loss: 0.1188934 Vali Loss: 0.1774006 Test Loss: 0.2134607
Validation loss decreased (0.183506 --> 0.177401).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1082498
	speed: 0.4661s/iter; left time: 666.5138s
Epoch: 20 cost time: 27.493817806243896
Epoch: 20, Steps: 139 | Train Loss: 0.1121347 Vali Loss: 0.1721056 Test Loss: 0.2072738
Validation loss decreased (0.177401 --> 0.172106).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1037287
	speed: 0.4797s/iter; left time: 619.3212s
Epoch: 21 cost time: 29.025055170059204
Epoch: 21, Steps: 139 | Train Loss: 0.1062305 Vali Loss: 0.1673802 Test Loss: 0.2016772
Validation loss decreased (0.172106 --> 0.167380).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0996464
	speed: 0.4811s/iter; left time: 554.2051s
Epoch: 22 cost time: 29.22035312652588
Epoch: 22, Steps: 139 | Train Loss: 0.1010587 Vali Loss: 0.1632758 Test Loss: 0.1967128
Validation loss decreased (0.167380 --> 0.163276).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0917356
	speed: 0.4915s/iter; left time: 497.9377s
Epoch: 23 cost time: 29.97861385345459
Epoch: 23, Steps: 139 | Train Loss: 0.0965303 Vali Loss: 0.1597767 Test Loss: 0.1925673
Validation loss decreased (0.163276 --> 0.159777).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0885412
	speed: 0.4911s/iter; left time: 429.1867s
Epoch: 24 cost time: 29.520321369171143
Epoch: 24, Steps: 139 | Train Loss: 0.0925634 Vali Loss: 0.1567136 Test Loss: 0.1889953
Validation loss decreased (0.159777 --> 0.156714).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0889385
	speed: 0.5061s/iter; left time: 371.9752s
Epoch: 25 cost time: 30.69062352180481
Epoch: 25, Steps: 139 | Train Loss: 0.0890491 Vali Loss: 0.1542328 Test Loss: 0.1859205
Validation loss decreased (0.156714 --> 0.154233).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0878837
	speed: 0.5118s/iter; left time: 305.0301s
Epoch: 26 cost time: 30.829171419143677
Epoch: 26, Steps: 139 | Train Loss: 0.0859541 Vali Loss: 0.1519499 Test Loss: 0.1831847
Validation loss decreased (0.154233 --> 0.151950).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0854117
	speed: 0.5001s/iter; left time: 228.5625s
Epoch: 27 cost time: 30.125401735305786
Epoch: 27, Steps: 139 | Train Loss: 0.0832314 Vali Loss: 0.1497325 Test Loss: 0.1804651
Validation loss decreased (0.151950 --> 0.149732).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0826136
	speed: 0.4989s/iter; left time: 158.6589s
Epoch: 28 cost time: 29.685749053955078
Epoch: 28, Steps: 139 | Train Loss: 0.0808569 Vali Loss: 0.1476755 Test Loss: 0.1780401
Validation loss decreased (0.149732 --> 0.147676).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0765852
	speed: 0.4801s/iter; left time: 85.9348s
Epoch: 29 cost time: 28.155934810638428
Epoch: 29, Steps: 139 | Train Loss: 0.0787316 Vali Loss: 0.1461205 Test Loss: 0.1761060
Validation loss decreased (0.147676 --> 0.146120).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0753402
	speed: 0.5006s/iter; left time: 20.0246s
Epoch: 30 cost time: 30.496983528137207
Epoch: 30, Steps: 139 | Train Loss: 0.0768655 Vali Loss: 0.1446559 Test Loss: 0.1743590
Validation loss decreased (0.146120 --> 0.144656).  Saving model ...
Updating learning rate to 0.00011296777049628277
train 17885
val 2441
test 5069
Model(
  (freq_upsampler): Linear(in_features=130, out_features=204, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  1089653760.0
params:  26724.0
Trainable parameters:  26724
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.1551605
	speed: 0.2092s/iter; left time: 851.5826s
Epoch: 1 cost time: 29.12711262702942
Epoch: 1, Steps: 139 | Train Loss: 0.1610975 Vali Loss: 0.1341971 Test Loss: 0.1598568
Validation loss decreased (inf --> 0.134197).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1556298
	speed: 0.5146s/iter; left time: 2023.4173s
Epoch: 2 cost time: 31.131407976150513
Epoch: 2, Steps: 139 | Train Loss: 0.1589380 Vali Loss: 0.1340644 Test Loss: 0.1596863
Validation loss decreased (0.134197 --> 0.134064).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1687584
	speed: 0.5029s/iter; left time: 1907.5012s
Epoch: 3 cost time: 29.609419107437134
Epoch: 3, Steps: 139 | Train Loss: 0.1588612 Vali Loss: 0.1340368 Test Loss: 0.1596687
Validation loss decreased (0.134064 --> 0.134037).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1718521
	speed: 0.4905s/iter; left time: 1792.2646s
Epoch: 4 cost time: 29.807345628738403
Epoch: 4, Steps: 139 | Train Loss: 0.1587539 Vali Loss: 0.1340112 Test Loss: 0.1596584
Validation loss decreased (0.134037 --> 0.134011).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1671824
	speed: 0.4961s/iter; left time: 1743.9475s
Epoch: 5 cost time: 30.03659224510193
Epoch: 5, Steps: 139 | Train Loss: 0.1587876 Vali Loss: 0.1340845 Test Loss: 0.1596175
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1655535
	speed: 0.5063s/iter; left time: 1709.4213s
Epoch: 6 cost time: 30.28494143486023
Epoch: 6, Steps: 139 | Train Loss: 0.1586457 Vali Loss: 0.1339875 Test Loss: 0.1595605
Validation loss decreased (0.134011 --> 0.133987).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1584496
	speed: 0.5023s/iter; left time: 1625.9167s
Epoch: 7 cost time: 30.15967583656311
Epoch: 7, Steps: 139 | Train Loss: 0.1587250 Vali Loss: 0.1338848 Test Loss: 0.1595509
Validation loss decreased (0.133987 --> 0.133885).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1686804
	speed: 0.5021s/iter; left time: 1555.4311s
Epoch: 8 cost time: 30.111804008483887
Epoch: 8, Steps: 139 | Train Loss: 0.1587113 Vali Loss: 0.1339292 Test Loss: 0.1595446
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1623708
	speed: 0.5112s/iter; left time: 1512.6555s
Epoch: 9 cost time: 30.068750143051147
Epoch: 9, Steps: 139 | Train Loss: 0.1586834 Vali Loss: 0.1338823 Test Loss: 0.1595465
Validation loss decreased (0.133885 --> 0.133882).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1596888
	speed: 0.4995s/iter; left time: 1408.6800s
Epoch: 10 cost time: 29.687692403793335
Epoch: 10, Steps: 139 | Train Loss: 0.1586862 Vali Loss: 0.1339170 Test Loss: 0.1595621
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1559391
	speed: 0.4888s/iter; left time: 1310.5782s
Epoch: 11 cost time: 28.05225682258606
Epoch: 11, Steps: 139 | Train Loss: 0.1586345 Vali Loss: 0.1338750 Test Loss: 0.1594855
Validation loss decreased (0.133882 --> 0.133875).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1571549
	speed: 0.4953s/iter; left time: 1258.9692s
Epoch: 12 cost time: 29.663018703460693
Epoch: 12, Steps: 139 | Train Loss: 0.1586094 Vali Loss: 0.1339199 Test Loss: 0.1595279
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1570062
	speed: 0.5010s/iter; left time: 1204.0047s
Epoch: 13 cost time: 29.847747802734375
Epoch: 13, Steps: 139 | Train Loss: 0.1587115 Vali Loss: 0.1338434 Test Loss: 0.1594981
Validation loss decreased (0.133875 --> 0.133843).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1646586
	speed: 0.4981s/iter; left time: 1127.6150s
Epoch: 14 cost time: 29.84174132347107
Epoch: 14, Steps: 139 | Train Loss: 0.1586074 Vali Loss: 0.1338907 Test Loss: 0.1595375
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1626375
	speed: 0.5105s/iter; left time: 1084.8662s
Epoch: 15 cost time: 29.55970573425293
Epoch: 15, Steps: 139 | Train Loss: 0.1586305 Vali Loss: 0.1339621 Test Loss: 0.1595068
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1546132
	speed: 0.5056s/iter; left time: 1004.1160s
Epoch: 16 cost time: 29.61371374130249
Epoch: 16, Steps: 139 | Train Loss: 0.1586441 Vali Loss: 0.1339121 Test Loss: 0.1594840
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1600597
	speed: 0.5249s/iter; left time: 969.5494s
Epoch: 17 cost time: 29.86669659614563
Epoch: 17, Steps: 139 | Train Loss: 0.1586359 Vali Loss: 0.1338353 Test Loss: 0.1594898
Validation loss decreased (0.133843 --> 0.133835).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1553817
	speed: 0.4990s/iter; left time: 852.2830s
Epoch: 18 cost time: 30.212128400802612
Epoch: 18, Steps: 139 | Train Loss: 0.1586187 Vali Loss: 0.1338337 Test Loss: 0.1595266
Validation loss decreased (0.133835 --> 0.133834).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1536407
	speed: 0.5166s/iter; left time: 810.5413s
Epoch: 19 cost time: 29.786522150039673
Epoch: 19, Steps: 139 | Train Loss: 0.1585911 Vali Loss: 0.1338696 Test Loss: 0.1595202
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1546321
	speed: 0.5080s/iter; left time: 726.3687s
Epoch: 20 cost time: 30.03075885772705
Epoch: 20, Steps: 139 | Train Loss: 0.1585698 Vali Loss: 0.1338489 Test Loss: 0.1594426
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1566786
	speed: 0.5029s/iter; left time: 649.2935s
Epoch: 21 cost time: 29.376864194869995
Epoch: 21, Steps: 139 | Train Loss: 0.1586414 Vali Loss: 0.1338416 Test Loss: 0.1594772
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1537510
	speed: 0.4959s/iter; left time: 571.2984s
Epoch: 22 cost time: 30.961889505386353
Epoch: 22, Steps: 139 | Train Loss: 0.1585972 Vali Loss: 0.1337844 Test Loss: 0.1594609
Validation loss decreased (0.133834 --> 0.133784).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.1606448
	speed: 0.5160s/iter; left time: 522.7087s
Epoch: 23 cost time: 30.99303436279297
Epoch: 23, Steps: 139 | Train Loss: 0.1586181 Vali Loss: 0.1338748 Test Loss: 0.1594563
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.1536784
	speed: 0.5178s/iter; left time: 452.5367s
Epoch: 24 cost time: 30.55443525314331
Epoch: 24, Steps: 139 | Train Loss: 0.1585799 Vali Loss: 0.1338215 Test Loss: 0.1594424
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.1545637
	speed: 0.5105s/iter; left time: 375.2133s
Epoch: 25 cost time: 29.647162675857544
Epoch: 25, Steps: 139 | Train Loss: 0.1585803 Vali Loss: 0.1339246 Test Loss: 0.1594507
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1617603
	speed: 0.5294s/iter; left time: 315.4970s
Epoch: 26 cost time: 30.870139122009277
Epoch: 26, Steps: 139 | Train Loss: 0.1585342 Vali Loss: 0.1339134 Test Loss: 0.1594540
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1480343
	speed: 0.5140s/iter; left time: 234.8810s
Epoch: 27 cost time: 30.10898232460022
Epoch: 27, Steps: 139 | Train Loss: 0.1585929 Vali Loss: 0.1339204 Test Loss: 0.1594678
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : electricity_336_192_FITS_custom_ftM_sl336_ll48_pl192_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5069
mse:0.15666106343269348, mae:0.25182920694351196, rse:0.3935345709323883, corr:[0.4627038  0.46592447 0.4670999  0.46728298 0.4675643  0.4673961
 0.4675953  0.46754813 0.46723384 0.46717975 0.4669434  0.46687242
 0.46680206 0.46674526 0.4667507  0.46661785 0.46664664 0.4666204
 0.46647376 0.4662827  0.46601203 0.46597156 0.46600172 0.46616912
 0.46647048 0.4665961  0.46667662 0.46664122 0.46654806 0.46650615
 0.46637657 0.46625495 0.46609905 0.4659524  0.46583667 0.46567306
 0.46562025 0.4655259  0.4653746  0.4653145  0.46516392 0.46500668
 0.46491447 0.46472338 0.4645522  0.46452484 0.46459246 0.46469566
 0.46472675 0.46482143 0.46488452 0.46486533 0.4648671  0.46478638
 0.46470848 0.4646334  0.46449396 0.4644084  0.46434474 0.46430987
 0.4643443  0.46435603 0.46439406 0.46437746 0.4643044  0.46426046
 0.46417305 0.46401078 0.46385044 0.46378642 0.46376517 0.46384817
 0.4639748  0.46397844 0.46394598 0.46399266 0.46395212 0.46386644
 0.46381918 0.463727   0.46363238 0.46356663 0.46354964 0.4635562
 0.4635794  0.46361697 0.46356434 0.46354446 0.46356723 0.46351174
 0.46345282 0.46328533 0.46305975 0.4630538  0.4630894  0.4630826
 0.4632108  0.4633982  0.46338123 0.4632514  0.46326315 0.4632849
 0.46321654 0.4631349  0.4629761  0.4628726  0.46283376 0.4628059
 0.46287283 0.46285388 0.46280771 0.4628837  0.46287572 0.4628731
 0.46296504 0.4629754  0.4629462  0.46295932 0.46298626 0.4630616
 0.46320045 0.46338075 0.46343538 0.4633969  0.46338832 0.46335268
 0.46328327 0.4631746  0.46311045 0.46306068 0.46294516 0.46298233
 0.4630501  0.46297312 0.46296164 0.46297932 0.46299028 0.46306378
 0.46306214 0.46291706 0.46274662 0.46272045 0.46273082 0.4628175
 0.4630268  0.46317753 0.46323946 0.4632412  0.46325025 0.4632806
 0.46315166 0.4630246  0.46304023 0.46298888 0.46294707 0.4629003
 0.46280542 0.4627645  0.46274707 0.46279207 0.46284705 0.4628855
 0.46294942 0.46273082 0.46247542 0.4625548  0.46252584 0.46273956
 0.46308696 0.4631626  0.46315292 0.46308464 0.46297348 0.4628638
 0.46277937 0.4626216  0.46242678 0.46233764 0.46218726 0.46210766
 0.46211427 0.46194476 0.4619706  0.46198204 0.46182844 0.46191025
 0.4617118  0.46150392 0.46137118 0.46133116 0.4614119  0.4617401 ]

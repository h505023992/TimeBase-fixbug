Args in experiment:
Namespace(is_training=1, model_id='ETTh2_720_720', model='SparseTSF', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=720, period_len=24, basis_num=6, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.03, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
model的参数数量: 925
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 277200.0
Params: 925.0
277200.0 MACs
>>>>>>>start training : ETTh2_720_720_SparseTSF_ETTh2_ftM_sl720_pl720_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7201
val 2161
test 2161
Max Memory (MB): 60.7333984375
Epoch: 1 cost time: 1.2852611541748047
Epoch: 1, Steps: 28 | Train Loss: 0.9905000 Vali Loss: 0.7910372 Test Loss: 0.4259121
Validation loss decreased (inf --> 0.791037).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 67.4150390625
Epoch: 2 cost time: 1.0656263828277588
Epoch: 2, Steps: 28 | Train Loss: 0.9492077 Vali Loss: 0.7024339 Test Loss: 0.3976691
Validation loss decreased (0.791037 --> 0.702434).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 67.4150390625
Epoch: 3 cost time: 1.1367874145507812
Epoch: 3, Steps: 28 | Train Loss: 0.8526910 Vali Loss: 0.6499968 Test Loss: 0.3823419
Validation loss decreased (0.702434 --> 0.649997).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 67.4150390625
Epoch: 4 cost time: 1.078798770904541
Epoch: 4, Steps: 28 | Train Loss: 0.8230366 Vali Loss: 0.6464936 Test Loss: 0.3722364
Validation loss decreased (0.649997 --> 0.646494).  Saving model ...
Updating learning rate to 0.024
Max Memory (MB): 67.4150390625
Epoch: 5 cost time: 1.0961816310882568
Epoch: 5, Steps: 28 | Train Loss: 0.8149160 Vali Loss: 0.6512380 Test Loss: 0.3698395
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.019200000000000002
Max Memory (MB): 67.4150390625
Epoch: 6 cost time: 1.068542718887329
Epoch: 6, Steps: 28 | Train Loss: 0.8113116 Vali Loss: 0.6467265 Test Loss: 0.3694111
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.015360000000000004
Max Memory (MB): 67.4150390625
Epoch: 7 cost time: 1.2272870540618896
Epoch: 7, Steps: 28 | Train Loss: 0.8097684 Vali Loss: 0.6451265 Test Loss: 0.3695736
Validation loss decreased (0.646494 --> 0.645126).  Saving model ...
Updating learning rate to 0.012288000000000002
Max Memory (MB): 67.4150390625
Epoch: 8 cost time: 1.1010854244232178
Epoch: 8, Steps: 28 | Train Loss: 0.8082745 Vali Loss: 0.6462705 Test Loss: 0.3670917
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.009830400000000001
Max Memory (MB): 67.4150390625
Epoch: 9 cost time: 1.2918384075164795
Epoch: 9, Steps: 28 | Train Loss: 0.8089018 Vali Loss: 0.6497612 Test Loss: 0.3686668
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.007864320000000003
Max Memory (MB): 67.4150390625
Epoch: 10 cost time: 1.1135890483856201
Epoch: 10, Steps: 28 | Train Loss: 0.8097632 Vali Loss: 0.6393041 Test Loss: 0.3680255
Validation loss decreased (0.645126 --> 0.639304).  Saving model ...
Updating learning rate to 0.006291456000000002
Max Memory (MB): 67.4150390625
Epoch: 11 cost time: 1.1124286651611328
Epoch: 11, Steps: 28 | Train Loss: 0.8086121 Vali Loss: 0.6459649 Test Loss: 0.3680405
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.005033164800000003
Max Memory (MB): 67.4150390625
Epoch: 12 cost time: 1.1097142696380615
Epoch: 12, Steps: 28 | Train Loss: 0.8091288 Vali Loss: 0.6455640 Test Loss: 0.3667758
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.004026531840000002
Max Memory (MB): 67.4150390625
Epoch: 13 cost time: 1.2218549251556396
Epoch: 13, Steps: 28 | Train Loss: 0.8080928 Vali Loss: 0.6451736 Test Loss: 0.3684636
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0032212254720000015
Max Memory (MB): 67.4150390625
Epoch: 14 cost time: 1.108626365661621
Epoch: 14, Steps: 28 | Train Loss: 0.8062836 Vali Loss: 0.6460445 Test Loss: 0.3665149
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0025769803776000016
Max Memory (MB): 67.4150390625
Epoch: 15 cost time: 1.102860927581787
Epoch: 15, Steps: 28 | Train Loss: 0.8081245 Vali Loss: 0.6413928 Test Loss: 0.3677375
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 67.4150390625
>>>>>>>testing : ETTh2_720_720_SparseTSF_ETTh2_ftM_sl720_pl720_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
mse:0.36802560091018677, mae:0.41449594497680664, rse:0.48636940121650696

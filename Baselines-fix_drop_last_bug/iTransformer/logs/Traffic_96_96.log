Args in experiment:
Namespace(is_training=1, model_id='traffic_96_96', model='iTransformer', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=862, dec_in=862, c_out=862, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=2, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)
Use GPU: cuda:2
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
MACs: 729731072.0
Params: 841568.0
729.73M MACs
>>>>>>>start training : traffic_96_96_iTransformer_custom_M_ft96_sl48_ll96_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 12089
val 1661
test 3413
	iters: 100, epoch: 1 | loss: 0.5698075
	speed: 0.1499s/iter; left time: 550.3457s
	iters: 200, epoch: 1 | loss: 0.4597037
	speed: 0.1268s/iter; left time: 452.9714s
	iters: 300, epoch: 1 | loss: 0.4297133
	speed: 0.1229s/iter; left time: 426.5085s
Max Memory (MB): 5100.13427734375
Epoch: 1 cost time: 49.638811111450195
Epoch: 1, Steps: 377 | Train Loss: 0.5040355 Vali Loss: 0.5247142 Test Loss: 0.6068311
Validation loss decreased (inf --> 0.524714).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3699867
	speed: 1.8491s/iter; left time: 6091.0437s
	iters: 200, epoch: 2 | loss: 0.3519735
	speed: 0.1223s/iter; left time: 390.6487s
	iters: 300, epoch: 2 | loss: 0.3301480
	speed: 0.1222s/iter; left time: 378.0366s
Max Memory (MB): 5100.13427734375
Epoch: 2 cost time: 48.0766282081604
Epoch: 2, Steps: 377 | Train Loss: 0.3660863 Vali Loss: 0.4614222 Test Loss: 0.5238058
Validation loss decreased (0.524714 --> 0.461422).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3555155
	speed: 1.9074s/iter; left time: 5563.7974s
	iters: 200, epoch: 3 | loss: 0.3640933
	speed: 0.1216s/iter; left time: 342.4881s
	iters: 300, epoch: 3 | loss: 0.3369492
	speed: 0.1242s/iter; left time: 337.3565s
Max Memory (MB): 5100.13427734375
Epoch: 3 cost time: 49.06425094604492
Epoch: 3, Steps: 377 | Train Loss: 0.3359925 Vali Loss: 0.4517651 Test Loss: 0.5075930
Validation loss decreased (0.461422 --> 0.451765).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3101930
	speed: 1.8281s/iter; left time: 4643.4852s
	iters: 200, epoch: 4 | loss: 0.3236367
	speed: 0.1193s/iter; left time: 291.0506s
	iters: 300, epoch: 4 | loss: 0.3576029
	speed: 0.1212s/iter; left time: 283.7220s
Max Memory (MB): 5100.13427734375
Epoch: 4 cost time: 47.23197555541992
Epoch: 4, Steps: 377 | Train Loss: 0.3271158 Vali Loss: 0.4445121 Test Loss: 0.4992789
Validation loss decreased (0.451765 --> 0.444512).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3124650
	speed: 1.6496s/iter; left time: 3568.0183s
	iters: 200, epoch: 5 | loss: 0.3131770
	speed: 0.1180s/iter; left time: 243.5226s
	iters: 300, epoch: 5 | loss: 0.3084465
	speed: 0.1201s/iter; left time: 235.7386s
Max Memory (MB): 5100.13427734375
Epoch: 5 cost time: 46.65082406997681
Epoch: 5, Steps: 377 | Train Loss: 0.3234571 Vali Loss: 0.4420720 Test Loss: 0.4955509
Validation loss decreased (0.444512 --> 0.442072).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3432823
	speed: 1.9340s/iter; left time: 3454.0361s
	iters: 200, epoch: 6 | loss: 0.3254785
	speed: 0.1195s/iter; left time: 201.4312s
	iters: 300, epoch: 6 | loss: 0.3056434
	speed: 0.1197s/iter; left time: 189.9230s
Max Memory (MB): 5100.13427734375
Epoch: 6 cost time: 47.38455557823181
Epoch: 6, Steps: 377 | Train Loss: 0.3216345 Vali Loss: 0.4413567 Test Loss: 0.4941969
Validation loss decreased (0.442072 --> 0.441357).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3296029
	speed: 1.8147s/iter; left time: 2556.9471s
	iters: 200, epoch: 7 | loss: 0.3053053
	speed: 0.1180s/iter; left time: 154.4976s
	iters: 300, epoch: 7 | loss: 0.3284707
	speed: 0.1178s/iter; left time: 142.4306s
Max Memory (MB): 5100.13427734375
Epoch: 7 cost time: 46.66610145568848
Epoch: 7, Steps: 377 | Train Loss: 0.3207374 Vali Loss: 0.4410847 Test Loss: 0.4933218
Validation loss decreased (0.441357 --> 0.441085).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3233972
	speed: 1.8286s/iter; left time: 1887.0644s
	iters: 200, epoch: 8 | loss: 0.3270591
	speed: 0.1210s/iter; left time: 112.7688s
	iters: 300, epoch: 8 | loss: 0.3117093
	speed: 0.1215s/iter; left time: 101.0845s
Max Memory (MB): 5100.13427734375
Epoch: 8 cost time: 47.37297081947327
Epoch: 8, Steps: 377 | Train Loss: 0.3202469 Vali Loss: 0.4401057 Test Loss: 0.4928404
Validation loss decreased (0.441085 --> 0.440106).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3091024
	speed: 1.9194s/iter; left time: 1257.2320s
	iters: 200, epoch: 9 | loss: 0.3202613
	speed: 0.1199s/iter; left time: 66.5619s
	iters: 300, epoch: 9 | loss: 0.3123278
	speed: 0.1196s/iter; left time: 54.4270s
Max Memory (MB): 5100.13427734375
Epoch: 9 cost time: 47.19225740432739
Epoch: 9, Steps: 377 | Train Loss: 0.3200295 Vali Loss: 0.4396009 Test Loss: 0.4926824
Validation loss decreased (0.440106 --> 0.439601).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3165057
	speed: 1.7504s/iter; left time: 486.6200s
	iters: 200, epoch: 10 | loss: 0.3468759
	speed: 0.1185s/iter; left time: 21.0953s
	iters: 300, epoch: 10 | loss: 0.3047411
	speed: 0.1188s/iter; left time: 9.2654s
Max Memory (MB): 5100.13427734375
Epoch: 10 cost time: 47.01729154586792
Epoch: 10, Steps: 377 | Train Loss: 0.3199140 Vali Loss: 0.4398697 Test Loss: 0.4925547
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : traffic_96_96_iTransformer_custom_M_ft96_sl48_ll96_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
test shape: (3413, 1, 96, 862) (3413, 1, 96, 862)
test shape: (3413, 96, 862) (3413, 96, 862)
mse:0.4926811158657074, mae:0.34127742052078247

Args in experiment:
Namespace(is_training=1, model_id='weather_720_96', model='LightTimeBaseTST', data='custom', root_path='./dataset/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=96, period_len=4, basis_num=6, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=21, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.02, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=3, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:3
1254
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 102816.0
Params: 1254.0
102816.0 MACs
>>>>>>>start training : weather_720_96_LightTimeBaseTST_custom_ftM_sl720_pl96_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36072
val 5175
test 10444
Max Memory (MB): 117.5732421875
Epoch: 1 cost time: 3.0939860343933105
Epoch: 1, Steps: 71 | Train Loss: 0.7134857 Vali Loss: 0.6485292 Test Loss: 0.3019446
Validation loss decreased (inf --> 0.648529).  Saving model ...
Updating learning rate to 0.02
Max Memory (MB): 133.79443359375
Epoch: 2 cost time: 3.459787607192993
Epoch: 2, Steps: 71 | Train Loss: 0.5115340 Vali Loss: 0.4320054 Test Loss: 0.1811503
Validation loss decreased (0.648529 --> 0.432005).  Saving model ...
Updating learning rate to 0.02
Max Memory (MB): 133.79443359375
Epoch: 3 cost time: 3.225567102432251
Epoch: 3, Steps: 71 | Train Loss: 0.4689370 Vali Loss: 0.4481030 Test Loss: 0.1777780
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.02
Max Memory (MB): 133.79443359375
Epoch: 4 cost time: 3.2849879264831543
Epoch: 4, Steps: 71 | Train Loss: 0.4645844 Vali Loss: 0.4270329 Test Loss: 0.1788199
Validation loss decreased (0.432005 --> 0.427033).  Saving model ...
Updating learning rate to 0.016
Max Memory (MB): 133.79443359375
Epoch: 5 cost time: 3.349332094192505
Epoch: 5, Steps: 71 | Train Loss: 0.4616256 Vali Loss: 0.4508930 Test Loss: 0.1796798
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.012800000000000002
Max Memory (MB): 133.79443359375
Epoch: 6 cost time: 3.4229798316955566
Epoch: 6, Steps: 71 | Train Loss: 0.4591042 Vali Loss: 0.4174137 Test Loss: 0.1728573
Validation loss decreased (0.427033 --> 0.417414).  Saving model ...
Updating learning rate to 0.010240000000000003
Max Memory (MB): 133.79443359375
Epoch: 7 cost time: 3.282362222671509
Epoch: 7, Steps: 71 | Train Loss: 0.4532148 Vali Loss: 0.4307247 Test Loss: 0.1756338
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.008192000000000001
Max Memory (MB): 133.79443359375
Epoch: 8 cost time: 3.285928964614868
Epoch: 8, Steps: 71 | Train Loss: 0.4533191 Vali Loss: 0.4215268 Test Loss: 0.1765053
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0065536000000000014
Max Memory (MB): 133.79443359375
Epoch: 9 cost time: 3.261793851852417
Epoch: 9, Steps: 71 | Train Loss: 0.4523372 Vali Loss: 0.4206820 Test Loss: 0.1757475
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.005242880000000002
Max Memory (MB): 133.79443359375
Epoch: 10 cost time: 3.531799077987671
Epoch: 10, Steps: 71 | Train Loss: 0.4511220 Vali Loss: 0.4360771 Test Loss: 0.1737807
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.004194304000000002
Max Memory (MB): 133.79443359375
Epoch: 11 cost time: 3.5149457454681396
Epoch: 11, Steps: 71 | Train Loss: 0.4495283 Vali Loss: 0.4118880 Test Loss: 0.1710780
Validation loss decreased (0.417414 --> 0.411888).  Saving model ...
Updating learning rate to 0.003355443200000002
Max Memory (MB): 133.79443359375
Epoch: 12 cost time: 3.4575135707855225
Epoch: 12, Steps: 71 | Train Loss: 0.4484243 Vali Loss: 0.4111458 Test Loss: 0.1721108
Validation loss decreased (0.411888 --> 0.411146).  Saving model ...
Updating learning rate to 0.002684354560000001
Max Memory (MB): 133.79443359375
Epoch: 13 cost time: 3.285689353942871
Epoch: 13, Steps: 71 | Train Loss: 0.4474882 Vali Loss: 0.4164993 Test Loss: 0.1712863
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0021474836480000013
Max Memory (MB): 133.79443359375
Epoch: 14 cost time: 3.3480701446533203
Epoch: 14, Steps: 71 | Train Loss: 0.4457759 Vali Loss: 0.4352200 Test Loss: 0.1707216
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0017179869184000011
Max Memory (MB): 133.79443359375
Epoch: 15 cost time: 3.317128896713257
Epoch: 15, Steps: 71 | Train Loss: 0.4482747 Vali Loss: 0.4181058 Test Loss: 0.1716606
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0013743895347200009
Max Memory (MB): 133.79443359375
Epoch: 16 cost time: 3.2976720333099365
Epoch: 16, Steps: 71 | Train Loss: 0.4462004 Vali Loss: 0.4195321 Test Loss: 0.1723973
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0010995116277760007
Max Memory (MB): 133.79443359375
Epoch: 17 cost time: 3.3980300426483154
Epoch: 17, Steps: 71 | Train Loss: 0.4451762 Vali Loss: 0.4039621 Test Loss: 0.1713687
Validation loss decreased (0.411146 --> 0.403962).  Saving model ...
Updating learning rate to 0.0008796093022208007
Max Memory (MB): 133.79443359375
Epoch: 18 cost time: 3.3781566619873047
Epoch: 18, Steps: 71 | Train Loss: 0.4456813 Vali Loss: 0.4199195 Test Loss: 0.1698204
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0007036874417766406
Max Memory (MB): 133.79443359375
Epoch: 19 cost time: 3.656076192855835
Epoch: 19, Steps: 71 | Train Loss: 0.4461662 Vali Loss: 0.4363540 Test Loss: 0.1704596
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0005629499534213125
Max Memory (MB): 133.79443359375
Epoch: 20 cost time: 3.5834357738494873
Epoch: 20, Steps: 71 | Train Loss: 0.4447533 Vali Loss: 0.4207785 Test Loss: 0.1707563
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0004503599627370501
Max Memory (MB): 133.79443359375
Epoch: 21 cost time: 3.567627429962158
Epoch: 21, Steps: 71 | Train Loss: 0.4442557 Vali Loss: 0.4158541 Test Loss: 0.1705452
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00036028797018964004
Max Memory (MB): 133.79443359375
Epoch: 22 cost time: 3.5469863414764404
Epoch: 22, Steps: 71 | Train Loss: 0.4443943 Vali Loss: 0.4252121 Test Loss: 0.1706461
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 133.79443359375
>>>>>>>testing : weather_720_96_LightTimeBaseTST_custom_ftM_sl720_pl96_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
mse:0.17453346672058105, mae:0.23088054358959198, rse:0.5514889359474182

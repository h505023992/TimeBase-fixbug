Args in experiment:
Namespace(is_training=1, model_id='electricity_192_96', model='FITS', data='custom', root_path='./dataset/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=321, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=82, base_T=24, H_order=8)
Use GPU: cuda:0
>>>>>>>start training : electricity_192_96_FITS_custom_ftM_sl192_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18125
val 2537
test 5165
Model(
  (freq_upsampler): Linear(in_features=82, out_features=123, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  414413568.0
params:  10209.0
Trainable parameters:  10209
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.8003163
	speed: 0.1654s/iter; left time: 683.4315s
Epoch: 1 cost time: 22.56901502609253
Epoch: 1, Steps: 141 | Train Loss: 0.9192671 Vali Loss: 0.6378132 Test Loss: 0.7287517
Validation loss decreased (inf --> 0.637813).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5991880
	speed: 0.3482s/iter; left time: 1389.2712s
Epoch: 2 cost time: 20.94188642501831
Epoch: 2, Steps: 141 | Train Loss: 0.6418335 Vali Loss: 0.5415758 Test Loss: 0.6232517
Validation loss decreased (0.637813 --> 0.541576).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.5261707
	speed: 0.3587s/iter; left time: 1380.6155s
Epoch: 3 cost time: 21.965126752853394
Epoch: 3, Steps: 141 | Train Loss: 0.5334502 Vali Loss: 0.4831054 Test Loss: 0.5571072
Validation loss decreased (0.541576 --> 0.483105).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.4311532
	speed: 0.4008s/iter; left time: 1486.1406s
Epoch: 4 cost time: 24.509063005447388
Epoch: 4, Steps: 141 | Train Loss: 0.4590131 Vali Loss: 0.4329950 Test Loss: 0.5010945
Validation loss decreased (0.483105 --> 0.432995).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3875717
	speed: 0.3773s/iter; left time: 1345.6927s
Epoch: 5 cost time: 21.6968777179718
Epoch: 5, Steps: 141 | Train Loss: 0.3984646 Vali Loss: 0.3928189 Test Loss: 0.4550824
Validation loss decreased (0.432995 --> 0.392819).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3313536
	speed: 0.3657s/iter; left time: 1252.7440s
Epoch: 6 cost time: 22.68579363822937
Epoch: 6, Steps: 141 | Train Loss: 0.3480439 Vali Loss: 0.3553813 Test Loss: 0.4129370
Validation loss decreased (0.392819 --> 0.355381).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2945073
	speed: 0.3710s/iter; left time: 1218.8842s
Epoch: 7 cost time: 21.987531423568726
Epoch: 7, Steps: 141 | Train Loss: 0.3058269 Vali Loss: 0.3247904 Test Loss: 0.3781374
Validation loss decreased (0.355381 --> 0.324790).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2639793
	speed: 0.3859s/iter; left time: 1213.1551s
Epoch: 8 cost time: 23.22862219810486
Epoch: 8, Steps: 141 | Train Loss: 0.2702490 Vali Loss: 0.2979790 Test Loss: 0.3479329
Validation loss decreased (0.324790 --> 0.297979).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2367833
	speed: 0.3754s/iter; left time: 1127.2003s
Epoch: 9 cost time: 22.449803113937378
Epoch: 9, Steps: 141 | Train Loss: 0.2401024 Vali Loss: 0.2759164 Test Loss: 0.3228812
Validation loss decreased (0.297979 --> 0.275916).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2079002
	speed: 0.3602s/iter; left time: 1030.9365s
Epoch: 10 cost time: 22.063844203948975
Epoch: 10, Steps: 141 | Train Loss: 0.2144823 Vali Loss: 0.2551700 Test Loss: 0.2988461
Validation loss decreased (0.275916 --> 0.255170).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1869600
	speed: 0.3903s/iter; left time: 1061.9083s
Epoch: 11 cost time: 24.26248073577881
Epoch: 11, Steps: 141 | Train Loss: 0.1926855 Vali Loss: 0.2390240 Test Loss: 0.2807843
Validation loss decreased (0.255170 --> 0.239024).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1701404
	speed: 0.3967s/iter; left time: 1023.5458s
Epoch: 12 cost time: 22.293829202651978
Epoch: 12, Steps: 141 | Train Loss: 0.1740301 Vali Loss: 0.2247581 Test Loss: 0.2642594
Validation loss decreased (0.239024 --> 0.224758).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1581678
	speed: 0.3697s/iter; left time: 901.8006s
Epoch: 13 cost time: 22.282371759414673
Epoch: 13, Steps: 141 | Train Loss: 0.1580305 Vali Loss: 0.2120204 Test Loss: 0.2497315
Validation loss decreased (0.224758 --> 0.212020).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1403617
	speed: 0.3481s/iter; left time: 799.8274s
Epoch: 14 cost time: 18.64684271812439
Epoch: 14, Steps: 141 | Train Loss: 0.1443040 Vali Loss: 0.2019700 Test Loss: 0.2381016
Validation loss decreased (0.212020 --> 0.201970).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1268064
	speed: 0.3649s/iter; left time: 787.0294s
Epoch: 15 cost time: 23.276070833206177
Epoch: 15, Steps: 141 | Train Loss: 0.1324891 Vali Loss: 0.1925346 Test Loss: 0.2271907
Validation loss decreased (0.201970 --> 0.192535).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.1190423
	speed: 0.3814s/iter; left time: 768.9885s
Epoch: 16 cost time: 22.69330072402954
Epoch: 16, Steps: 141 | Train Loss: 0.1222788 Vali Loss: 0.1848080 Test Loss: 0.2181803
Validation loss decreased (0.192535 --> 0.184808).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1118768
	speed: 0.3791s/iter; left time: 710.7744s
Epoch: 17 cost time: 22.326837301254272
Epoch: 17, Steps: 141 | Train Loss: 0.1135028 Vali Loss: 0.1777447 Test Loss: 0.2098673
Validation loss decreased (0.184808 --> 0.177745).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.1049139
	speed: 0.3691s/iter; left time: 640.0309s
Epoch: 18 cost time: 23.377376317977905
Epoch: 18, Steps: 141 | Train Loss: 0.1059336 Vali Loss: 0.1728119 Test Loss: 0.2042651
Validation loss decreased (0.177745 --> 0.172812).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0941274
	speed: 0.4016s/iter; left time: 639.7926s
Epoch: 19 cost time: 23.39895510673523
Epoch: 19, Steps: 141 | Train Loss: 0.0993349 Vali Loss: 0.1666697 Test Loss: 0.1972404
Validation loss decreased (0.172812 --> 0.166670).  Saving model ...
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0918946
	speed: 0.3639s/iter; left time: 528.4507s
Epoch: 20 cost time: 20.949670553207397
Epoch: 20, Steps: 141 | Train Loss: 0.0936139 Vali Loss: 0.1623987 Test Loss: 0.1923353
Validation loss decreased (0.166670 --> 0.162399).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0865209
	speed: 0.3592s/iter; left time: 470.9011s
Epoch: 21 cost time: 21.547443151474
Epoch: 21, Steps: 141 | Train Loss: 0.0886650 Vali Loss: 0.1587722 Test Loss: 0.1877559
Validation loss decreased (0.162399 --> 0.158772).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0834097
	speed: 0.3595s/iter; left time: 420.6548s
Epoch: 22 cost time: 21.92470955848694
Epoch: 22, Steps: 141 | Train Loss: 0.0843777 Vali Loss: 0.1555648 Test Loss: 0.1838138
Validation loss decreased (0.158772 --> 0.155565).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0835763
	speed: 0.3400s/iter; left time: 349.8649s
Epoch: 23 cost time: 19.852408170700073
Epoch: 23, Steps: 141 | Train Loss: 0.0806631 Vali Loss: 0.1526779 Test Loss: 0.1806671
Validation loss decreased (0.155565 --> 0.152678).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0769144
	speed: 0.3297s/iter; left time: 292.7437s
Epoch: 24 cost time: 19.430579900741577
Epoch: 24, Steps: 141 | Train Loss: 0.0773835 Vali Loss: 0.1502822 Test Loss: 0.1777143
Validation loss decreased (0.152678 --> 0.150282).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0737858
	speed: 0.3310s/iter; left time: 247.2486s
Epoch: 25 cost time: 19.765350580215454
Epoch: 25, Steps: 141 | Train Loss: 0.0745686 Vali Loss: 0.1482389 Test Loss: 0.1752743
Validation loss decreased (0.150282 --> 0.148239).  Saving model ...
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0718627
	speed: 0.3454s/iter; left time: 209.3113s
Epoch: 26 cost time: 20.579798936843872
Epoch: 26, Steps: 141 | Train Loss: 0.0721045 Vali Loss: 0.1468417 Test Loss: 0.1730748
Validation loss decreased (0.148239 --> 0.146842).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0694819
	speed: 0.3304s/iter; left time: 153.6206s
Epoch: 27 cost time: 19.013533115386963
Epoch: 27, Steps: 141 | Train Loss: 0.0699339 Vali Loss: 0.1447196 Test Loss: 0.1709428
Validation loss decreased (0.146842 --> 0.144720).  Saving model ...
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0685453
	speed: 0.3277s/iter; left time: 106.1892s
Epoch: 28 cost time: 19.5511314868927
Epoch: 28, Steps: 141 | Train Loss: 0.0680778 Vali Loss: 0.1431001 Test Loss: 0.1691674
Validation loss decreased (0.144720 --> 0.143100).  Saving model ...
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0648142
	speed: 0.3402s/iter; left time: 62.2523s
Epoch: 29 cost time: 20.149057149887085
Epoch: 29, Steps: 141 | Train Loss: 0.0664521 Vali Loss: 0.1419437 Test Loss: 0.1676062
Validation loss decreased (0.143100 --> 0.141944).  Saving model ...
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0633857
	speed: 0.3419s/iter; left time: 14.3593s
Epoch: 30 cost time: 20.1691415309906
Epoch: 30, Steps: 141 | Train Loss: 0.0650307 Vali Loss: 0.1413276 Test Loss: 0.1664612
Validation loss decreased (0.141944 --> 0.141328).  Saving model ...
Updating learning rate to 0.00011296777049628277
train 18125
val 2537
test 5165
Model(
  (freq_upsampler): Linear(in_features=82, out_features=123, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  414413568.0
params:  10209.0
Trainable parameters:  10209
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.1555584
	speed: 0.1398s/iter; left time: 577.4723s
Epoch: 1 cost time: 19.33508014678955
Epoch: 1, Steps: 141 | Train Loss: 0.1548881 Vali Loss: 0.1326553 Test Loss: 0.1551294
Validation loss decreased (inf --> 0.132655).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1608858
	speed: 0.3291s/iter; left time: 1313.3036s
Epoch: 2 cost time: 19.33499503135681
Epoch: 2, Steps: 141 | Train Loss: 0.1529397 Vali Loss: 0.1322096 Test Loss: 0.1547368
Validation loss decreased (0.132655 --> 0.132210).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1594157
	speed: 0.3742s/iter; left time: 1440.4632s
Epoch: 3 cost time: 22.800365447998047
Epoch: 3, Steps: 141 | Train Loss: 0.1526956 Vali Loss: 0.1320371 Test Loss: 0.1545659
Validation loss decreased (0.132210 --> 0.132037).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1618458
	speed: 0.3747s/iter; left time: 1389.3226s
Epoch: 4 cost time: 22.430351972579956
Epoch: 4, Steps: 141 | Train Loss: 0.1525189 Vali Loss: 0.1317963 Test Loss: 0.1544459
Validation loss decreased (0.132037 --> 0.131796).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1561309
	speed: 0.3597s/iter; left time: 1283.0151s
Epoch: 5 cost time: 20.83483099937439
Epoch: 5, Steps: 141 | Train Loss: 0.1523755 Vali Loss: 0.1316534 Test Loss: 0.1544130
Validation loss decreased (0.131796 --> 0.131653).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1531228
	speed: 0.3557s/iter; left time: 1218.5591s
Epoch: 6 cost time: 21.537158966064453
Epoch: 6, Steps: 141 | Train Loss: 0.1523487 Vali Loss: 0.1317129 Test Loss: 0.1543233
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.1395966
	speed: 0.3999s/iter; left time: 1313.8112s
Epoch: 7 cost time: 23.793449640274048
Epoch: 7, Steps: 141 | Train Loss: 0.1522978 Vali Loss: 0.1316428 Test Loss: 0.1542742
Validation loss decreased (0.131653 --> 0.131643).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.1540712
	speed: 0.3574s/iter; left time: 1123.6611s
Epoch: 8 cost time: 20.83976674079895
Epoch: 8, Steps: 141 | Train Loss: 0.1522552 Vali Loss: 0.1317593 Test Loss: 0.1543114
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.1391274
	speed: 0.3566s/iter; left time: 1070.7742s
Epoch: 9 cost time: 21.71027708053589
Epoch: 9, Steps: 141 | Train Loss: 0.1521896 Vali Loss: 0.1316078 Test Loss: 0.1542690
Validation loss decreased (0.131643 --> 0.131608).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.1565810
	speed: 0.3796s/iter; left time: 1086.4366s
Epoch: 10 cost time: 22.53477454185486
Epoch: 10, Steps: 141 | Train Loss: 0.1521946 Vali Loss: 0.1314154 Test Loss: 0.1542642
Validation loss decreased (0.131608 --> 0.131415).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.1485668
	speed: 0.3992s/iter; left time: 1086.2761s
Epoch: 11 cost time: 22.92474603652954
Epoch: 11, Steps: 141 | Train Loss: 0.1522297 Vali Loss: 0.1314273 Test Loss: 0.1542264
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1606787
	speed: 0.3599s/iter; left time: 928.5299s
Epoch: 12 cost time: 21.133431911468506
Epoch: 12, Steps: 141 | Train Loss: 0.1520965 Vali Loss: 0.1317553 Test Loss: 0.1542482
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1661552
	speed: 0.3621s/iter; left time: 883.1918s
Epoch: 13 cost time: 22.36961054801941
Epoch: 13, Steps: 141 | Train Loss: 0.1522282 Vali Loss: 0.1316915 Test Loss: 0.1542218
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1700684
	speed: 0.3905s/iter; left time: 897.4096s
Epoch: 14 cost time: 23.86608099937439
Epoch: 14, Steps: 141 | Train Loss: 0.1521056 Vali Loss: 0.1319572 Test Loss: 0.1542069
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.1705631
	speed: 0.3753s/iter; left time: 809.4794s
Epoch: 15 cost time: 21.19840407371521
Epoch: 15, Steps: 141 | Train Loss: 0.1521587 Vali Loss: 0.1315731 Test Loss: 0.1541753
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : electricity_192_96_FITS_custom_ftM_sl192_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
mse:0.15415586531162262, mae:0.24796612560749054, rse:0.3902329206466675, corr:[0.4647119  0.46760118 0.46883598 0.46879557 0.4691529  0.4689983
 0.4690754  0.46876952 0.46859413 0.46844232 0.46821716 0.4682222
 0.46793255 0.46794677 0.4677082  0.46762025 0.46745214 0.4671728
 0.46721342 0.46701664 0.4668864  0.4668691  0.46695986 0.4670483
 0.46700794 0.46696916 0.46694785 0.46690136 0.46673876 0.46652758
 0.46635506 0.46631277 0.46612385 0.46599776 0.465898   0.46577075
 0.46578646 0.46561855 0.46560153 0.46558332 0.46542022 0.46553943
 0.4655006  0.46534273 0.46517906 0.46515974 0.4651486  0.46515942
 0.46523523 0.46535343 0.46537742 0.46521446 0.4651682  0.46510714
 0.46512958 0.46508735 0.46497282 0.46501452 0.46492916 0.46492797
 0.46484116 0.46474326 0.46480232 0.46473643 0.4647642  0.4647523
 0.4646498  0.46437976 0.464257   0.46425128 0.46417013 0.4642035
 0.46412638 0.46418703 0.46420115 0.46419773 0.46411017 0.46404287
 0.46410796 0.46397826 0.46401897 0.4639691  0.4639319  0.46388626
 0.46381384 0.46378177 0.463679   0.46381038 0.46352965 0.4635953
 0.46345797 0.46337718 0.4632135  0.46330824 0.46335065 0.46341655]

Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='96_336', model='PatchTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, fc_dropout=0.3, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:1
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 1795584.0
Params: 81296.0
1.80M MACs
>>>>>>>start training : 96_336_PatchTST_ETTh1_ftM_sl96_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
Epoch: 1 cost time: 8.368650197982788
Epoch: 1, Steps: 65 | Train Loss: 0.7912226 Vali Loss: 1.8061543 Test Loss: 0.8506255
Validation loss decreased (inf --> 1.806154).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 7.9676854610443115
Epoch: 2, Steps: 65 | Train Loss: 0.7203616 Vali Loss: 1.5416921 Test Loss: 0.6540653
Validation loss decreased (1.806154 --> 1.541692).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 7.5947349071502686
Epoch: 3, Steps: 65 | Train Loss: 0.6213679 Vali Loss: 1.4132922 Test Loss: 0.5689257
Validation loss decreased (1.541692 --> 1.413292).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 8.080850601196289
Epoch: 4, Steps: 65 | Train Loss: 0.5752350 Vali Loss: 1.3689950 Test Loss: 0.5347409
Validation loss decreased (1.413292 --> 1.368995).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 8.01349687576294
Epoch: 5, Steps: 65 | Train Loss: 0.5524381 Vali Loss: 1.3480847 Test Loss: 0.5176459
Validation loss decreased (1.368995 --> 1.348085).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 6.894040107727051
Epoch: 6, Steps: 65 | Train Loss: 0.5375812 Vali Loss: 1.3336954 Test Loss: 0.5080966
Validation loss decreased (1.348085 --> 1.333695).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 6.747987747192383
Epoch: 7, Steps: 65 | Train Loss: 0.5319462 Vali Loss: 1.3242756 Test Loss: 0.5030323
Validation loss decreased (1.333695 --> 1.324276).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 8.921372175216675
Epoch: 8, Steps: 65 | Train Loss: 0.5254270 Vali Loss: 1.3181098 Test Loss: 0.4997891
Validation loss decreased (1.324276 --> 1.318110).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 8.096771717071533
Epoch: 9, Steps: 65 | Train Loss: 0.5218959 Vali Loss: 1.3135141 Test Loss: 0.4974945
Validation loss decreased (1.318110 --> 1.313514).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 7.51093316078186
Epoch: 10, Steps: 65 | Train Loss: 0.5185915 Vali Loss: 1.3108138 Test Loss: 0.4961309
Validation loss decreased (1.313514 --> 1.310814).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 7.654234170913696
Epoch: 11, Steps: 65 | Train Loss: 0.5166915 Vali Loss: 1.3075569 Test Loss: 0.4951729
Validation loss decreased (1.310814 --> 1.307557).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 7.732876539230347
Epoch: 12, Steps: 65 | Train Loss: 0.5142182 Vali Loss: 1.3049573 Test Loss: 0.4941311
Validation loss decreased (1.307557 --> 1.304957).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 7.5638747215271
Epoch: 13, Steps: 65 | Train Loss: 0.5130321 Vali Loss: 1.3036426 Test Loss: 0.4934568
Validation loss decreased (1.304957 --> 1.303643).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 8.265076637268066
Epoch: 14, Steps: 65 | Train Loss: 0.5123783 Vali Loss: 1.3024573 Test Loss: 0.4928681
Validation loss decreased (1.303643 --> 1.302457).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 7.6779398918151855
Epoch: 15, Steps: 65 | Train Loss: 0.5117572 Vali Loss: 1.3003792 Test Loss: 0.4922709
Validation loss decreased (1.302457 --> 1.300379).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 7.787186145782471
Epoch: 16, Steps: 65 | Train Loss: 0.5090713 Vali Loss: 1.2998092 Test Loss: 0.4919179
Validation loss decreased (1.300379 --> 1.299809).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 7.415478706359863
Epoch: 17, Steps: 65 | Train Loss: 0.5103303 Vali Loss: 1.3001026 Test Loss: 0.4916741
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 7.880443811416626
Epoch: 18, Steps: 65 | Train Loss: 0.5097262 Vali Loss: 1.2987418 Test Loss: 0.4913109
Validation loss decreased (1.299809 --> 1.298742).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 7.75995135307312
Epoch: 19, Steps: 65 | Train Loss: 0.5083019 Vali Loss: 1.2990416 Test Loss: 0.4910224
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 8.33283019065857
Epoch: 20, Steps: 65 | Train Loss: 0.5094496 Vali Loss: 1.2980373 Test Loss: 0.4907943
Validation loss decreased (1.298742 --> 1.298037).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 7.700442552566528
Epoch: 21, Steps: 65 | Train Loss: 0.5078840 Vali Loss: 1.2971338 Test Loss: 0.4904311
Validation loss decreased (1.298037 --> 1.297134).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 8.200373411178589
Epoch: 22, Steps: 65 | Train Loss: 0.5074869 Vali Loss: 1.2980883 Test Loss: 0.4901414
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 7.830964803695679
Epoch: 23, Steps: 65 | Train Loss: 0.5068437 Vali Loss: 1.2969038 Test Loss: 0.4901597
Validation loss decreased (1.297134 --> 1.296904).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 8.049811363220215
Epoch: 24, Steps: 65 | Train Loss: 0.5079230 Vali Loss: 1.2963231 Test Loss: 0.4900835
Validation loss decreased (1.296904 --> 1.296323).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 8.365795135498047
Epoch: 25, Steps: 65 | Train Loss: 0.5057972 Vali Loss: 1.2972976 Test Loss: 0.4897635
EarlyStopping counter: 1 out of 5
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 8.305649518966675
Epoch: 26, Steps: 65 | Train Loss: 0.5070884 Vali Loss: 1.2960892 Test Loss: 0.4897716
Validation loss decreased (1.296323 --> 1.296089).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 7.818828105926514
Epoch: 27, Steps: 65 | Train Loss: 0.5069578 Vali Loss: 1.2961279 Test Loss: 0.4895111
EarlyStopping counter: 1 out of 5
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 8.554056882858276
Epoch: 28, Steps: 65 | Train Loss: 0.5059356 Vali Loss: 1.2957940 Test Loss: 0.4893251
Validation loss decreased (1.296089 --> 1.295794).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 8.639680862426758
Epoch: 29, Steps: 65 | Train Loss: 0.5071011 Vali Loss: 1.2959635 Test Loss: 0.4892807
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 8.10622763633728
Epoch: 30, Steps: 65 | Train Loss: 0.5055006 Vali Loss: 1.2951012 Test Loss: 0.4892460
Validation loss decreased (1.295794 --> 1.295101).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
>>>>>>>testing : 96_336_PatchTST_ETTh1_ftM_sl96_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4887191653251648, mae:0.4564351737499237, rse:0.6655516028404236

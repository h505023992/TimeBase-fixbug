Args in experiment:
Namespace(is_training=1, model_id='ETTm2_720_96', model='SparseTSF', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=96, period_len=4, basis_num=6, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.02, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
model的参数数量: 4325
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 146160.0
Params: 4325.0
146160.0 MACs
>>>>>>>start training : ETTm2_720_96_SparseTSF_ETTm2_ftM_sl720_pl96_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.3382250
	speed: 0.0520s/iter; left time: 199.2529s
Max Memory (MB): 112.3515625
Epoch: 1 cost time: 6.63871955871582
Epoch: 1, Steps: 131 | Train Loss: 0.3170615 Vali Loss: 0.1378330 Test Loss: 0.1967822
Validation loss decreased (inf --> 0.137833).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 2 | loss: 0.1715949
	speed: 0.1378s/iter; left time: 509.7230s
Max Memory (MB): 112.3515625
Epoch: 2 cost time: 6.037048816680908
Epoch: 2, Steps: 131 | Train Loss: 0.2303509 Vali Loss: 0.1199546 Test Loss: 0.1745635
Validation loss decreased (0.137833 --> 0.119955).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 3 | loss: 0.2325331
	speed: 0.1339s/iter; left time: 477.7249s
Max Memory (MB): 112.3515625
Epoch: 3 cost time: 6.295913219451904
Epoch: 3, Steps: 131 | Train Loss: 0.2172229 Vali Loss: 0.1177447 Test Loss: 0.1678153
Validation loss decreased (0.119955 --> 0.117745).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 4 | loss: 0.2298374
	speed: 0.1331s/iter; left time: 457.6192s
Max Memory (MB): 112.3515625
Epoch: 4 cost time: 6.755624055862427
Epoch: 4, Steps: 131 | Train Loss: 0.2159011 Vali Loss: 0.1163334 Test Loss: 0.1687289
Validation loss decreased (0.117745 --> 0.116333).  Saving model ...
Updating learning rate to 0.016
	iters: 100, epoch: 5 | loss: 0.1892092
	speed: 0.1199s/iter; left time: 396.5961s
Max Memory (MB): 112.3515625
Epoch: 5 cost time: 5.302232503890991
Epoch: 5, Steps: 131 | Train Loss: 0.2154643 Vali Loss: 0.1161280 Test Loss: 0.1691952
Validation loss decreased (0.116333 --> 0.116128).  Saving model ...
Updating learning rate to 0.012800000000000002
	iters: 100, epoch: 6 | loss: 0.2095720
	speed: 0.1013s/iter; left time: 321.6880s
Max Memory (MB): 112.3515625
Epoch: 6 cost time: 4.504451274871826
Epoch: 6, Steps: 131 | Train Loss: 0.2119193 Vali Loss: 0.1163722 Test Loss: 0.1694162
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.010240000000000003
	iters: 100, epoch: 7 | loss: 0.2364515
	speed: 0.1218s/iter; left time: 370.8944s
Max Memory (MB): 112.3515625
Epoch: 7 cost time: 6.410932540893555
Epoch: 7, Steps: 131 | Train Loss: 0.2112665 Vali Loss: 0.1159631 Test Loss: 0.1687442
Validation loss decreased (0.116128 --> 0.115963).  Saving model ...
Updating learning rate to 0.008192000000000001
	iters: 100, epoch: 8 | loss: 0.1870548
	speed: 0.1387s/iter; left time: 404.1669s
Max Memory (MB): 112.3515625
Epoch: 8 cost time: 7.149685859680176
Epoch: 8, Steps: 131 | Train Loss: 0.2102898 Vali Loss: 0.1142929 Test Loss: 0.1642417
Validation loss decreased (0.115963 --> 0.114293).  Saving model ...
Updating learning rate to 0.0065536000000000014
	iters: 100, epoch: 9 | loss: 0.2300229
	speed: 0.1380s/iter; left time: 384.0326s
Max Memory (MB): 112.3515625
Epoch: 9 cost time: 6.241053581237793
Epoch: 9, Steps: 131 | Train Loss: 0.2101147 Vali Loss: 0.1154771 Test Loss: 0.1683174
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.005242880000000002
	iters: 100, epoch: 10 | loss: 0.2222252
	speed: 0.1171s/iter; left time: 310.6787s
Max Memory (MB): 112.3515625
Epoch: 10 cost time: 5.60111927986145
Epoch: 10, Steps: 131 | Train Loss: 0.2093774 Vali Loss: 0.1156672 Test Loss: 0.1646318
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.004194304000000002
	iters: 100, epoch: 11 | loss: 0.2111316
	speed: 0.1195s/iter; left time: 301.2788s
Max Memory (MB): 112.3515625
Epoch: 11 cost time: 5.627309799194336
Epoch: 11, Steps: 131 | Train Loss: 0.2092899 Vali Loss: 0.1148706 Test Loss: 0.1646218
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.003355443200000002
	iters: 100, epoch: 12 | loss: 0.1882876
	speed: 0.1094s/iter; left time: 261.4035s
Max Memory (MB): 112.3515625
Epoch: 12 cost time: 4.948631763458252
Epoch: 12, Steps: 131 | Train Loss: 0.2090561 Vali Loss: 0.1151799 Test Loss: 0.1669895
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.002684354560000001
	iters: 100, epoch: 13 | loss: 0.2126392
	speed: 0.0999s/iter; left time: 225.6837s
Max Memory (MB): 112.3515625
Epoch: 13 cost time: 5.3298187255859375
Epoch: 13, Steps: 131 | Train Loss: 0.2085144 Vali Loss: 0.1152665 Test Loss: 0.1665598
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 112.3515625
>>>>>>>testing : ETTm2_720_96_SparseTSF_ETTm2_ftM_sl720_pl96_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.16424164175987244, mae:0.25413674116134644, rse:0.32730504870414734

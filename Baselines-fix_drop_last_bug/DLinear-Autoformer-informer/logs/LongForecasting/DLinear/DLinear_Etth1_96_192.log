Args in experiment:
Namespace(is_training=1, train_only=False, model_id='DLinear_ETTh1_96_192', model='DLinear', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DLinear_ETTh1_96_192_DLinear_ETTh1_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.7035917
	speed: 0.0374s/iter; left time: 289.9767s
	iters: 200, epoch: 1 | loss: 0.5842575
	speed: 0.0138s/iter; left time: 106.0639s
Epoch: 1 cost time: 6.099716901779175
Epoch: 1, Steps: 262 | Train Loss: 0.7281291 Vali Loss: 1.0893120 Test Loss: 0.5746586
Validation loss decreased (inf --> 1.089312).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4923377
	speed: 0.0874s/iter; left time: 655.7290s
	iters: 200, epoch: 2 | loss: 0.4983377
	speed: 0.0154s/iter; left time: 114.1451s
Epoch: 2 cost time: 4.713905572891235
Epoch: 2, Steps: 262 | Train Loss: 0.4876665 Vali Loss: 1.0033501 Test Loss: 0.5017922
Validation loss decreased (1.089312 --> 1.003350).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4391825
	speed: 0.1229s/iter; left time: 889.5110s
	iters: 200, epoch: 3 | loss: 0.4693923
	speed: 0.0175s/iter; left time: 124.5805s
Epoch: 3 cost time: 5.419945001602173
Epoch: 3, Steps: 262 | Train Loss: 0.4606478 Vali Loss: 0.9905162 Test Loss: 0.4863199
Validation loss decreased (1.003350 --> 0.990516).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4358924
	speed: 0.1186s/iter; left time: 827.3651s
	iters: 200, epoch: 4 | loss: 0.4813747
	speed: 0.0172s/iter; left time: 118.5894s
Epoch: 4 cost time: 5.3292646408081055
Epoch: 4, Steps: 262 | Train Loss: 0.4521540 Vali Loss: 0.9819831 Test Loss: 0.4807083
Validation loss decreased (0.990516 --> 0.981983).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4248435
	speed: 0.1266s/iter; left time: 850.1079s
	iters: 200, epoch: 5 | loss: 0.4168144
	speed: 0.0172s/iter; left time: 113.8696s
Epoch: 5 cost time: 5.421737909317017
Epoch: 5, Steps: 262 | Train Loss: 0.4478622 Vali Loss: 0.9782289 Test Loss: 0.4781125
Validation loss decreased (0.981983 --> 0.978229).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4676923
	speed: 0.1188s/iter; left time: 766.6689s
	iters: 200, epoch: 6 | loss: 0.4951552
	speed: 0.0171s/iter; left time: 108.3692s
Epoch: 6 cost time: 5.261070728302002
Epoch: 6, Steps: 262 | Train Loss: 0.4479245 Vali Loss: 0.9665452 Test Loss: 0.4768093
Validation loss decreased (0.978229 --> 0.966545).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4870211
	speed: 0.1253s/iter; left time: 775.3274s
	iters: 200, epoch: 7 | loss: 0.3779164
	speed: 0.0173s/iter; left time: 105.2194s
Epoch: 7 cost time: 5.343986988067627
Epoch: 7, Steps: 262 | Train Loss: 0.4453479 Vali Loss: 0.9597623 Test Loss: 0.4761360
Validation loss decreased (0.966545 --> 0.959762).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3805004
	speed: 0.1313s/iter; left time: 778.1997s
	iters: 200, epoch: 8 | loss: 0.4988119
	speed: 0.0183s/iter; left time: 106.7948s
Epoch: 8 cost time: 5.658899784088135
Epoch: 8, Steps: 262 | Train Loss: 0.4451833 Vali Loss: 0.9558828 Test Loss: 0.4758238
Validation loss decreased (0.959762 --> 0.955883).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.4534100
	speed: 0.1349s/iter; left time: 764.3595s
	iters: 200, epoch: 9 | loss: 0.4479854
	speed: 0.0176s/iter; left time: 98.2120s
Epoch: 9 cost time: 5.513556480407715
Epoch: 9, Steps: 262 | Train Loss: 0.4451313 Vali Loss: 0.9581186 Test Loss: 0.4756377
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.4496131
	speed: 0.1198s/iter; left time: 647.3685s
	iters: 200, epoch: 10 | loss: 0.4195262
	speed: 0.0172s/iter; left time: 91.3767s
Epoch: 10 cost time: 5.3584980964660645
Epoch: 10, Steps: 262 | Train Loss: 0.4455114 Vali Loss: 0.9581062 Test Loss: 0.4755553
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3681856
	speed: 0.1123s/iter; left time: 577.3280s
	iters: 200, epoch: 11 | loss: 0.4202075
	speed: 0.0169s/iter; left time: 85.1304s
Epoch: 11 cost time: 5.3171467781066895
Epoch: 11, Steps: 262 | Train Loss: 0.4447900 Vali Loss: 0.9693098 Test Loss: 0.4755116
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : DLinear_ETTh1_96_192_DLinear_ETTh1_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.47576066851615906, mae:0.46335285902023315

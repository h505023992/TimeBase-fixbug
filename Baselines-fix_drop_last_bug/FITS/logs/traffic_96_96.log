Args in experiment:
Namespace(is_training=1, model_id='traffic_96_96', model='FITS', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=862, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=34, base_T=36, H_order=8)
Use GPU: cuda:0
>>>>>>>start training : traffic_96_96_FITS_custom_ftM_sl96_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 12089
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=34, out_features=68, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  255096832.0
params:  2380.0
Trainable parameters:  2380
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 14.046771049499512
Epoch: 1, Steps: 94 | Train Loss: 1.1533238 Vali Loss: 1.3407477 Test Loss: 1.5415773
Validation loss decreased (inf --> 1.340748).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 14.67483925819397
Epoch: 2, Steps: 94 | Train Loss: 0.8342766 Vali Loss: 1.1065954 Test Loss: 1.2756945
Validation loss decreased (1.340748 --> 1.106595).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 14.237891912460327
Epoch: 3, Steps: 94 | Train Loss: 0.6729778 Vali Loss: 0.9870391 Test Loss: 1.1412610
Validation loss decreased (1.106595 --> 0.987039).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 14.491941452026367
Epoch: 4, Steps: 94 | Train Loss: 0.5835075 Vali Loss: 0.9160687 Test Loss: 1.0606513
Validation loss decreased (0.987039 --> 0.916069).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 14.311657905578613
Epoch: 5, Steps: 94 | Train Loss: 0.5265433 Vali Loss: 0.8643132 Test Loss: 1.0056304
Validation loss decreased (0.916069 --> 0.864313).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 14.276670694351196
Epoch: 6, Steps: 94 | Train Loss: 0.4853429 Vali Loss: 0.8280805 Test Loss: 0.9624735
Validation loss decreased (0.864313 --> 0.828080).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 14.181853532791138
Epoch: 7, Steps: 94 | Train Loss: 0.4528687 Vali Loss: 0.7965495 Test Loss: 0.9270856
Validation loss decreased (0.828080 --> 0.796549).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 14.328653573989868
Epoch: 8, Steps: 94 | Train Loss: 0.4258234 Vali Loss: 0.7693350 Test Loss: 0.8957454
Validation loss decreased (0.796549 --> 0.769335).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 14.62178635597229
Epoch: 9, Steps: 94 | Train Loss: 0.4028411 Vali Loss: 0.7436058 Test Loss: 0.8689349
Validation loss decreased (0.769335 --> 0.743606).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 15.48643183708191
Epoch: 10, Steps: 94 | Train Loss: 0.3830473 Vali Loss: 0.7245916 Test Loss: 0.8459184
Validation loss decreased (0.743606 --> 0.724592).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 15.103816509246826
Epoch: 11, Steps: 94 | Train Loss: 0.3658030 Vali Loss: 0.7099550 Test Loss: 0.8260582
Validation loss decreased (0.724592 --> 0.709955).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 15.60777735710144
Epoch: 12, Steps: 94 | Train Loss: 0.3508006 Vali Loss: 0.6908621 Test Loss: 0.8070663
Validation loss decreased (0.709955 --> 0.690862).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 14.284258365631104
Epoch: 13, Steps: 94 | Train Loss: 0.3376350 Vali Loss: 0.6780371 Test Loss: 0.7905784
Validation loss decreased (0.690862 --> 0.678037).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 14.914081811904907
Epoch: 14, Steps: 94 | Train Loss: 0.3259124 Vali Loss: 0.6632225 Test Loss: 0.7759954
Validation loss decreased (0.678037 --> 0.663222).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 13.155695915222168
Epoch: 15, Steps: 94 | Train Loss: 0.3156526 Vali Loss: 0.6525388 Test Loss: 0.7630936
Validation loss decreased (0.663222 --> 0.652539).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 14.215561628341675
Epoch: 16, Steps: 94 | Train Loss: 0.3065625 Vali Loss: 0.6417172 Test Loss: 0.7524629
Validation loss decreased (0.652539 --> 0.641717).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 14.617661952972412
Epoch: 17, Steps: 94 | Train Loss: 0.2984519 Vali Loss: 0.6340715 Test Loss: 0.7423711
Validation loss decreased (0.641717 --> 0.634072).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 14.113154649734497
Epoch: 18, Steps: 94 | Train Loss: 0.2913428 Vali Loss: 0.6262064 Test Loss: 0.7333177
Validation loss decreased (0.634072 --> 0.626206).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 14.0284583568573
Epoch: 19, Steps: 94 | Train Loss: 0.2849218 Vali Loss: 0.6200964 Test Loss: 0.7257851
Validation loss decreased (0.626206 --> 0.620096).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 13.971726655960083
Epoch: 20, Steps: 94 | Train Loss: 0.2791486 Vali Loss: 0.6119874 Test Loss: 0.7186636
Validation loss decreased (0.620096 --> 0.611987).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 14.590643167495728
Epoch: 21, Steps: 94 | Train Loss: 0.2740188 Vali Loss: 0.6078736 Test Loss: 0.7124687
Validation loss decreased (0.611987 --> 0.607874).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 14.793952703475952
Epoch: 22, Steps: 94 | Train Loss: 0.2693321 Vali Loss: 0.6017157 Test Loss: 0.7066543
Validation loss decreased (0.607874 --> 0.601716).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 15.192849159240723
Epoch: 23, Steps: 94 | Train Loss: 0.2652029 Vali Loss: 0.6001773 Test Loss: 0.7017642
Validation loss decreased (0.601716 --> 0.600177).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 14.410280466079712
Epoch: 24, Steps: 94 | Train Loss: 0.2615231 Vali Loss: 0.5933416 Test Loss: 0.6969848
Validation loss decreased (0.600177 --> 0.593342).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 14.287995338439941
Epoch: 25, Steps: 94 | Train Loss: 0.2580352 Vali Loss: 0.5912494 Test Loss: 0.6930457
Validation loss decreased (0.593342 --> 0.591249).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 14.57935905456543
Epoch: 26, Steps: 94 | Train Loss: 0.2550792 Vali Loss: 0.5874656 Test Loss: 0.6893359
Validation loss decreased (0.591249 --> 0.587466).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 15.386326313018799
Epoch: 27, Steps: 94 | Train Loss: 0.2523044 Vali Loss: 0.5848114 Test Loss: 0.6860683
Validation loss decreased (0.587466 --> 0.584811).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 15.415927171707153
Epoch: 28, Steps: 94 | Train Loss: 0.2497754 Vali Loss: 0.5817387 Test Loss: 0.6830931
Validation loss decreased (0.584811 --> 0.581739).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 15.303082466125488
Epoch: 29, Steps: 94 | Train Loss: 0.2475191 Vali Loss: 0.5795150 Test Loss: 0.6804031
Validation loss decreased (0.581739 --> 0.579515).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 14.236791849136353
Epoch: 30, Steps: 94 | Train Loss: 0.2453981 Vali Loss: 0.5778306 Test Loss: 0.6779801
Validation loss decreased (0.579515 --> 0.577831).  Saving model ...
Updating learning rate to 0.00011296777049628277
train 12089
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=34, out_features=68, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  255096832.0
params:  2380.0
Trainable parameters:  2380
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 13.616673946380615
Epoch: 1, Steps: 94 | Train Loss: 0.4274569 Vali Loss: 0.5528215 Test Loss: 0.6512187
Validation loss decreased (inf --> 0.552821).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 14.190903186798096
Epoch: 2, Steps: 94 | Train Loss: 0.4153894 Vali Loss: 0.5479867 Test Loss: 0.6479637
Validation loss decreased (0.552821 --> 0.547987).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 14.127828359603882
Epoch: 3, Steps: 94 | Train Loss: 0.4139217 Vali Loss: 0.5485376 Test Loss: 0.6476808
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00045125
Epoch: 4 cost time: 13.833708763122559
Epoch: 4, Steps: 94 | Train Loss: 0.4136804 Vali Loss: 0.5486254 Test Loss: 0.6475094
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 13.587290287017822
Epoch: 5, Steps: 94 | Train Loss: 0.4135926 Vali Loss: 0.5492958 Test Loss: 0.6474429
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 13.301446676254272
Epoch: 6, Steps: 94 | Train Loss: 0.4135728 Vali Loss: 0.5471282 Test Loss: 0.6473311
Validation loss decreased (0.547987 --> 0.547128).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 14.169599771499634
Epoch: 7, Steps: 94 | Train Loss: 0.4134288 Vali Loss: 0.5499886 Test Loss: 0.6471649
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 14.574321269989014
Epoch: 8, Steps: 94 | Train Loss: 0.4134035 Vali Loss: 0.5484644 Test Loss: 0.6471218
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 14.05331301689148
Epoch: 9, Steps: 94 | Train Loss: 0.4132655 Vali Loss: 0.5484408 Test Loss: 0.6470413
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 15.335378646850586
Epoch: 10, Steps: 94 | Train Loss: 0.4132190 Vali Loss: 0.5464220 Test Loss: 0.6470274
Validation loss decreased (0.547128 --> 0.546422).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 15.18363904953003
Epoch: 11, Steps: 94 | Train Loss: 0.4133113 Vali Loss: 0.5499392 Test Loss: 0.6468980
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 15.155117988586426
Epoch: 12, Steps: 94 | Train Loss: 0.4130607 Vali Loss: 0.5492963 Test Loss: 0.6469021
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 14.628230810165405
Epoch: 13, Steps: 94 | Train Loss: 0.4131612 Vali Loss: 0.5492389 Test Loss: 0.6469116
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 14.711594343185425
Epoch: 14, Steps: 94 | Train Loss: 0.4132673 Vali Loss: 0.5487136 Test Loss: 0.6469963
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 13.736515522003174
Epoch: 15, Steps: 94 | Train Loss: 0.4131286 Vali Loss: 0.5472434 Test Loss: 0.6467633
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : traffic_96_96_FITS_custom_ftM_sl96_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.6512741446495056, mae:0.38865527510643005, rse:0.668244481086731, corr:[0.27484933 0.29143742 0.29172894 0.2907947  0.28862092 0.28866932
 0.28834683 0.28744578 0.28765067 0.2878291  0.28798664 0.2886306
 0.28840014 0.28801602 0.2882502  0.28822964 0.2881606  0.2886672
 0.28886685 0.28900936 0.28917262 0.28859395 0.2886753  0.29491475
 0.30734226 0.30905527 0.30667347 0.30497494 0.30388632 0.3033523
 0.30319273 0.30263996 0.30191034 0.30225867 0.30261052 0.30247596
 0.30278236 0.3028465  0.30256283 0.30293626 0.30326197 0.3031413
 0.30386427 0.3046132  0.30465105 0.30584517 0.3078854  0.3062885
 0.29509345 0.28919646 0.28915167 0.2896932  0.28983605 0.28941357
 0.2893046  0.28944722 0.28909588 0.28873327 0.28892675 0.28904548
 0.28900707 0.2893315  0.28942972 0.28909668 0.2889736  0.2893106
 0.28979734 0.2903201  0.291261   0.2932821  0.29544085 0.29325593
 0.28533247 0.28333348 0.28529817 0.28625324 0.2859892  0.2859969
 0.285945   0.2855818  0.28569308 0.28578526 0.28560486 0.28566143
 0.28576243 0.2858532  0.28647667 0.28683174 0.28619716 0.2859331
 0.28604382 0.28534275 0.28537858 0.28622276 0.285867   0.28775412]

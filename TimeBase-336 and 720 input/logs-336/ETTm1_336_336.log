Args in experiment:
Namespace(is_training=1, model_id='ETTm1-i_336_336', model='LightTimeBaseTST', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, period_len=4, basis_num=20, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=1, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.1, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=7, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:7
24248
>>>>>>>start training : ETTm1-i_336_336_LightTimeBaseTST_ETTm1_ftM_sl336_pl336_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
Epoch: 1 cost time: 11.613420486450195
Epoch: 1, Steps: 67 | Train Loss: 0.4931709 Vali Loss: 0.7997344 Test Loss: 0.5022256
Validation loss decreased (inf --> 0.799734).  Saving model ...
Updating learning rate to 0.1
Epoch: 2 cost time: 10.161388158798218
Epoch: 2, Steps: 67 | Train Loss: 0.6335005 Vali Loss: 0.7851260 Test Loss: 0.4760025
Validation loss decreased (0.799734 --> 0.785126).  Saving model ...
Updating learning rate to 0.1
Epoch: 3 cost time: 9.628785610198975
Epoch: 3, Steps: 67 | Train Loss: 0.4017422 Vali Loss: 0.7315289 Test Loss: 0.4315652
Validation loss decreased (0.785126 --> 0.731529).  Saving model ...
Updating learning rate to 0.1
Epoch: 4 cost time: 11.112923622131348
Epoch: 4, Steps: 67 | Train Loss: 0.3887810 Vali Loss: 0.7615053 Test Loss: 0.4546877
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.08000000000000002
Epoch: 5 cost time: 9.70975112915039
Epoch: 5, Steps: 67 | Train Loss: 0.3790858 Vali Loss: 0.7090689 Test Loss: 0.4154393
Validation loss decreased (0.731529 --> 0.709069).  Saving model ...
Updating learning rate to 0.06400000000000002
Epoch: 6 cost time: 9.836791038513184
Epoch: 6, Steps: 67 | Train Loss: 0.3726316 Vali Loss: 0.7076994 Test Loss: 0.4281500
Validation loss decreased (0.709069 --> 0.707699).  Saving model ...
Updating learning rate to 0.051200000000000016
Epoch: 7 cost time: 10.811573028564453
Epoch: 7, Steps: 67 | Train Loss: 0.3712584 Vali Loss: 0.6918035 Test Loss: 0.4043898
Validation loss decreased (0.707699 --> 0.691804).  Saving model ...
Updating learning rate to 0.04096000000000001
Epoch: 8 cost time: 9.195175647735596
Epoch: 8, Steps: 67 | Train Loss: 0.3627310 Vali Loss: 0.6915600 Test Loss: 0.4115190
Validation loss decreased (0.691804 --> 0.691560).  Saving model ...
Updating learning rate to 0.03276800000000001
Epoch: 9 cost time: 10.83506464958191
Epoch: 9, Steps: 67 | Train Loss: 0.3634919 Vali Loss: 0.6898797 Test Loss: 0.4019084
Validation loss decreased (0.691560 --> 0.689880).  Saving model ...
Updating learning rate to 0.026214400000000013
Epoch: 10 cost time: 10.110803842544556
Epoch: 10, Steps: 67 | Train Loss: 0.3574220 Vali Loss: 0.6796490 Test Loss: 0.3880335
Validation loss decreased (0.689880 --> 0.679649).  Saving model ...
Updating learning rate to 0.020971520000000007
Epoch: 11 cost time: 9.869119644165039
Epoch: 11, Steps: 67 | Train Loss: 0.3552522 Vali Loss: 0.6644598 Test Loss: 0.3883276
Validation loss decreased (0.679649 --> 0.664460).  Saving model ...
Updating learning rate to 0.016777216000000008
Epoch: 12 cost time: 11.34967589378357
Epoch: 12, Steps: 67 | Train Loss: 0.3531659 Vali Loss: 0.6748431 Test Loss: 0.3868615
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.013421772800000007
Epoch: 13 cost time: 10.9765145778656
Epoch: 13, Steps: 67 | Train Loss: 0.3528258 Vali Loss: 0.6602833 Test Loss: 0.3846604
Validation loss decreased (0.664460 --> 0.660283).  Saving model ...
Updating learning rate to 0.010737418240000006
Epoch: 14 cost time: 11.861982107162476
Epoch: 14, Steps: 67 | Train Loss: 0.3500523 Vali Loss: 0.6580899 Test Loss: 0.3809285
Validation loss decreased (0.660283 --> 0.658090).  Saving model ...
Updating learning rate to 0.008589934592000005
Epoch: 15 cost time: 11.687461614608765
Epoch: 15, Steps: 67 | Train Loss: 0.3491514 Vali Loss: 0.6628023 Test Loss: 0.3798891
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0068719476736000045
Epoch: 16 cost time: 9.708661556243896
Epoch: 16, Steps: 67 | Train Loss: 0.3491904 Vali Loss: 0.6541006 Test Loss: 0.3791617
Validation loss decreased (0.658090 --> 0.654101).  Saving model ...
Updating learning rate to 0.005497558138880004
Epoch: 17 cost time: 11.52691650390625
Epoch: 17, Steps: 67 | Train Loss: 0.3473244 Vali Loss: 0.6558304 Test Loss: 0.3764807
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.004398046511104004
Epoch: 18 cost time: 10.464531183242798
Epoch: 18, Steps: 67 | Train Loss: 0.3467585 Vali Loss: 0.6545987 Test Loss: 0.3750840
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0035184372088832034
Epoch: 19 cost time: 10.935327053070068
Epoch: 19, Steps: 67 | Train Loss: 0.3465653 Vali Loss: 0.6539630 Test Loss: 0.3767051
Validation loss decreased (0.654101 --> 0.653963).  Saving model ...
Updating learning rate to 0.0028147497671065624
Epoch: 20 cost time: 11.820108652114868
Epoch: 20, Steps: 67 | Train Loss: 0.3457565 Vali Loss: 0.6531475 Test Loss: 0.3753733
Validation loss decreased (0.653963 --> 0.653147).  Saving model ...
Updating learning rate to 0.0022517998136852503
Epoch: 21 cost time: 11.33480429649353
Epoch: 21, Steps: 67 | Train Loss: 0.3455245 Vali Loss: 0.6508530 Test Loss: 0.3749717
Validation loss decreased (0.653147 --> 0.650853).  Saving model ...
Updating learning rate to 0.0018014398509482003
Epoch: 22 cost time: 10.614084482192993
Epoch: 22, Steps: 67 | Train Loss: 0.3453000 Vali Loss: 0.6487820 Test Loss: 0.3742143
Validation loss decreased (0.650853 --> 0.648782).  Saving model ...
Updating learning rate to 0.0014411518807585604
Epoch: 23 cost time: 11.456525564193726
Epoch: 23, Steps: 67 | Train Loss: 0.3446957 Vali Loss: 0.6490193 Test Loss: 0.3737196
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0011529215046068484
Epoch: 24 cost time: 9.924128532409668
Epoch: 24, Steps: 67 | Train Loss: 0.3445774 Vali Loss: 0.6487322 Test Loss: 0.3741533
Validation loss decreased (0.648782 --> 0.648732).  Saving model ...
Updating learning rate to 0.0009223372036854787
Epoch: 25 cost time: 10.117179870605469
Epoch: 25, Steps: 67 | Train Loss: 0.3444471 Vali Loss: 0.6481175 Test Loss: 0.3731050
Validation loss decreased (0.648732 --> 0.648118).  Saving model ...
Updating learning rate to 0.000737869762948383
Epoch: 26 cost time: 10.684370040893555
Epoch: 26, Steps: 67 | Train Loss: 0.3437414 Vali Loss: 0.6455886 Test Loss: 0.3734918
Validation loss decreased (0.648118 --> 0.645589).  Saving model ...
Updating learning rate to 0.0005902958103587065
Epoch: 27 cost time: 11.156629085540771
Epoch: 27, Steps: 67 | Train Loss: 0.3432849 Vali Loss: 0.6484812 Test Loss: 0.3731403
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0004722366482869652
Epoch: 28 cost time: 12.051822185516357
Epoch: 28, Steps: 67 | Train Loss: 0.3440353 Vali Loss: 0.6498824 Test Loss: 0.3731080
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0003777893186295722
Epoch: 29 cost time: 10.580907583236694
Epoch: 29, Steps: 67 | Train Loss: 0.3436754 Vali Loss: 0.6481459 Test Loss: 0.3732214
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00030223145490365774
Epoch: 30 cost time: 12.081790924072266
Epoch: 30, Steps: 67 | Train Loss: 0.3433951 Vali Loss: 0.6483394 Test Loss: 0.3725576
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0002417851639229262
>>>>>>>testing : ETTm1-i_336_336_LightTimeBaseTST_ETTm1_ftM_sl336_pl336_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.37296023964881897, mae:0.3894191086292267, rse:0.5811384320259094

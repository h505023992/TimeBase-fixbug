Args in experiment:
Namespace(is_training=1, model_id='Electricity_720_96', model='LightTimeBaseTST', data='custom', root_path='./dataset/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=96, period_len=24, basis_num=6, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=321, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.02, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=3, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:3
214
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 1571616.0
Params: 214.0
1.57M MACs
>>>>>>>start training : Electricity_720_96_LightTimeBaseTST_custom_ftM_sl720_pl96_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17597
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2613742
	speed: 0.1280s/iter; left time: 517.2612s
Max Memory (MB): 420.2255859375
Epoch: 1 cost time: 16.749839544296265
Epoch: 1, Steps: 138 | Train Loss: 0.2682365 Vali Loss: 0.2110922 Test Loss: 0.2387860
Validation loss decreased (inf --> 0.211092).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 2 | loss: 0.1505875
	speed: 0.2586s/iter; left time: 1009.4698s
Max Memory (MB): 472.09619140625
Epoch: 2 cost time: 16.893380641937256
Epoch: 2, Steps: 138 | Train Loss: 0.1619328 Vali Loss: 0.1219388 Test Loss: 0.1444096
Validation loss decreased (0.211092 --> 0.121939).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 3 | loss: 0.1435438
	speed: 0.2777s/iter; left time: 1045.5315s
Max Memory (MB): 473.04931640625
Epoch: 3 cost time: 17.412044525146484
Epoch: 3, Steps: 138 | Train Loss: 0.1448151 Vali Loss: 0.1204112 Test Loss: 0.1441758
Validation loss decreased (0.121939 --> 0.120411).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 4 | loss: 0.1484803
	speed: 0.2770s/iter; left time: 1004.8005s
Max Memory (MB): 473.04931640625
Epoch: 4 cost time: 17.146075010299683
Epoch: 4, Steps: 138 | Train Loss: 0.1447136 Vali Loss: 0.1208800 Test Loss: 0.1450621
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.016
	iters: 100, epoch: 5 | loss: 0.1456533
	speed: 0.2764s/iter; left time: 964.3411s
Max Memory (MB): 473.04931640625
Epoch: 5 cost time: 17.162921667099
Epoch: 5, Steps: 138 | Train Loss: 0.1436213 Vali Loss: 0.1202564 Test Loss: 0.1434121
Validation loss decreased (0.120411 --> 0.120256).  Saving model ...
Updating learning rate to 0.012800000000000002
	iters: 100, epoch: 6 | loss: 0.1433076
	speed: 0.2788s/iter; left time: 934.2543s
Max Memory (MB): 473.04931640625
Epoch: 6 cost time: 17.528916120529175
Epoch: 6, Steps: 138 | Train Loss: 0.1433168 Vali Loss: 0.1213887 Test Loss: 0.1459077
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.010240000000000003
	iters: 100, epoch: 7 | loss: 0.1430546
	speed: 0.2718s/iter; left time: 873.4085s
Max Memory (MB): 473.04931640625
Epoch: 7 cost time: 17.486633777618408
Epoch: 7, Steps: 138 | Train Loss: 0.1428466 Vali Loss: 0.1191668 Test Loss: 0.1418589
Validation loss decreased (0.120256 --> 0.119167).  Saving model ...
Updating learning rate to 0.008192000000000001
	iters: 100, epoch: 8 | loss: 0.1425158
	speed: 0.2818s/iter; left time: 866.4872s
Max Memory (MB): 473.04931640625
Epoch: 8 cost time: 17.505189895629883
Epoch: 8, Steps: 138 | Train Loss: 0.1424785 Vali Loss: 0.1200859 Test Loss: 0.1437624
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0065536000000000014
	iters: 100, epoch: 9 | loss: 0.1395596
	speed: 0.2747s/iter; left time: 806.8896s
Max Memory (MB): 473.04931640625
Epoch: 9 cost time: 17.42071509361267
Epoch: 9, Steps: 138 | Train Loss: 0.1422793 Vali Loss: 0.1194091 Test Loss: 0.1425216
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.005242880000000002
	iters: 100, epoch: 10 | loss: 0.1321490
	speed: 0.2780s/iter; left time: 778.2177s
Max Memory (MB): 473.04931640625
Epoch: 10 cost time: 17.415393829345703
Epoch: 10, Steps: 138 | Train Loss: 0.1421665 Vali Loss: 0.1188899 Test Loss: 0.1420234
Validation loss decreased (0.119167 --> 0.118890).  Saving model ...
Updating learning rate to 0.004194304000000002
	iters: 100, epoch: 11 | loss: 0.1295584
	speed: 0.2730s/iter; left time: 726.5440s
Max Memory (MB): 473.04931640625
Epoch: 11 cost time: 17.19319748878479
Epoch: 11, Steps: 138 | Train Loss: 0.1419479 Vali Loss: 0.1185432 Test Loss: 0.1417988
Validation loss decreased (0.118890 --> 0.118543).  Saving model ...
Updating learning rate to 0.003355443200000002
	iters: 100, epoch: 12 | loss: 0.1500051
	speed: 0.2747s/iter; left time: 693.1227s
Max Memory (MB): 473.04931640625
Epoch: 12 cost time: 17.38242268562317
Epoch: 12, Steps: 138 | Train Loss: 0.1416555 Vali Loss: 0.1183505 Test Loss: 0.1416571
Validation loss decreased (0.118543 --> 0.118350).  Saving model ...
Updating learning rate to 0.002684354560000001
	iters: 100, epoch: 13 | loss: 0.1422496
	speed: 0.2765s/iter; left time: 659.4979s
Max Memory (MB): 473.04931640625
Epoch: 13 cost time: 17.18741750717163
Epoch: 13, Steps: 138 | Train Loss: 0.1415157 Vali Loss: 0.1185873 Test Loss: 0.1415301
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0021474836480000013
	iters: 100, epoch: 14 | loss: 0.1459886
	speed: 0.2779s/iter; left time: 624.5113s
Max Memory (MB): 473.04931640625
Epoch: 14 cost time: 17.256755828857422
Epoch: 14, Steps: 138 | Train Loss: 0.1413813 Vali Loss: 0.1186135 Test Loss: 0.1419594
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0017179869184000011
	iters: 100, epoch: 15 | loss: 0.1522924
	speed: 0.2706s/iter; left time: 570.6495s
Max Memory (MB): 473.04931640625
Epoch: 15 cost time: 16.863791465759277
Epoch: 15, Steps: 138 | Train Loss: 0.1412706 Vali Loss: 0.1185144 Test Loss: 0.1415340
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0013743895347200009
	iters: 100, epoch: 16 | loss: 0.1496401
	speed: 0.2739s/iter; left time: 539.8674s
Max Memory (MB): 473.04931640625
Epoch: 16 cost time: 17.423949241638184
Epoch: 16, Steps: 138 | Train Loss: 0.1412892 Vali Loss: 0.1180868 Test Loss: 0.1412275
Validation loss decreased (0.118350 --> 0.118087).  Saving model ...
Updating learning rate to 0.0010995116277760007
	iters: 100, epoch: 17 | loss: 0.1507759
	speed: 0.2760s/iter; left time: 505.9012s
Max Memory (MB): 473.04931640625
Epoch: 17 cost time: 17.315990447998047
Epoch: 17, Steps: 138 | Train Loss: 0.1412083 Vali Loss: 0.1182307 Test Loss: 0.1414547
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0008796093022208007
	iters: 100, epoch: 18 | loss: 0.1417605
	speed: 0.2724s/iter; left time: 461.6916s
Max Memory (MB): 473.04931640625
Epoch: 18 cost time: 17.255162000656128
Epoch: 18, Steps: 138 | Train Loss: 0.1411935 Vali Loss: 0.1182041 Test Loss: 0.1413383
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0007036874417766406
	iters: 100, epoch: 19 | loss: 0.1444974
	speed: 0.2751s/iter; left time: 428.2819s
Max Memory (MB): 473.04931640625
Epoch: 19 cost time: 17.085142374038696
Epoch: 19, Steps: 138 | Train Loss: 0.1411900 Vali Loss: 0.1182882 Test Loss: 0.1412255
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0005629499534213125
	iters: 100, epoch: 20 | loss: 0.1302579
	speed: 0.2743s/iter; left time: 389.2750s
Max Memory (MB): 473.04931640625
Epoch: 20 cost time: 17.32695460319519
Epoch: 20, Steps: 138 | Train Loss: 0.1410717 Vali Loss: 0.1182548 Test Loss: 0.1414474
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0004503599627370501
	iters: 100, epoch: 21 | loss: 0.1374757
	speed: 0.2755s/iter; left time: 352.9246s
Max Memory (MB): 473.04931640625
Epoch: 21 cost time: 17.21126079559326
Epoch: 21, Steps: 138 | Train Loss: 0.1410881 Vali Loss: 0.1180370 Test Loss: 0.1411429
Validation loss decreased (0.118087 --> 0.118037).  Saving model ...
Updating learning rate to 0.00036028797018964004
	iters: 100, epoch: 22 | loss: 0.1522347
	speed: 0.2724s/iter; left time: 311.3021s
Max Memory (MB): 473.04931640625
Epoch: 22 cost time: 17.229100227355957
Epoch: 22, Steps: 138 | Train Loss: 0.1410272 Vali Loss: 0.1181069 Test Loss: 0.1411263
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00028823037615171204
	iters: 100, epoch: 23 | loss: 0.1422578
	speed: 0.2736s/iter; left time: 274.9650s
Max Memory (MB): 473.04931640625
Epoch: 23 cost time: 17.18775725364685
Epoch: 23, Steps: 138 | Train Loss: 0.1410259 Vali Loss: 0.1180748 Test Loss: 0.1411037
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00023058430092136968
	iters: 100, epoch: 24 | loss: 0.1329017
	speed: 0.2779s/iter; left time: 240.9085s
Max Memory (MB): 473.04931640625
Epoch: 24 cost time: 17.47026777267456
Epoch: 24, Steps: 138 | Train Loss: 0.1410049 Vali Loss: 0.1181225 Test Loss: 0.1410781
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00018446744073709575
	iters: 100, epoch: 25 | loss: 0.1295842
	speed: 0.2799s/iter; left time: 204.0427s
Max Memory (MB): 473.04931640625
Epoch: 25 cost time: 17.65435218811035
Epoch: 25, Steps: 138 | Train Loss: 0.1410339 Vali Loss: 0.1179665 Test Loss: 0.1411379
Validation loss decreased (0.118037 --> 0.117967).  Saving model ...
Updating learning rate to 0.0001475739525896766
	iters: 100, epoch: 26 | loss: 0.1308383
	speed: 0.2741s/iter; left time: 162.0050s
Max Memory (MB): 473.04931640625
Epoch: 26 cost time: 17.384815216064453
Epoch: 26, Steps: 138 | Train Loss: 0.1409221 Vali Loss: 0.1180958 Test Loss: 0.1411000
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00011805916207174128
	iters: 100, epoch: 27 | loss: 0.1427963
	speed: 0.2646s/iter; left time: 119.8689s
Max Memory (MB): 473.04931640625
Epoch: 27 cost time: 16.143176794052124
Epoch: 27, Steps: 138 | Train Loss: 0.1409425 Vali Loss: 0.1181052 Test Loss: 0.1410685
EarlyStopping counter: 2 out of 5
Updating learning rate to 9.444732965739304e-05
	iters: 100, epoch: 28 | loss: 0.1363594
	speed: 0.2588s/iter; left time: 81.5324s
Max Memory (MB): 473.04931640625
Epoch: 28 cost time: 16.394758462905884
Epoch: 28, Steps: 138 | Train Loss: 0.1409434 Vali Loss: 0.1181715 Test Loss: 0.1411194
EarlyStopping counter: 3 out of 5
Updating learning rate to 7.555786372591443e-05
	iters: 100, epoch: 29 | loss: 0.1402622
	speed: 0.2660s/iter; left time: 47.0740s
Max Memory (MB): 473.04931640625
Epoch: 29 cost time: 16.436142206192017
Epoch: 29, Steps: 138 | Train Loss: 0.1409226 Vali Loss: 0.1180748 Test Loss: 0.1410135
EarlyStopping counter: 4 out of 5
Updating learning rate to 6.044629098073155e-05
	iters: 100, epoch: 30 | loss: 0.1389933
	speed: 0.2660s/iter; left time: 10.3745s
Max Memory (MB): 473.04931640625
Epoch: 30 cost time: 16.469861268997192
Epoch: 30, Steps: 138 | Train Loss: 0.1409182 Vali Loss: 0.1181076 Test Loss: 0.1411142
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 473.04931640625
>>>>>>>testing : Electricity_720_96_LightTimeBaseTST_custom_ftM_sl720_pl96_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
mse:0.1394324322938919, mae:0.23143820869922638, rse:0.37245824933052063

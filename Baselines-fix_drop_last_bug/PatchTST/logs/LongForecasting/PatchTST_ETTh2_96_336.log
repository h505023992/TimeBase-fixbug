Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='96_336', model='PatchTST', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, fc_dropout=0.3, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:1
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 1795584.0
Params: 81296.0
1.80M MACs
>>>>>>>start training : 96_336_PatchTST_ETTh2_ftM_sl96_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
Epoch: 1 cost time: 7.445483684539795
Epoch: 1, Steps: 65 | Train Loss: 0.7843738 Vali Loss: 0.4314376 Test Loss: 0.4887027
Validation loss decreased (inf --> 0.431438).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 7.487271785736084
Epoch: 2, Steps: 65 | Train Loss: 0.7557342 Vali Loss: 0.4132658 Test Loss: 0.4685323
Validation loss decreased (0.431438 --> 0.413266).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 7.6695849895477295
Epoch: 3, Steps: 65 | Train Loss: 0.7241351 Vali Loss: 0.3979422 Test Loss: 0.4530181
Validation loss decreased (0.413266 --> 0.397942).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 7.602439880371094
Epoch: 4, Steps: 65 | Train Loss: 0.7022660 Vali Loss: 0.3852233 Test Loss: 0.4413773
Validation loss decreased (0.397942 --> 0.385223).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 6.487771272659302
Epoch: 5, Steps: 65 | Train Loss: 0.6880516 Vali Loss: 0.3781038 Test Loss: 0.4349204
Validation loss decreased (0.385223 --> 0.378104).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 8.143710136413574
Epoch: 6, Steps: 65 | Train Loss: 0.6783785 Vali Loss: 0.3739477 Test Loss: 0.4310655
Validation loss decreased (0.378104 --> 0.373948).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 7.9271252155303955
Epoch: 7, Steps: 65 | Train Loss: 0.6696427 Vali Loss: 0.3712108 Test Loss: 0.4291261
Validation loss decreased (0.373948 --> 0.371211).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 7.445699691772461
Epoch: 8, Steps: 65 | Train Loss: 0.6660311 Vali Loss: 0.3696593 Test Loss: 0.4274485
Validation loss decreased (0.371211 --> 0.369659).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 7.6403968334198
Epoch: 9, Steps: 65 | Train Loss: 0.6692288 Vali Loss: 0.3684652 Test Loss: 0.4264142
Validation loss decreased (0.369659 --> 0.368465).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 7.726055145263672
Epoch: 10, Steps: 65 | Train Loss: 0.6573614 Vali Loss: 0.3679933 Test Loss: 0.4257058
Validation loss decreased (0.368465 --> 0.367993).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 7.499738693237305
Epoch: 11, Steps: 65 | Train Loss: 0.6568461 Vali Loss: 0.3672284 Test Loss: 0.4252880
Validation loss decreased (0.367993 --> 0.367228).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 7.7671897411346436
Epoch: 12, Steps: 65 | Train Loss: 0.6639703 Vali Loss: 0.3668473 Test Loss: 0.4248546
Validation loss decreased (0.367228 --> 0.366847).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 7.810183525085449
Epoch: 13, Steps: 65 | Train Loss: 0.6584027 Vali Loss: 0.3667610 Test Loss: 0.4243830
Validation loss decreased (0.366847 --> 0.366761).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 7.526533603668213
Epoch: 14, Steps: 65 | Train Loss: 0.6552109 Vali Loss: 0.3663436 Test Loss: 0.4241309
Validation loss decreased (0.366761 --> 0.366344).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 7.76103401184082
Epoch: 15, Steps: 65 | Train Loss: 0.6531693 Vali Loss: 0.3663416 Test Loss: 0.4238098
Validation loss decreased (0.366344 --> 0.366342).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 8.500900506973267
Epoch: 16, Steps: 65 | Train Loss: 0.6526742 Vali Loss: 0.3657261 Test Loss: 0.4237310
Validation loss decreased (0.366342 --> 0.365726).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 7.834441900253296
Epoch: 17, Steps: 65 | Train Loss: 0.6591189 Vali Loss: 0.3655210 Test Loss: 0.4236059
Validation loss decreased (0.365726 --> 0.365521).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 7.8230907917022705
Epoch: 18, Steps: 65 | Train Loss: 0.6589487 Vali Loss: 0.3652121 Test Loss: 0.4235520
Validation loss decreased (0.365521 --> 0.365212).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 7.259572267532349
Epoch: 19, Steps: 65 | Train Loss: 0.6584142 Vali Loss: 0.3652252 Test Loss: 0.4233037
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 7.632207155227661
Epoch: 20, Steps: 65 | Train Loss: 0.6521617 Vali Loss: 0.3651214 Test Loss: 0.4234281
Validation loss decreased (0.365212 --> 0.365121).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 7.757723331451416
Epoch: 21, Steps: 65 | Train Loss: 0.6598527 Vali Loss: 0.3651423 Test Loss: 0.4232032
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 8.075531482696533
Epoch: 22, Steps: 65 | Train Loss: 0.6651454 Vali Loss: 0.3653671 Test Loss: 0.4230440
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 7.678513765335083
Epoch: 23, Steps: 65 | Train Loss: 0.6493774 Vali Loss: 0.3653447 Test Loss: 0.4229220
EarlyStopping counter: 3 out of 5
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 7.498109340667725
Epoch: 24, Steps: 65 | Train Loss: 0.6510547 Vali Loss: 0.3648652 Test Loss: 0.4230258
Validation loss decreased (0.365121 --> 0.364865).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 8.202075481414795
Epoch: 25, Steps: 65 | Train Loss: 0.6504996 Vali Loss: 0.3648298 Test Loss: 0.4229659
Validation loss decreased (0.364865 --> 0.364830).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 7.83527946472168
Epoch: 26, Steps: 65 | Train Loss: 0.6546054 Vali Loss: 0.3649384 Test Loss: 0.4228964
EarlyStopping counter: 1 out of 5
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 7.640733003616333
Epoch: 27, Steps: 65 | Train Loss: 0.6546619 Vali Loss: 0.3651114 Test Loss: 0.4229009
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 8.430873394012451
Epoch: 28, Steps: 65 | Train Loss: 0.6554915 Vali Loss: 0.3645699 Test Loss: 0.4228718
Validation loss decreased (0.364830 --> 0.364570).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 7.863027095794678
Epoch: 29, Steps: 65 | Train Loss: 0.6559961 Vali Loss: 0.3650177 Test Loss: 0.4227843
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 7.634352922439575
Epoch: 30, Steps: 65 | Train Loss: 0.6553295 Vali Loss: 0.3646706 Test Loss: 0.4227853
EarlyStopping counter: 2 out of 5
Updating learning rate to 5.8149737003040096e-06
>>>>>>>testing : 96_336_PatchTST_ETTh2_ftM_sl96_ll48_pl336_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4181908071041107, mae:0.42843180894851685, rse:0.5170431733131409

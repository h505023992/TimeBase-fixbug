Args in experiment:
Namespace(is_training=1, model_id='ETTh1_336_336', model='LightTimeBaseTST', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, period_len=24, basis_num=6, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.12, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=512, patience=5, learning_rate=0.1, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=6, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:6
188
>>>>>>>start training : ETTh1_336_336_LightTimeBaseTST_ETTh1_ftM_sl336_pl336_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
Epoch: 1 cost time: 4.512400388717651
Epoch: 1, Steps: 16 | Train Loss: 0.5814509 Vali Loss: 1.3185682 Test Loss: 0.4872998
Validation loss decreased (inf --> 1.318568).  Saving model ...
Updating learning rate to 0.1
Epoch: 2 cost time: 2.7101221084594727
Epoch: 2, Steps: 16 | Train Loss: 0.5966542 Vali Loss: 1.4142356 Test Loss: 0.5875999
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.1
Epoch: 3 cost time: 2.932816505432129
Epoch: 3, Steps: 16 | Train Loss: 0.6340971 Vali Loss: 1.3146223 Test Loss: 0.4748965
Validation loss decreased (1.318568 --> 1.314622).  Saving model ...
Updating learning rate to 0.1
Epoch: 4 cost time: 2.9215025901794434
Epoch: 4, Steps: 16 | Train Loss: 0.5342947 Vali Loss: 1.3023366 Test Loss: 0.4603090
Validation loss decreased (1.314622 --> 1.302337).  Saving model ...
Updating learning rate to 0.08000000000000002
Epoch: 5 cost time: 3.3489716053009033
Epoch: 5, Steps: 16 | Train Loss: 0.5189623 Vali Loss: 1.2756600 Test Loss: 0.4389314
Validation loss decreased (1.302337 --> 1.275660).  Saving model ...
Updating learning rate to 0.06400000000000002
Epoch: 6 cost time: 2.7901785373687744
Epoch: 6, Steps: 16 | Train Loss: 0.4977791 Vali Loss: 1.2559869 Test Loss: 0.4309510
Validation loss decreased (1.275660 --> 1.255987).  Saving model ...
Updating learning rate to 0.051200000000000016
Epoch: 7 cost time: 2.815925121307373
Epoch: 7, Steps: 16 | Train Loss: 0.4909936 Vali Loss: 1.2396092 Test Loss: 0.4256777
Validation loss decreased (1.255987 --> 1.239609).  Saving model ...
Updating learning rate to 0.04096000000000001
Epoch: 8 cost time: 2.8675482273101807
Epoch: 8, Steps: 16 | Train Loss: 0.4862330 Vali Loss: 1.2397234 Test Loss: 0.4270602
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.03276800000000001
Epoch: 9 cost time: 3.1980669498443604
Epoch: 9, Steps: 16 | Train Loss: 0.4840557 Vali Loss: 1.2298611 Test Loss: 0.4245088
Validation loss decreased (1.239609 --> 1.229861).  Saving model ...
Updating learning rate to 0.026214400000000013
Epoch: 10 cost time: 2.6678638458251953
Epoch: 10, Steps: 16 | Train Loss: 0.4816002 Vali Loss: 1.2182423 Test Loss: 0.4224465
Validation loss decreased (1.229861 --> 1.218242).  Saving model ...
Updating learning rate to 0.020971520000000007
Epoch: 11 cost time: 3.324620008468628
Epoch: 11, Steps: 16 | Train Loss: 0.4798515 Vali Loss: 1.2210795 Test Loss: 0.4235925
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.016777216000000008
Epoch: 12 cost time: 2.532975912094116
Epoch: 12, Steps: 16 | Train Loss: 0.4788920 Vali Loss: 1.2140249 Test Loss: 0.4228655
Validation loss decreased (1.218242 --> 1.214025).  Saving model ...
Updating learning rate to 0.013421772800000007
Epoch: 13 cost time: 2.9375569820404053
Epoch: 13, Steps: 16 | Train Loss: 0.4773397 Vali Loss: 1.2149353 Test Loss: 0.4242844
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.010737418240000006
Epoch: 14 cost time: 2.7231545448303223
Epoch: 14, Steps: 16 | Train Loss: 0.4772644 Vali Loss: 1.2125840 Test Loss: 0.4242427
Validation loss decreased (1.214025 --> 1.212584).  Saving model ...
Updating learning rate to 0.008589934592000005
Epoch: 15 cost time: 2.8163347244262695
Epoch: 15, Steps: 16 | Train Loss: 0.4769743 Vali Loss: 1.2118002 Test Loss: 0.4246570
Validation loss decreased (1.212584 --> 1.211800).  Saving model ...
Updating learning rate to 0.0068719476736000045
Epoch: 16 cost time: 3.1912176609039307
Epoch: 16, Steps: 16 | Train Loss: 0.4761251 Vali Loss: 1.2091688 Test Loss: 0.4247661
Validation loss decreased (1.211800 --> 1.209169).  Saving model ...
Updating learning rate to 0.005497558138880004
Epoch: 17 cost time: 3.0656321048736572
Epoch: 17, Steps: 16 | Train Loss: 0.4764315 Vali Loss: 1.2098984 Test Loss: 0.4251269
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.004398046511104004
Epoch: 18 cost time: 2.8127119541168213
Epoch: 18, Steps: 16 | Train Loss: 0.4766763 Vali Loss: 1.2093861 Test Loss: 0.4252555
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0035184372088832034
Epoch: 19 cost time: 3.011237144470215
Epoch: 19, Steps: 16 | Train Loss: 0.4748741 Vali Loss: 1.2088404 Test Loss: 0.4252073
Validation loss decreased (1.209169 --> 1.208840).  Saving model ...
Updating learning rate to 0.0028147497671065624
Epoch: 20 cost time: 2.9992949962615967
Epoch: 20, Steps: 16 | Train Loss: 0.4756353 Vali Loss: 1.2076792 Test Loss: 0.4251769
Validation loss decreased (1.208840 --> 1.207679).  Saving model ...
Updating learning rate to 0.0022517998136852503
Epoch: 21 cost time: 3.1495754718780518
Epoch: 21, Steps: 16 | Train Loss: 0.4758557 Vali Loss: 1.2088455 Test Loss: 0.4258684
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0018014398509482003
Epoch: 22 cost time: 2.9993629455566406
Epoch: 22, Steps: 16 | Train Loss: 0.4751288 Vali Loss: 1.2073987 Test Loss: 0.4255838
Validation loss decreased (1.207679 --> 1.207399).  Saving model ...
Updating learning rate to 0.0014411518807585604
Epoch: 23 cost time: 3.1788315773010254
Epoch: 23, Steps: 16 | Train Loss: 0.4753155 Vali Loss: 1.2079141 Test Loss: 0.4257939
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0011529215046068484
Epoch: 24 cost time: 2.800358533859253
Epoch: 24, Steps: 16 | Train Loss: 0.4749839 Vali Loss: 1.2079980 Test Loss: 0.4257456
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0009223372036854787
Epoch: 25 cost time: 2.7992706298828125
Epoch: 25, Steps: 16 | Train Loss: 0.4754041 Vali Loss: 1.2075717 Test Loss: 0.4257402
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.000737869762948383
Epoch: 26 cost time: 2.810119867324829
Epoch: 26, Steps: 16 | Train Loss: 0.4755007 Vali Loss: 1.2074935 Test Loss: 0.4258296
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0005902958103587065
Epoch: 27 cost time: 4.0983946323394775
Epoch: 27, Steps: 16 | Train Loss: 0.4757378 Vali Loss: 1.2073021 Test Loss: 0.4258773
Validation loss decreased (1.207399 --> 1.207302).  Saving model ...
Updating learning rate to 0.0004722366482869652
Epoch: 28 cost time: 3.0413591861724854
Epoch: 28, Steps: 16 | Train Loss: 0.4756508 Vali Loss: 1.2072533 Test Loss: 0.4259346
Validation loss decreased (1.207302 --> 1.207253).  Saving model ...
Updating learning rate to 0.0003777893186295722
Epoch: 29 cost time: 2.9213767051696777
Epoch: 29, Steps: 16 | Train Loss: 0.4753010 Vali Loss: 1.2072697 Test Loss: 0.4260289
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00030223145490365774
Epoch: 30 cost time: 2.929029941558838
Epoch: 30, Steps: 16 | Train Loss: 0.4751648 Vali Loss: 1.2075832 Test Loss: 0.4260721
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002417851639229262
>>>>>>>testing : ETTh1_336_336_LightTimeBaseTST_ETTh1_ftM_sl336_pl336_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.42495208978652954, mae:0.41998687386512756, rse:0.6206146478652954

Args in experiment:
Namespace(is_training=1, model_id='ETTm1_192_336', model='FITS', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=64, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_192_336_FITS_ETTm1_ftM_sl192_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=64, out_features=176, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10092544.0
params:  11440.0
Trainable parameters:  11440
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.4935907
	speed: 0.0743s/iter; left time: 583.5394s
	iters: 200, epoch: 1 | loss: 0.4203773
	speed: 0.0592s/iter; left time: 458.6497s
Epoch: 1 cost time: 17.958380460739136
Epoch: 1, Steps: 265 | Train Loss: 0.5083250 Vali Loss: 0.9169617 Test Loss: 0.6246291
Validation loss decreased (inf --> 0.916962).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3428070
	speed: 0.3202s/iter; left time: 2428.8658s
	iters: 200, epoch: 2 | loss: 0.3402865
	speed: 0.0688s/iter; left time: 515.2882s
Epoch: 2 cost time: 20.216527938842773
Epoch: 2, Steps: 265 | Train Loss: 0.3323652 Vali Loss: 0.8168100 Test Loss: 0.5336800
Validation loss decreased (0.916962 --> 0.816810).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3045878
	speed: 0.2982s/iter; left time: 2183.0609s
	iters: 200, epoch: 3 | loss: 0.3292971
	speed: 0.0737s/iter; left time: 532.5131s
Epoch: 3 cost time: 19.287793159484863
Epoch: 3, Steps: 265 | Train Loss: 0.2909995 Vali Loss: 0.7590137 Test Loss: 0.4788277
Validation loss decreased (0.816810 --> 0.759014).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2944642
	speed: 0.3206s/iter; left time: 2262.0289s
	iters: 200, epoch: 4 | loss: 0.2518683
	speed: 0.0678s/iter; left time: 471.6726s
Epoch: 4 cost time: 17.897184371948242
Epoch: 4, Steps: 265 | Train Loss: 0.2696423 Vali Loss: 0.7219128 Test Loss: 0.4427104
Validation loss decreased (0.759014 --> 0.721913).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2644509
	speed: 0.3191s/iter; left time: 2166.8004s
	iters: 200, epoch: 5 | loss: 0.2711602
	speed: 0.0627s/iter; left time: 419.3910s
Epoch: 5 cost time: 18.742523908615112
Epoch: 5, Steps: 265 | Train Loss: 0.2574059 Vali Loss: 0.6999033 Test Loss: 0.4211383
Validation loss decreased (0.721913 --> 0.699903).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2273565
	speed: 0.2669s/iter; left time: 1741.8136s
	iters: 200, epoch: 6 | loss: 0.2495406
	speed: 0.0675s/iter; left time: 433.5298s
Epoch: 6 cost time: 18.242502689361572
Epoch: 6, Steps: 265 | Train Loss: 0.2505328 Vali Loss: 0.6875840 Test Loss: 0.4078235
Validation loss decreased (0.699903 --> 0.687584).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2153901
	speed: 0.3055s/iter; left time: 1912.5308s
	iters: 200, epoch: 7 | loss: 0.2318263
	speed: 0.0624s/iter; left time: 384.4725s
Epoch: 7 cost time: 19.15252113342285
Epoch: 7, Steps: 265 | Train Loss: 0.2465967 Vali Loss: 0.6796693 Test Loss: 0.3997110
Validation loss decreased (0.687584 --> 0.679669).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2723826
	speed: 0.2993s/iter; left time: 1794.6516s
	iters: 200, epoch: 8 | loss: 0.2676979
	speed: 0.0580s/iter; left time: 341.8983s
Epoch: 8 cost time: 16.667744159698486
Epoch: 8, Steps: 265 | Train Loss: 0.2444016 Vali Loss: 0.6748725 Test Loss: 0.3949919
Validation loss decreased (0.679669 --> 0.674872).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2718857
	speed: 0.3032s/iter; left time: 1737.7646s
	iters: 200, epoch: 9 | loss: 0.2295877
	speed: 0.0604s/iter; left time: 340.1624s
Epoch: 9 cost time: 17.770278215408325
Epoch: 9, Steps: 265 | Train Loss: 0.2430427 Vali Loss: 0.6731585 Test Loss: 0.3916102
Validation loss decreased (0.674872 --> 0.673158).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2318529
	speed: 0.2796s/iter; left time: 1528.0629s
	iters: 200, epoch: 10 | loss: 0.2197799
	speed: 0.0646s/iter; left time: 346.7475s
Epoch: 10 cost time: 19.000202894210815
Epoch: 10, Steps: 265 | Train Loss: 0.2421606 Vali Loss: 0.6720573 Test Loss: 0.3893550
Validation loss decreased (0.673158 --> 0.672057).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2530999
	speed: 0.3028s/iter; left time: 1574.6944s
	iters: 200, epoch: 11 | loss: 0.2448305
	speed: 0.0623s/iter; left time: 317.7615s
Epoch: 11 cost time: 17.510340452194214
Epoch: 11, Steps: 265 | Train Loss: 0.2418041 Vali Loss: 0.6707582 Test Loss: 0.3882337
Validation loss decreased (0.672057 --> 0.670758).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.2428392
	speed: 0.3119s/iter; left time: 1539.6432s
	iters: 200, epoch: 12 | loss: 0.2446199
	speed: 0.0652s/iter; left time: 315.5285s
Epoch: 12 cost time: 18.46110439300537
Epoch: 12, Steps: 265 | Train Loss: 0.2414631 Vali Loss: 0.6696582 Test Loss: 0.3871381
Validation loss decreased (0.670758 --> 0.669658).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.2385935
	speed: 0.2726s/iter; left time: 1273.3883s
	iters: 200, epoch: 13 | loss: 0.2298071
	speed: 0.0698s/iter; left time: 319.0608s
Epoch: 13 cost time: 18.093583583831787
Epoch: 13, Steps: 265 | Train Loss: 0.2412826 Vali Loss: 0.6686097 Test Loss: 0.3865507
Validation loss decreased (0.669658 --> 0.668610).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.2517325
	speed: 0.2950s/iter; left time: 1299.8448s
	iters: 200, epoch: 14 | loss: 0.2417292
	speed: 0.0556s/iter; left time: 239.3045s
Epoch: 14 cost time: 16.81305193901062
Epoch: 14, Steps: 265 | Train Loss: 0.2412452 Vali Loss: 0.6695477 Test Loss: 0.3860866
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2431607
	speed: 0.2927s/iter; left time: 1211.9393s
	iters: 200, epoch: 15 | loss: 0.2293947
	speed: 0.0605s/iter; left time: 244.6378s
Epoch: 15 cost time: 16.44299340248108
Epoch: 15, Steps: 265 | Train Loss: 0.2411865 Vali Loss: 0.6691191 Test Loss: 0.3859857
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2499404
	speed: 0.2463s/iter; left time: 954.7666s
	iters: 200, epoch: 16 | loss: 0.2449245
	speed: 0.0529s/iter; left time: 199.7183s
Epoch: 16 cost time: 15.079017400741577
Epoch: 16, Steps: 265 | Train Loss: 0.2411234 Vali Loss: 0.6694647 Test Loss: 0.3858080
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.2607706
	speed: 0.2689s/iter; left time: 970.8858s
	iters: 200, epoch: 17 | loss: 0.2466150
	speed: 0.0477s/iter; left time: 167.3777s
Epoch: 17 cost time: 14.098718643188477
Epoch: 17, Steps: 265 | Train Loss: 0.2411816 Vali Loss: 0.6693316 Test Loss: 0.3856641
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2346922
	speed: 0.2715s/iter; left time: 908.3714s
	iters: 200, epoch: 18 | loss: 0.2570832
	speed: 0.0672s/iter; left time: 218.1115s
Epoch: 18 cost time: 17.784555912017822
Epoch: 18, Steps: 265 | Train Loss: 0.2410521 Vali Loss: 0.6682389 Test Loss: 0.3854154
Validation loss decreased (0.668610 --> 0.668239).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.2407200
	speed: 0.2456s/iter; left time: 756.8127s
	iters: 200, epoch: 19 | loss: 0.2365102
	speed: 0.0511s/iter; left time: 152.3699s
Epoch: 19 cost time: 14.834902048110962
Epoch: 19, Steps: 265 | Train Loss: 0.2411340 Vali Loss: 0.6686948 Test Loss: 0.3854422
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.2185903
	speed: 0.2670s/iter; left time: 751.9986s
	iters: 200, epoch: 20 | loss: 0.2529467
	speed: 0.0504s/iter; left time: 136.9564s
Epoch: 20 cost time: 14.14267635345459
Epoch: 20, Steps: 265 | Train Loss: 0.2410665 Vali Loss: 0.6691995 Test Loss: 0.3853729
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.2609574
	speed: 0.2096s/iter; left time: 534.7474s
	iters: 200, epoch: 21 | loss: 0.2508877
	speed: 0.0425s/iter; left time: 104.1698s
Epoch: 21 cost time: 13.213220357894897
Epoch: 21, Steps: 265 | Train Loss: 0.2411148 Vali Loss: 0.6682415 Test Loss: 0.3855558
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.2394630
	speed: 0.2736s/iter; left time: 625.5598s
	iters: 200, epoch: 22 | loss: 0.2288202
	speed: 0.0623s/iter; left time: 136.1427s
Epoch: 22 cost time: 18.045156002044678
Epoch: 22, Steps: 265 | Train Loss: 0.2410400 Vali Loss: 0.6684397 Test Loss: 0.3854257
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2473243
	speed: 0.2834s/iter; left time: 572.6830s
	iters: 200, epoch: 23 | loss: 0.2512252
	speed: 0.0665s/iter; left time: 127.6575s
Epoch: 23 cost time: 17.10890007019043
Epoch: 23, Steps: 265 | Train Loss: 0.2411207 Vali Loss: 0.6682935 Test Loss: 0.3853510
EarlyStopping counter: 5 out of 5
Early stopping
train 34033
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=64, out_features=176, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  10092544.0
params:  11440.0
Trainable parameters:  11440
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3873331
	speed: 0.0767s/iter; left time: 602.4382s
	iters: 200, epoch: 1 | loss: 0.3224681
	speed: 0.0668s/iter; left time: 518.0832s
Epoch: 1 cost time: 18.563941717147827
Epoch: 1, Steps: 265 | Train Loss: 0.3713319 Vali Loss: 0.6640450 Test Loss: 0.3819245
Validation loss decreased (inf --> 0.664045).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3615348
	speed: 0.2832s/iter; left time: 2148.3419s
	iters: 200, epoch: 2 | loss: 0.3738236
	speed: 0.0533s/iter; left time: 398.8453s
Epoch: 2 cost time: 15.300247430801392
Epoch: 2, Steps: 265 | Train Loss: 0.3708008 Vali Loss: 0.6629987 Test Loss: 0.3818435
Validation loss decreased (0.664045 --> 0.662999).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4117278
	speed: 0.2529s/iter; left time: 1851.7725s
	iters: 200, epoch: 3 | loss: 0.4277290
	speed: 0.0587s/iter; left time: 423.8795s
Epoch: 3 cost time: 15.802176237106323
Epoch: 3, Steps: 265 | Train Loss: 0.3706814 Vali Loss: 0.6627608 Test Loss: 0.3816327
Validation loss decreased (0.662999 --> 0.662761).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3832537
	speed: 0.2570s/iter; left time: 1813.3265s
	iters: 200, epoch: 4 | loss: 0.3661317
	speed: 0.0673s/iter; left time: 467.8109s
Epoch: 4 cost time: 17.426260232925415
Epoch: 4, Steps: 265 | Train Loss: 0.3704691 Vali Loss: 0.6628017 Test Loss: 0.3815401
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3369503
	speed: 0.2954s/iter; left time: 2006.0762s
	iters: 200, epoch: 5 | loss: 0.3901750
	speed: 0.0579s/iter; left time: 387.3747s
Epoch: 5 cost time: 17.032580852508545
Epoch: 5, Steps: 265 | Train Loss: 0.3704263 Vali Loss: 0.6626742 Test Loss: 0.3815272
Validation loss decreased (0.662761 --> 0.662674).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.4054258
	speed: 0.2520s/iter; left time: 1644.6235s
	iters: 200, epoch: 6 | loss: 0.3505639
	speed: 0.0562s/iter; left time: 361.3235s
Epoch: 6 cost time: 15.843714952468872
Epoch: 6, Steps: 265 | Train Loss: 0.3703689 Vali Loss: 0.6621195 Test Loss: 0.3813947
Validation loss decreased (0.662674 --> 0.662120).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3722158
	speed: 0.2626s/iter; left time: 1643.8966s
	iters: 200, epoch: 7 | loss: 0.3887442
	speed: 0.0597s/iter; left time: 367.8260s
Epoch: 7 cost time: 16.483113050460815
Epoch: 7, Steps: 265 | Train Loss: 0.3701476 Vali Loss: 0.6626203 Test Loss: 0.3811156
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3801934
	speed: 0.2785s/iter; left time: 1669.6537s
	iters: 200, epoch: 8 | loss: 0.3683453
	speed: 0.0604s/iter; left time: 355.8749s
Epoch: 8 cost time: 17.632164001464844
Epoch: 8, Steps: 265 | Train Loss: 0.3702282 Vali Loss: 0.6621613 Test Loss: 0.3812795
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3580181
	speed: 0.2838s/iter; left time: 1626.7262s
	iters: 200, epoch: 9 | loss: 0.3688280
	speed: 0.0541s/iter; left time: 304.7954s
Epoch: 9 cost time: 15.484853029251099
Epoch: 9, Steps: 265 | Train Loss: 0.3701787 Vali Loss: 0.6616196 Test Loss: 0.3813243
Validation loss decreased (0.662120 --> 0.661620).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3678773
	speed: 0.2470s/iter; left time: 1350.2654s
	iters: 200, epoch: 10 | loss: 0.3492786
	speed: 0.0549s/iter; left time: 294.4280s
Epoch: 10 cost time: 15.37444543838501
Epoch: 10, Steps: 265 | Train Loss: 0.3702830 Vali Loss: 0.6622135 Test Loss: 0.3812417
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3168141
	speed: 0.2567s/iter; left time: 1334.9623s
	iters: 200, epoch: 11 | loss: 0.3934090
	speed: 0.0606s/iter; left time: 309.3541s
Epoch: 11 cost time: 17.678443670272827
Epoch: 11, Steps: 265 | Train Loss: 0.3703563 Vali Loss: 0.6629817 Test Loss: 0.3812779
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.3575203
	speed: 0.2936s/iter; left time: 1449.3405s
	iters: 200, epoch: 12 | loss: 0.3618901
	speed: 0.0583s/iter; left time: 281.8940s
Epoch: 12 cost time: 16.580314874649048
Epoch: 12, Steps: 265 | Train Loss: 0.3701135 Vali Loss: 0.6622403 Test Loss: 0.3813793
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.3664657
	speed: 0.2528s/iter; left time: 1180.7214s
	iters: 200, epoch: 13 | loss: 0.4119892
	speed: 0.0578s/iter; left time: 264.1999s
Epoch: 13 cost time: 16.090038537979126
Epoch: 13, Steps: 265 | Train Loss: 0.3702934 Vali Loss: 0.6627412 Test Loss: 0.3813847
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.3523596
	speed: 0.2489s/iter; left time: 1096.7556s
	iters: 200, epoch: 14 | loss: 0.4144710
	speed: 0.0538s/iter; left time: 231.8043s
Epoch: 14 cost time: 14.967585563659668
Epoch: 14, Steps: 265 | Train Loss: 0.3701544 Vali Loss: 0.6621060 Test Loss: 0.3812971
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm1_192_336_FITS_ETTm1_ftM_sl192_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.3813053369522095, mae:0.3886231482028961, rse:0.5876040458679199, corr:[0.5466934  0.5472304  0.54582    0.5480231  0.54421437 0.54482085
 0.5452605  0.54313314 0.5436291  0.5437152  0.5425834  0.5426372
 0.5417649  0.54034394 0.5399639  0.5384546  0.5357816  0.5340789
 0.5324738  0.5299605  0.52788323 0.52596515 0.52371055 0.52150434
 0.51937807 0.5173549  0.5159145  0.51437247 0.5129881  0.5122183
 0.51178306 0.51172906 0.5127679  0.5140808  0.5139078  0.5136303
 0.51358056 0.5132276  0.5130272  0.51301247 0.5127356  0.5123175
 0.5120402  0.5120825  0.51212037 0.51185364 0.5118332  0.5121712
 0.5128269  0.5132733  0.5132792  0.51330477 0.5134266  0.5132804
 0.5132164  0.51330626 0.5134141  0.5134499  0.51358145 0.51343465
 0.5130387  0.5126349  0.51233435 0.5120146  0.51192147 0.5118824
 0.51186615 0.5119829  0.5123179  0.51262844 0.5128931  0.5131302
 0.5132137  0.5132439  0.5134974  0.5138369  0.51389134 0.51359814
 0.5134074  0.5135266  0.5132261  0.5127425  0.5131262  0.51390564
 0.51422083 0.51412976 0.51410943 0.51429707 0.5146702  0.5148186
 0.51459616 0.51495695 0.5160158  0.5162669  0.5157075  0.5162149
 0.5175032  0.5175249  0.5166962  0.51622367 0.516113   0.51606107
 0.5156549  0.5148784  0.514801   0.5153781  0.5151042  0.5145107
 0.5148041  0.51477504 0.51392114 0.51343113 0.51325595 0.51265377
 0.51222867 0.51212686 0.51149803 0.51092947 0.51096773 0.5107348
 0.5099472  0.509086   0.508326   0.50787103 0.5075689  0.5070492
 0.50668305 0.50659007 0.5063827  0.50615686 0.5060262  0.50598687
 0.5061054  0.5061355  0.50563806 0.50534266 0.5053538  0.5048678
 0.5044309  0.50438935 0.5044498  0.5048463  0.50518256 0.5049045
 0.50471365 0.505138   0.50499946 0.5046329  0.50497884 0.5051849
 0.505006   0.5052117  0.50539285 0.5055181  0.50557667 0.505419
 0.5052337  0.50499976 0.504385   0.5041403  0.50465    0.50478524
 0.50458384 0.5048427  0.5051081  0.50481904 0.50482965 0.505534
 0.50594896 0.50617    0.50670505 0.5068163  0.5063038  0.50638956
 0.5069967  0.50700647 0.50680023 0.5071151  0.5074444  0.5076022
 0.5080661  0.50863594 0.50895834 0.5094739  0.5103145  0.51098126
 0.5114535  0.5119078  0.5124449  0.5129458  0.51380336 0.5143893
 0.5145466  0.5148124  0.51474214 0.51393944 0.51321083 0.5129858
 0.51249546 0.5113468  0.51039183 0.50969976 0.50854707 0.50737405
 0.50655895 0.50559723 0.5047535  0.5041623  0.5032565  0.5024076
 0.5019138  0.5012884  0.5001913  0.49936736 0.49864197 0.49740133
 0.4960752  0.4954874  0.49498713 0.49421412 0.49350253 0.49324512
 0.49323452 0.4933459  0.49321082 0.49308553 0.4933044  0.49337816
 0.4931943  0.49295697 0.49297538 0.49306998 0.492966   0.4924824
 0.4922869  0.49255064 0.49258944 0.49232066 0.49232692 0.492484
 0.4927354  0.49303427 0.49319187 0.493068   0.49306753 0.49317053
 0.4932236  0.49335662 0.49369872 0.49392265 0.49376094 0.49367747
 0.49353907 0.49325693 0.49304745 0.4930191  0.4928908  0.49282253
 0.49287993 0.4930449  0.49363792 0.4942912  0.49450567 0.49473605
 0.4953644  0.49590033 0.49631152 0.49655402 0.49669826 0.4968863
 0.49739736 0.49786654 0.49851656 0.49916857 0.4996346  0.5003568
 0.50096714 0.5010628  0.501543   0.50260735 0.5029377  0.5029356
 0.5034214  0.5035099  0.50355315 0.5043065  0.5042667  0.5031675
 0.5028854  0.5029121  0.50247645 0.50209475 0.5013452  0.5005505
 0.50023466 0.49959964 0.4986443  0.49822906 0.4976885  0.49653134
 0.49568114 0.49518156 0.4943784  0.49367046 0.4934632  0.4931979
 0.4926679  0.49199685 0.49151632 0.49149042 0.49113077 0.49015087
 0.48943365 0.48930866 0.48894602 0.4886483  0.48823428 0.48744604
 0.48721045 0.48754314 0.48679373 0.4861072  0.4864987  0.48596683
 0.4851993  0.48582378 0.48568168 0.4853565  0.48577967 0.48486397
 0.48415518 0.48491552 0.48460212 0.48563352 0.48730618 0.48530498]

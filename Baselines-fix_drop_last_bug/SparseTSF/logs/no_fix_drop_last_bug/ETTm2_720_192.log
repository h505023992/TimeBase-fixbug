Args in experiment:
Namespace(is_training=1, model_id='ETTm2_720_192', model='SparseTSF', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=192, period_len=4, basis_num=6, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.02, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
model的参数数量: 8645
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 267120.0
Params: 8645.0
267120.0 MACs
>>>>>>>start training : ETTm2_720_192_SparseTSF_ETTm2_ftM_sl720_pl192_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2800878
	speed: 0.0499s/iter; left time: 191.0814s
Max Memory (MB): 167.5283203125
Epoch: 1 cost time: 6.362015962600708
Epoch: 1, Steps: 131 | Train Loss: 0.3813987 Vali Loss: 0.1735495 Test Loss: 0.2454915
Validation loss decreased (inf --> 0.173549).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 2 | loss: 0.3014083
	speed: 0.1303s/iter; left time: 482.0243s
Max Memory (MB): 167.5283203125
Epoch: 2 cost time: 6.551533460617065
Epoch: 2, Steps: 131 | Train Loss: 0.3081056 Vali Loss: 0.1569879 Test Loss: 0.2258563
Validation loss decreased (0.173549 --> 0.156988).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 3 | loss: 0.3642558
	speed: 0.1324s/iter; left time: 472.7011s
Max Memory (MB): 167.5283203125
Epoch: 3 cost time: 6.122369766235352
Epoch: 3, Steps: 131 | Train Loss: 0.3001283 Vali Loss: 0.1569282 Test Loss: 0.2243755
Validation loss decreased (0.156988 --> 0.156928).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 4 | loss: 0.2589175
	speed: 0.1282s/iter; left time: 440.9133s
Max Memory (MB): 167.5283203125
Epoch: 4 cost time: 5.921548366546631
Epoch: 4, Steps: 131 | Train Loss: 0.2990649 Vali Loss: 0.1552096 Test Loss: 0.2231748
Validation loss decreased (0.156928 --> 0.155210).  Saving model ...
Updating learning rate to 0.016
	iters: 100, epoch: 5 | loss: 0.2507721
	speed: 0.1021s/iter; left time: 337.7713s
Max Memory (MB): 167.5283203125
Epoch: 5 cost time: 4.620325088500977
Epoch: 5, Steps: 131 | Train Loss: 0.2981884 Vali Loss: 0.1574668 Test Loss: 0.2267670
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.012800000000000002
	iters: 100, epoch: 6 | loss: 0.3595876
	speed: 0.1106s/iter; left time: 351.2700s
Max Memory (MB): 167.5283203125
Epoch: 6 cost time: 6.609916687011719
Epoch: 6, Steps: 131 | Train Loss: 0.2944417 Vali Loss: 0.1523058 Test Loss: 0.2193835
Validation loss decreased (0.155210 --> 0.152306).  Saving model ...
Updating learning rate to 0.010240000000000003
	iters: 100, epoch: 7 | loss: 0.2230421
	speed: 0.1390s/iter; left time: 423.3082s
Max Memory (MB): 167.5283203125
Epoch: 7 cost time: 6.733954906463623
Epoch: 7, Steps: 131 | Train Loss: 0.2923468 Vali Loss: 0.1530430 Test Loss: 0.2218218
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.008192000000000001
	iters: 100, epoch: 8 | loss: 0.2349891
	speed: 0.1372s/iter; left time: 399.7321s
Max Memory (MB): 167.5283203125
Epoch: 8 cost time: 6.772470712661743
Epoch: 8, Steps: 131 | Train Loss: 0.2926343 Vali Loss: 0.1524668 Test Loss: 0.2175415
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0065536000000000014
	iters: 100, epoch: 9 | loss: 0.2463703
	speed: 0.1342s/iter; left time: 373.5981s
Max Memory (MB): 167.5283203125
Epoch: 9 cost time: 5.883538246154785
Epoch: 9, Steps: 131 | Train Loss: 0.2917333 Vali Loss: 0.1516516 Test Loss: 0.2200414
Validation loss decreased (0.152306 --> 0.151652).  Saving model ...
Updating learning rate to 0.005242880000000002
	iters: 100, epoch: 10 | loss: 0.2499794
	speed: 0.1160s/iter; left time: 307.5343s
Max Memory (MB): 167.5283203125
Epoch: 10 cost time: 6.032115697860718
Epoch: 10, Steps: 131 | Train Loss: 0.2921165 Vali Loss: 0.1520366 Test Loss: 0.2183441
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.004194304000000002
	iters: 100, epoch: 11 | loss: 0.2523726
	speed: 0.1198s/iter; left time: 301.9877s
Max Memory (MB): 167.5283203125
Epoch: 11 cost time: 6.330992221832275
Epoch: 11, Steps: 131 | Train Loss: 0.2903995 Vali Loss: 0.1520897 Test Loss: 0.2181204
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.003355443200000002
	iters: 100, epoch: 12 | loss: 0.2732911
	speed: 0.1285s/iter; left time: 307.2040s
Max Memory (MB): 167.5283203125
Epoch: 12 cost time: 6.878759384155273
Epoch: 12, Steps: 131 | Train Loss: 0.2905982 Vali Loss: 0.1535362 Test Loss: 0.2191406
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.002684354560000001
	iters: 100, epoch: 13 | loss: 0.2401539
	speed: 0.1533s/iter; left time: 346.3383s
Max Memory (MB): 167.5283203125
Epoch: 13 cost time: 7.59261155128479
Epoch: 13, Steps: 131 | Train Loss: 0.2906083 Vali Loss: 0.1519920 Test Loss: 0.2194906
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0021474836480000013
	iters: 100, epoch: 14 | loss: 0.2711329
	speed: 0.1505s/iter; left time: 320.3546s
Max Memory (MB): 167.5283203125
Epoch: 14 cost time: 7.163097381591797
Epoch: 14, Steps: 131 | Train Loss: 0.2899305 Vali Loss: 0.1514147 Test Loss: 0.2176291
Validation loss decreased (0.151652 --> 0.151415).  Saving model ...
Updating learning rate to 0.0017179869184000011
	iters: 100, epoch: 15 | loss: 0.3122652
	speed: 0.1446s/iter; left time: 288.8527s
Max Memory (MB): 167.5283203125
Epoch: 15 cost time: 6.960325241088867
Epoch: 15, Steps: 131 | Train Loss: 0.2900663 Vali Loss: 0.1517635 Test Loss: 0.2172847
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0013743895347200009
	iters: 100, epoch: 16 | loss: 0.3255484
	speed: 0.1470s/iter; left time: 274.2402s
Max Memory (MB): 167.5283203125
Epoch: 16 cost time: 7.050368547439575
Epoch: 16, Steps: 131 | Train Loss: 0.2897579 Vali Loss: 0.1515699 Test Loss: 0.2181902
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0010995116277760007
	iters: 100, epoch: 17 | loss: 0.3085987
	speed: 0.1254s/iter; left time: 217.5315s
Max Memory (MB): 167.5283203125
Epoch: 17 cost time: 5.351763963699341
Epoch: 17, Steps: 131 | Train Loss: 0.2893156 Vali Loss: 0.1520207 Test Loss: 0.2180617
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0008796093022208007
	iters: 100, epoch: 18 | loss: 0.2428688
	speed: 0.1052s/iter; left time: 168.7747s
Max Memory (MB): 167.5283203125
Epoch: 18 cost time: 5.181611776351929
Epoch: 18, Steps: 131 | Train Loss: 0.2893849 Vali Loss: 0.1514880 Test Loss: 0.2192876
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0007036874417766406
	iters: 100, epoch: 19 | loss: 0.3240316
	speed: 0.0991s/iter; left time: 145.9693s
Max Memory (MB): 167.5283203125
Epoch: 19 cost time: 4.763015985488892
Epoch: 19, Steps: 131 | Train Loss: 0.2890371 Vali Loss: 0.1514999 Test Loss: 0.2180662
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 167.5283203125
>>>>>>>testing : ETTm2_720_192_SparseTSF_ETTm2_ftM_sl720_pl192_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.217629075050354, mae:0.29110756516456604, rse:0.37702223658561707

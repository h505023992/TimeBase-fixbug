Args in experiment:
Namespace(is_training=1, model_id='ETTh1_96_96', model='FITS', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=40, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_96_FITS_ETTh1_ftM_sl96_ll48_pl96_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=40, out_features=80, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2867200.0
params:  3280.0
Trainable parameters:  3280
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 3.267758846282959
Epoch: 1, Steps: 66 | Train Loss: 0.6259293 Vali Loss: 1.3073782 Test Loss: 0.8740876
Validation loss decreased (inf --> 1.307378).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 4.55778431892395
Epoch: 2, Steps: 66 | Train Loss: 0.5060031 Vali Loss: 1.1726414 Test Loss: 0.7621460
Validation loss decreased (1.307378 --> 1.172641).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.314466714859009
Epoch: 3, Steps: 66 | Train Loss: 0.4348444 Vali Loss: 1.0837767 Test Loss: 0.6945705
Validation loss decreased (1.172641 --> 1.083777).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.411924362182617
Epoch: 4, Steps: 66 | Train Loss: 0.3909358 Vali Loss: 1.0271292 Test Loss: 0.6511715
Validation loss decreased (1.083777 --> 1.027129).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 4.99277663230896
Epoch: 5, Steps: 66 | Train Loss: 0.3619890 Vali Loss: 0.9923402 Test Loss: 0.6221438
Validation loss decreased (1.027129 --> 0.992340).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 4.044874906539917
Epoch: 6, Steps: 66 | Train Loss: 0.3414178 Vali Loss: 0.9635509 Test Loss: 0.6006858
Validation loss decreased (0.992340 --> 0.963551).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.923788547515869
Epoch: 7, Steps: 66 | Train Loss: 0.3259409 Vali Loss: 0.9440501 Test Loss: 0.5838047
Validation loss decreased (0.963551 --> 0.944050).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 3.866441488265991
Epoch: 8, Steps: 66 | Train Loss: 0.3134973 Vali Loss: 0.9265460 Test Loss: 0.5692804
Validation loss decreased (0.944050 --> 0.926546).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.185453176498413
Epoch: 9, Steps: 66 | Train Loss: 0.3031722 Vali Loss: 0.9083861 Test Loss: 0.5575487
Validation loss decreased (0.926546 --> 0.908386).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 3.5839526653289795
Epoch: 10, Steps: 66 | Train Loss: 0.2943181 Vali Loss: 0.9027166 Test Loss: 0.5471149
Validation loss decreased (0.908386 --> 0.902717).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 4.7178404331207275
Epoch: 11, Steps: 66 | Train Loss: 0.2865955 Vali Loss: 0.8817576 Test Loss: 0.5372949
Validation loss decreased (0.902717 --> 0.881758).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.306082248687744
Epoch: 12, Steps: 66 | Train Loss: 0.2797739 Vali Loss: 0.8773004 Test Loss: 0.5283067
Validation loss decreased (0.881758 --> 0.877300).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 3.3253870010375977
Epoch: 13, Steps: 66 | Train Loss: 0.2737191 Vali Loss: 0.8637221 Test Loss: 0.5205553
Validation loss decreased (0.877300 --> 0.863722).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 4.522383689880371
Epoch: 14, Steps: 66 | Train Loss: 0.2682821 Vali Loss: 0.8569090 Test Loss: 0.5132099
Validation loss decreased (0.863722 --> 0.856909).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.659047842025757
Epoch: 15, Steps: 66 | Train Loss: 0.2633500 Vali Loss: 0.8494448 Test Loss: 0.5062761
Validation loss decreased (0.856909 --> 0.849445).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.339550018310547
Epoch: 16, Steps: 66 | Train Loss: 0.2589471 Vali Loss: 0.8444240 Test Loss: 0.4999522
Validation loss decreased (0.849445 --> 0.844424).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 3.4311156272888184
Epoch: 17, Steps: 66 | Train Loss: 0.2549247 Vali Loss: 0.8350553 Test Loss: 0.4943906
Validation loss decreased (0.844424 --> 0.835055).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 2.85123872756958
Epoch: 18, Steps: 66 | Train Loss: 0.2512185 Vali Loss: 0.8313692 Test Loss: 0.4892486
Validation loss decreased (0.835055 --> 0.831369).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 3.4063217639923096
Epoch: 19, Steps: 66 | Train Loss: 0.2478996 Vali Loss: 0.8208380 Test Loss: 0.4843706
Validation loss decreased (0.831369 --> 0.820838).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 2.876221179962158
Epoch: 20, Steps: 66 | Train Loss: 0.2448687 Vali Loss: 0.8175294 Test Loss: 0.4799643
Validation loss decreased (0.820838 --> 0.817529).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 2.930406093597412
Epoch: 21, Steps: 66 | Train Loss: 0.2420670 Vali Loss: 0.8115628 Test Loss: 0.4757510
Validation loss decreased (0.817529 --> 0.811563).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.002070665359497
Epoch: 22, Steps: 66 | Train Loss: 0.2395045 Vali Loss: 0.8122080 Test Loss: 0.4721612
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 2.946422576904297
Epoch: 23, Steps: 66 | Train Loss: 0.2371125 Vali Loss: 0.8074622 Test Loss: 0.4686206
Validation loss decreased (0.811563 --> 0.807462).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 3.6901373863220215
Epoch: 24, Steps: 66 | Train Loss: 0.2349320 Vali Loss: 0.8030438 Test Loss: 0.4653043
Validation loss decreased (0.807462 --> 0.803044).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 3.329235792160034
Epoch: 25, Steps: 66 | Train Loss: 0.2329146 Vali Loss: 0.7951242 Test Loss: 0.4623089
Validation loss decreased (0.803044 --> 0.795124).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 3.449047803878784
Epoch: 26, Steps: 66 | Train Loss: 0.2310598 Vali Loss: 0.7966790 Test Loss: 0.4593870
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 3.3125758171081543
Epoch: 27, Steps: 66 | Train Loss: 0.2293165 Vali Loss: 0.7957603 Test Loss: 0.4569155
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 2.8161613941192627
Epoch: 28, Steps: 66 | Train Loss: 0.2277089 Vali Loss: 0.7873809 Test Loss: 0.4543724
Validation loss decreased (0.795124 --> 0.787381).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 3.3157505989074707
Epoch: 29, Steps: 66 | Train Loss: 0.2261713 Vali Loss: 0.7875874 Test Loss: 0.4521473
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 3.0130691528320312
Epoch: 30, Steps: 66 | Train Loss: 0.2248160 Vali Loss: 0.7891334 Test Loss: 0.4501797
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00011296777049628277
train 8449
val 2785
test 2785
Model(
  (freq_upsampler): Linear(in_features=40, out_features=80, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  2867200.0
params:  3280.0
Trainable parameters:  3280
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 2.954871416091919
Epoch: 1, Steps: 66 | Train Loss: 0.3893354 Vali Loss: 0.7544710 Test Loss: 0.4218104
Validation loss decreased (inf --> 0.754471).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 2.899233102798462
Epoch: 2, Steps: 66 | Train Loss: 0.3739421 Vali Loss: 0.7278816 Test Loss: 0.4039467
Validation loss decreased (0.754471 --> 0.727882).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 3.047177314758301
Epoch: 3, Steps: 66 | Train Loss: 0.3653820 Vali Loss: 0.7179370 Test Loss: 0.3946981
Validation loss decreased (0.727882 --> 0.717937).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 3.267320156097412
Epoch: 4, Steps: 66 | Train Loss: 0.3608264 Vali Loss: 0.7130704 Test Loss: 0.3901380
Validation loss decreased (0.717937 --> 0.713070).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 3.4158992767333984
Epoch: 5, Steps: 66 | Train Loss: 0.3583579 Vali Loss: 0.7108109 Test Loss: 0.3878593
Validation loss decreased (0.713070 --> 0.710811).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 3.2994465827941895
Epoch: 6, Steps: 66 | Train Loss: 0.3568646 Vali Loss: 0.7060102 Test Loss: 0.3867237
Validation loss decreased (0.710811 --> 0.706010).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 3.2675893306732178
Epoch: 7, Steps: 66 | Train Loss: 0.3561842 Vali Loss: 0.7052583 Test Loss: 0.3862416
Validation loss decreased (0.706010 --> 0.705258).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 2.7648398876190186
Epoch: 8, Steps: 66 | Train Loss: 0.3557654 Vali Loss: 0.7051714 Test Loss: 0.3860254
Validation loss decreased (0.705258 --> 0.705171).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 3.3742988109588623
Epoch: 9, Steps: 66 | Train Loss: 0.3555085 Vali Loss: 0.7042029 Test Loss: 0.3857916
Validation loss decreased (0.705171 --> 0.704203).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 4.318423271179199
Epoch: 10, Steps: 66 | Train Loss: 0.3553161 Vali Loss: 0.7031921 Test Loss: 0.3859295
Validation loss decreased (0.704203 --> 0.703192).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 3.073237657546997
Epoch: 11, Steps: 66 | Train Loss: 0.3551889 Vali Loss: 0.7037495 Test Loss: 0.3857770
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 3.0805740356445312
Epoch: 12, Steps: 66 | Train Loss: 0.3551088 Vali Loss: 0.7057304 Test Loss: 0.3856757
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 4.545032501220703
Epoch: 13, Steps: 66 | Train Loss: 0.3550470 Vali Loss: 0.7050901 Test Loss: 0.3858019
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 3.4058279991149902
Epoch: 14, Steps: 66 | Train Loss: 0.3549948 Vali Loss: 0.7021714 Test Loss: 0.3858615
Validation loss decreased (0.703192 --> 0.702171).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 3.3699452877044678
Epoch: 15, Steps: 66 | Train Loss: 0.3549676 Vali Loss: 0.7037412 Test Loss: 0.3857681
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 3.4560458660125732
Epoch: 16, Steps: 66 | Train Loss: 0.3548592 Vali Loss: 0.7034388 Test Loss: 0.3857985
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 2.846191883087158
Epoch: 17, Steps: 66 | Train Loss: 0.3548769 Vali Loss: 0.7004861 Test Loss: 0.3857826
Validation loss decreased (0.702171 --> 0.700486).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 3.389686346054077
Epoch: 18, Steps: 66 | Train Loss: 0.3548668 Vali Loss: 0.6963455 Test Loss: 0.3858753
Validation loss decreased (0.700486 --> 0.696346).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 2.919485092163086
Epoch: 19, Steps: 66 | Train Loss: 0.3548414 Vali Loss: 0.7029468 Test Loss: 0.3858384
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 3.0043716430664062
Epoch: 20, Steps: 66 | Train Loss: 0.3548458 Vali Loss: 0.7040128 Test Loss: 0.3857889
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 3.061617612838745
Epoch: 21, Steps: 66 | Train Loss: 0.3548316 Vali Loss: 0.7030218 Test Loss: 0.3857694
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 3.024627208709717
Epoch: 22, Steps: 66 | Train Loss: 0.3547861 Vali Loss: 0.7004770 Test Loss: 0.3857695
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 3.3981752395629883
Epoch: 23, Steps: 66 | Train Loss: 0.3547506 Vali Loss: 0.7049543 Test Loss: 0.3858315
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTh1_96_96_FITS_ETTh1_ftM_sl96_ll48_pl96_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3851375877857208, mae:0.3932528793811798, rse:0.5894755721092224, corr:[0.27185175 0.27419174 0.2745028  0.27391353 0.27204663 0.26972696
 0.26721385 0.26730013 0.2666956  0.26688644 0.26696646 0.26652935
 0.26687145 0.26637942 0.26615742 0.26584908 0.2656242  0.2659566
 0.26584592 0.26571885 0.26557836 0.26571733 0.26583827 0.26655748
 0.2662762  0.2656028  0.26516405 0.26466173 0.2641119  0.2635174
 0.26292673 0.26229468 0.26203826 0.26189515 0.2614503  0.26169157
 0.26173976 0.2614278  0.2620115  0.2618679  0.26181936 0.26258397
 0.26285213 0.26306626 0.26318562 0.26296437 0.26326266 0.2641649
 0.26398912 0.26298374 0.26185006 0.26036492 0.25907326 0.25765383
 0.25636637 0.25571015 0.2551926  0.25521144 0.25524446 0.2553
 0.2553631  0.25552967 0.25590378 0.2556549  0.25544906 0.2558024
 0.25593692 0.25616026 0.25623763 0.25599763 0.25636542 0.2562126
 0.25480086 0.25381285 0.25273886 0.25189504 0.25159585 0.2510446
 0.2504966  0.24992114 0.24972133 0.24952835 0.24927624 0.24948032
 0.24940561 0.24939702 0.24973355 0.2496206  0.24950467 0.24912795
 0.24898191 0.24921705 0.24831653 0.24897176 0.24920289 0.2509499 ]

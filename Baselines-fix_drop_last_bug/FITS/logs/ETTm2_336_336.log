Args in experiment:
Namespace(is_training=1, model_id='ETTm2_336_336', model='FITS', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=100, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTm2_336_336_FITS_ETTm2_ftM_sl336_ll48_pl336_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=100, out_features=200, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  17920000.0
params:  20200.0
Trainable parameters:  20200
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3238973
	speed: 0.0561s/iter; left time: 438.4639s
	iters: 200, epoch: 1 | loss: 0.3373929
	speed: 0.0449s/iter; left time: 346.8069s
Epoch: 1 cost time: 13.271719694137573
Epoch: 1, Steps: 264 | Train Loss: 0.3393833 Vali Loss: 0.2356345 Test Loss: 0.3105554
Validation loss decreased (inf --> 0.235634).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3222002
	speed: 0.2182s/iter; left time: 1648.8814s
	iters: 200, epoch: 2 | loss: 0.2474219
	speed: 0.0506s/iter; left time: 377.5473s
Epoch: 2 cost time: 14.092500686645508
Epoch: 2, Steps: 264 | Train Loss: 0.2532182 Vali Loss: 0.2205608 Test Loss: 0.2940617
Validation loss decreased (0.235634 --> 0.220561).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.2196900
	speed: 0.2268s/iter; left time: 1654.1968s
	iters: 200, epoch: 3 | loss: 0.1838601
	speed: 0.0509s/iter; left time: 366.1281s
Epoch: 3 cost time: 13.913549900054932
Epoch: 3, Steps: 264 | Train Loss: 0.2300052 Vali Loss: 0.2134028 Test Loss: 0.2861069
Validation loss decreased (0.220561 --> 0.213403).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2670700
	speed: 0.2325s/iter; left time: 1634.3001s
	iters: 200, epoch: 4 | loss: 0.2050952
	speed: 0.0471s/iter; left time: 326.4708s
Epoch: 4 cost time: 13.67724061012268
Epoch: 4, Steps: 264 | Train Loss: 0.2184556 Vali Loss: 0.2088812 Test Loss: 0.2812977
Validation loss decreased (0.213403 --> 0.208881).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1645586
	speed: 0.2444s/iter; left time: 1653.5632s
	iters: 200, epoch: 5 | loss: 0.2831811
	speed: 0.0469s/iter; left time: 312.8384s
Epoch: 5 cost time: 13.749254941940308
Epoch: 5, Steps: 264 | Train Loss: 0.2114154 Vali Loss: 0.2059708 Test Loss: 0.2781577
Validation loss decreased (0.208881 --> 0.205971).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.1771153
	speed: 0.2137s/iter; left time: 1389.4916s
	iters: 200, epoch: 6 | loss: 0.2302660
	speed: 0.0469s/iter; left time: 300.5070s
Epoch: 6 cost time: 13.259048700332642
Epoch: 6, Steps: 264 | Train Loss: 0.2074793 Vali Loss: 0.2042202 Test Loss: 0.2764050
Validation loss decreased (0.205971 --> 0.204220).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2128982
	speed: 0.2138s/iter; left time: 1333.6794s
	iters: 200, epoch: 7 | loss: 0.2334732
	speed: 0.0458s/iter; left time: 281.0102s
Epoch: 7 cost time: 13.015384435653687
Epoch: 7, Steps: 264 | Train Loss: 0.2051602 Vali Loss: 0.2028289 Test Loss: 0.2754020
Validation loss decreased (0.204220 --> 0.202829).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2515939
	speed: 0.2152s/iter; left time: 1285.1673s
	iters: 200, epoch: 8 | loss: 0.2004323
	speed: 0.0492s/iter; left time: 289.0283s
Epoch: 8 cost time: 13.259841203689575
Epoch: 8, Steps: 264 | Train Loss: 0.2034520 Vali Loss: 0.2022092 Test Loss: 0.2747089
Validation loss decreased (0.202829 --> 0.202209).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2850232
	speed: 0.2232s/iter; left time: 1274.3542s
	iters: 200, epoch: 9 | loss: 0.2062348
	speed: 0.0487s/iter; left time: 273.1196s
Epoch: 9 cost time: 13.578096151351929
Epoch: 9, Steps: 264 | Train Loss: 0.2027765 Vali Loss: 0.2016523 Test Loss: 0.2745460
Validation loss decreased (0.202209 --> 0.201652).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.2470903
	speed: 0.2207s/iter; left time: 1201.6172s
	iters: 200, epoch: 10 | loss: 0.2159755
	speed: 0.0508s/iter; left time: 271.2731s
Epoch: 10 cost time: 13.664226055145264
Epoch: 10, Steps: 264 | Train Loss: 0.2019289 Vali Loss: 0.2012176 Test Loss: 0.2743804
Validation loss decreased (0.201652 --> 0.201218).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.2352761
	speed: 0.2171s/iter; left time: 1124.9519s
	iters: 200, epoch: 11 | loss: 0.1671845
	speed: 0.0440s/iter; left time: 223.5450s
Epoch: 11 cost time: 13.05008053779602
Epoch: 11, Steps: 264 | Train Loss: 0.2017556 Vali Loss: 0.2010359 Test Loss: 0.2743731
Validation loss decreased (0.201218 --> 0.201036).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.1610145
	speed: 0.2201s/iter; left time: 1082.4771s
	iters: 200, epoch: 12 | loss: 0.2021180
	speed: 0.0496s/iter; left time: 238.7296s
Epoch: 12 cost time: 13.998697519302368
Epoch: 12, Steps: 264 | Train Loss: 0.2011622 Vali Loss: 0.2006884 Test Loss: 0.2743839
Validation loss decreased (0.201036 --> 0.200688).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.1787322
	speed: 0.2205s/iter; left time: 1026.0171s
	iters: 200, epoch: 13 | loss: 0.1320052
	speed: 0.0460s/iter; left time: 209.2223s
Epoch: 13 cost time: 13.849289894104004
Epoch: 13, Steps: 264 | Train Loss: 0.2009680 Vali Loss: 0.2007959 Test Loss: 0.2743585
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.1549705
	speed: 0.2168s/iter; left time: 951.5086s
	iters: 200, epoch: 14 | loss: 0.1370057
	speed: 0.0460s/iter; left time: 197.1098s
Epoch: 14 cost time: 12.340284585952759
Epoch: 14, Steps: 264 | Train Loss: 0.2012423 Vali Loss: 0.2005517 Test Loss: 0.2742640
Validation loss decreased (0.200688 --> 0.200552).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2244184
	speed: 0.2081s/iter; left time: 858.6133s
	iters: 200, epoch: 15 | loss: 0.1783233
	speed: 0.0440s/iter; left time: 177.0409s
Epoch: 15 cost time: 12.439913511276245
Epoch: 15, Steps: 264 | Train Loss: 0.2008727 Vali Loss: 0.2007048 Test Loss: 0.2742857
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.2262248
	speed: 0.2014s/iter; left time: 777.7327s
	iters: 200, epoch: 16 | loss: 0.1929523
	speed: 0.0432s/iter; left time: 162.5561s
Epoch: 16 cost time: 12.771218299865723
Epoch: 16, Steps: 264 | Train Loss: 0.2008963 Vali Loss: 0.2006136 Test Loss: 0.2742458
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.1410688
	speed: 0.2050s/iter; left time: 737.4509s
	iters: 200, epoch: 17 | loss: 0.2221805
	speed: 0.0447s/iter; left time: 156.2110s
Epoch: 17 cost time: 12.221048593521118
Epoch: 17, Steps: 264 | Train Loss: 0.2010229 Vali Loss: 0.2004467 Test Loss: 0.2742231
Validation loss decreased (0.200552 --> 0.200447).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.2177611
	speed: 0.2100s/iter; left time: 699.9021s
	iters: 200, epoch: 18 | loss: 0.1879105
	speed: 0.0460s/iter; left time: 148.6961s
Epoch: 18 cost time: 12.870038270950317
Epoch: 18, Steps: 264 | Train Loss: 0.2008127 Vali Loss: 0.2003241 Test Loss: 0.2742041
Validation loss decreased (0.200447 --> 0.200324).  Saving model ...
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.1834498
	speed: 0.2080s/iter; left time: 638.3895s
	iters: 200, epoch: 19 | loss: 0.1482487
	speed: 0.0443s/iter; left time: 131.5750s
Epoch: 19 cost time: 12.914113759994507
Epoch: 19, Steps: 264 | Train Loss: 0.2006111 Vali Loss: 0.2003425 Test Loss: 0.2742899
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.1701033
	speed: 0.2142s/iter; left time: 600.8248s
	iters: 200, epoch: 20 | loss: 0.2050413
	speed: 0.0459s/iter; left time: 124.2066s
Epoch: 20 cost time: 12.906947135925293
Epoch: 20, Steps: 264 | Train Loss: 0.2005500 Vali Loss: 0.2004022 Test Loss: 0.2741945
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.1539232
	speed: 0.2290s/iter; left time: 581.9688s
	iters: 200, epoch: 21 | loss: 0.1726617
	speed: 0.0508s/iter; left time: 124.0962s
Epoch: 21 cost time: 13.819632053375244
Epoch: 21, Steps: 264 | Train Loss: 0.2005014 Vali Loss: 0.2003736 Test Loss: 0.2742489
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.1585451
	speed: 0.2247s/iter; left time: 511.6512s
	iters: 200, epoch: 22 | loss: 0.2822173
	speed: 0.0524s/iter; left time: 114.0546s
Epoch: 22 cost time: 13.916889429092407
Epoch: 22, Steps: 264 | Train Loss: 0.2006050 Vali Loss: 0.2003042 Test Loss: 0.2742413
Validation loss decreased (0.200324 --> 0.200304).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.2335344
	speed: 0.2205s/iter; left time: 443.8155s
	iters: 200, epoch: 23 | loss: 0.2094231
	speed: 0.0516s/iter; left time: 98.7709s
Epoch: 23 cost time: 13.991357326507568
Epoch: 23, Steps: 264 | Train Loss: 0.2006907 Vali Loss: 0.2002691 Test Loss: 0.2741612
Validation loss decreased (0.200304 --> 0.200269).  Saving model ...
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.2520490
	speed: 0.2263s/iter; left time: 395.8809s
	iters: 200, epoch: 24 | loss: 0.1522015
	speed: 0.0459s/iter; left time: 75.6306s
Epoch: 24 cost time: 13.338452339172363
Epoch: 24, Steps: 264 | Train Loss: 0.2007024 Vali Loss: 0.2002110 Test Loss: 0.2742175
Validation loss decreased (0.200269 --> 0.200211).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.2688846
	speed: 0.2280s/iter; left time: 338.6502s
	iters: 200, epoch: 25 | loss: 0.2124771
	speed: 0.0494s/iter; left time: 68.4570s
Epoch: 25 cost time: 13.856098890304565
Epoch: 25, Steps: 264 | Train Loss: 0.2005277 Vali Loss: 0.2003810 Test Loss: 0.2741352
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.1975801
	speed: 0.2263s/iter; left time: 276.3501s
	iters: 200, epoch: 26 | loss: 0.1881177
	speed: 0.0477s/iter; left time: 53.4258s
Epoch: 26 cost time: 13.395600318908691
Epoch: 26, Steps: 264 | Train Loss: 0.2004579 Vali Loss: 0.2002180 Test Loss: 0.2741584
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.1054437
	speed: 0.1873s/iter; left time: 179.2376s
	iters: 200, epoch: 27 | loss: 0.2105946
	speed: 0.0362s/iter; left time: 31.0529s
Epoch: 27 cost time: 10.629946947097778
Epoch: 27, Steps: 264 | Train Loss: 0.2002544 Vali Loss: 0.2002465 Test Loss: 0.2741882
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.3075412
	speed: 0.1715s/iter; left time: 118.8334s
	iters: 200, epoch: 28 | loss: 0.1944206
	speed: 0.0359s/iter; left time: 21.2809s
Epoch: 28 cost time: 10.316877841949463
Epoch: 28, Steps: 264 | Train Loss: 0.2005723 Vali Loss: 0.2002187 Test Loss: 0.2741430
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.1627346
	speed: 0.1739s/iter; left time: 74.6086s
	iters: 200, epoch: 29 | loss: 0.2626270
	speed: 0.0446s/iter; left time: 14.6645s
Epoch: 29 cost time: 12.19271183013916
Epoch: 29, Steps: 264 | Train Loss: 0.2003833 Vali Loss: 0.2002146 Test Loss: 0.2741303
EarlyStopping counter: 5 out of 5
Early stopping
train 33889
val 11185
test 11185
Model(
  (freq_upsampler): Linear(in_features=100, out_features=200, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  17920000.0
params:  20200.0
Trainable parameters:  20200
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.5674664
	speed: 0.0530s/iter; left time: 414.4501s
	iters: 200, epoch: 1 | loss: 0.3208526
	speed: 0.0488s/iter; left time: 376.7911s
Epoch: 1 cost time: 13.380930185317993
Epoch: 1, Steps: 264 | Train Loss: 0.3932920 Vali Loss: 0.1995327 Test Loss: 0.2730681
Validation loss decreased (inf --> 0.199533).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4037689
	speed: 0.2123s/iter; left time: 1604.1428s
	iters: 200, epoch: 2 | loss: 0.3606460
	speed: 0.0446s/iter; left time: 332.3375s
Epoch: 2 cost time: 12.729260444641113
Epoch: 2, Steps: 264 | Train Loss: 0.3923579 Vali Loss: 0.1991144 Test Loss: 0.2730768
Validation loss decreased (0.199533 --> 0.199114).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.4428461
	speed: 0.2063s/iter; left time: 1504.8703s
	iters: 200, epoch: 3 | loss: 0.5480335
	speed: 0.0443s/iter; left time: 318.8565s
Epoch: 3 cost time: 12.617347240447998
Epoch: 3, Steps: 264 | Train Loss: 0.3910783 Vali Loss: 0.1992660 Test Loss: 0.2726880
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.3822953
	speed: 0.2068s/iter; left time: 1453.4891s
	iters: 200, epoch: 4 | loss: 0.2724300
	speed: 0.0443s/iter; left time: 307.1786s
Epoch: 4 cost time: 12.314603567123413
Epoch: 4, Steps: 264 | Train Loss: 0.3909894 Vali Loss: 0.1989793 Test Loss: 0.2726950
Validation loss decreased (0.199114 --> 0.198979).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.3520433
	speed: 0.2035s/iter; left time: 1376.3914s
	iters: 200, epoch: 5 | loss: 0.2898281
	speed: 0.0459s/iter; left time: 305.6798s
Epoch: 5 cost time: 12.452625513076782
Epoch: 5, Steps: 264 | Train Loss: 0.3910147 Vali Loss: 0.1989814 Test Loss: 0.2725907
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.3815977
	speed: 0.2051s/iter; left time: 1333.3905s
	iters: 200, epoch: 6 | loss: 0.3365396
	speed: 0.0433s/iter; left time: 277.4682s
Epoch: 6 cost time: 12.099859476089478
Epoch: 6, Steps: 264 | Train Loss: 0.3909806 Vali Loss: 0.1989179 Test Loss: 0.2724959
Validation loss decreased (0.198979 --> 0.198918).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.3070434
	speed: 0.2107s/iter; left time: 1314.0814s
	iters: 200, epoch: 7 | loss: 0.4813164
	speed: 0.0448s/iter; left time: 275.1013s
Epoch: 7 cost time: 13.040992736816406
Epoch: 7, Steps: 264 | Train Loss: 0.3904918 Vali Loss: 0.1986459 Test Loss: 0.2724064
Validation loss decreased (0.198918 --> 0.198646).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.2938456
	speed: 0.2019s/iter; left time: 1205.7224s
	iters: 200, epoch: 8 | loss: 0.5047954
	speed: 0.0462s/iter; left time: 271.1950s
Epoch: 8 cost time: 12.746248006820679
Epoch: 8, Steps: 264 | Train Loss: 0.3899489 Vali Loss: 0.1987073 Test Loss: 0.2724373
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.3614820
	speed: 0.2061s/iter; left time: 1176.5206s
	iters: 200, epoch: 9 | loss: 0.3090042
	speed: 0.0468s/iter; left time: 262.2859s
Epoch: 9 cost time: 13.11784815788269
Epoch: 9, Steps: 264 | Train Loss: 0.3901114 Vali Loss: 0.1985591 Test Loss: 0.2723453
Validation loss decreased (0.198646 --> 0.198559).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3537242
	speed: 0.2053s/iter; left time: 1117.7842s
	iters: 200, epoch: 10 | loss: 0.2543691
	speed: 0.0416s/iter; left time: 222.1724s
Epoch: 10 cost time: 12.433408975601196
Epoch: 10, Steps: 264 | Train Loss: 0.3900403 Vali Loss: 0.1988018 Test Loss: 0.2724801
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3217090
	speed: 0.2027s/iter; left time: 1050.1763s
	iters: 200, epoch: 11 | loss: 0.4968110
	speed: 0.0366s/iter; left time: 186.1114s
Epoch: 11 cost time: 10.036252975463867
Epoch: 11, Steps: 264 | Train Loss: 0.3900129 Vali Loss: 0.1985299 Test Loss: 0.2721694
Validation loss decreased (0.198559 --> 0.198530).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.4526947
	speed: 0.1517s/iter; left time: 745.8595s
	iters: 200, epoch: 12 | loss: 0.3228374
	speed: 0.0341s/iter; left time: 164.2018s
Epoch: 12 cost time: 10.28799819946289
Epoch: 12, Steps: 264 | Train Loss: 0.3899330 Vali Loss: 0.1986061 Test Loss: 0.2723213
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.4687259
	speed: 0.1739s/iter; left time: 809.1416s
	iters: 200, epoch: 13 | loss: 0.4683539
	speed: 0.0359s/iter; left time: 163.2825s
Epoch: 13 cost time: 9.83104419708252
Epoch: 13, Steps: 264 | Train Loss: 0.3897581 Vali Loss: 0.1986608 Test Loss: 0.2722414
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.4153539
	speed: 0.1565s/iter; left time: 686.9851s
	iters: 200, epoch: 14 | loss: 0.3500818
	speed: 0.0319s/iter; left time: 136.8943s
Epoch: 14 cost time: 9.897270441055298
Epoch: 14, Steps: 264 | Train Loss: 0.3896983 Vali Loss: 0.1984176 Test Loss: 0.2721690
Validation loss decreased (0.198530 --> 0.198418).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.2565301
	speed: 0.1765s/iter; left time: 728.1713s
	iters: 200, epoch: 15 | loss: 0.4333666
	speed: 0.0349s/iter; left time: 140.4211s
Epoch: 15 cost time: 10.049969911575317
Epoch: 15, Steps: 264 | Train Loss: 0.3898089 Vali Loss: 0.1985423 Test Loss: 0.2721346
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.4746679
	speed: 0.1728s/iter; left time: 667.3733s
	iters: 200, epoch: 16 | loss: 0.4666405
	speed: 0.0436s/iter; left time: 164.0480s
Epoch: 16 cost time: 11.605394840240479
Epoch: 16, Steps: 264 | Train Loss: 0.3890426 Vali Loss: 0.1985008 Test Loss: 0.2721601
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.3635108
	speed: 0.1912s/iter; left time: 687.5807s
	iters: 200, epoch: 17 | loss: 0.3694376
	speed: 0.0376s/iter; left time: 131.3847s
Epoch: 17 cost time: 10.590635299682617
Epoch: 17, Steps: 264 | Train Loss: 0.3897823 Vali Loss: 0.1985529 Test Loss: 0.2721957
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.5088396
	speed: 0.1794s/iter; left time: 598.0332s
	iters: 200, epoch: 18 | loss: 0.3395350
	speed: 0.0424s/iter; left time: 137.1005s
Epoch: 18 cost time: 12.012064218521118
Epoch: 18, Steps: 264 | Train Loss: 0.3896117 Vali Loss: 0.1984996 Test Loss: 0.2722368
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.3945780
	speed: 0.1922s/iter; left time: 589.9845s
	iters: 200, epoch: 19 | loss: 0.3936886
	speed: 0.0367s/iter; left time: 109.0562s
Epoch: 19 cost time: 11.446156024932861
Epoch: 19, Steps: 264 | Train Loss: 0.3897447 Vali Loss: 0.1985958 Test Loss: 0.2721735
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm2_336_336_FITS_ETTm2_ftM_sl336_ll48_pl336_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.27352821826934814, mae:0.3262827694416046, rse:0.42243677377700806, corr:[0.5661686  0.5597579  0.55800587 0.5584185  0.55593497 0.55563015
 0.5558328  0.55430895 0.55373544 0.5536527  0.5527263  0.5523594
 0.55253744 0.5520839  0.5518062  0.55184805 0.5510728  0.55016226
 0.55010456 0.54982656 0.5489645  0.5484925  0.5481028  0.5471758
 0.54658735 0.5467484  0.5467834  0.54633844 0.54572815 0.54487664
 0.54400754 0.54353595 0.5431998  0.5428994  0.5428308  0.54263586
 0.5417755  0.54084283 0.54045236 0.5401757  0.5397596  0.53939325
 0.5389707  0.538448   0.53804296 0.53754085 0.53669834 0.5360178
 0.5356614  0.5350517  0.53414    0.5335515  0.5331169  0.5322222
 0.5312218  0.5306543  0.53021264 0.5295601  0.5288669  0.5283976
 0.5280194  0.52764565 0.52735573 0.52711904 0.5269898  0.5269354
 0.52663285 0.526174   0.5259405  0.52593774 0.525881   0.5257772
 0.5256138  0.52531374 0.52491504 0.52457523 0.5241952  0.52369595
 0.5232112  0.5228582  0.5225143  0.522048   0.5215182  0.52096593
 0.5204974  0.52006906 0.51957506 0.51902026 0.518457   0.5180033
 0.5176983  0.5173748  0.5169077  0.5162861  0.5154562  0.51419026
 0.5125757  0.5109536  0.5094175  0.50800633 0.50678587 0.50562567
 0.5044661  0.5033933  0.50232947 0.50105923 0.49980217 0.49876338
 0.49781954 0.49678424 0.49590608 0.4951224  0.49425992 0.49336672
 0.4925931  0.49175254 0.49069127 0.48989737 0.48949972 0.48885557
 0.48787424 0.48688984 0.486113   0.48542458 0.4850086  0.4845362
 0.48375914 0.48296532 0.48241937 0.4817471  0.4807967  0.47999457
 0.47954226 0.47907266 0.47853    0.47817633 0.4777315  0.47716066
 0.4767936  0.4765522  0.47600254 0.47524473 0.4748061  0.47448668
 0.47381863 0.47279766 0.47189087 0.47135043 0.47103086 0.4704589
 0.46962833 0.4690455  0.4685988  0.46782216 0.46703115 0.46666938
 0.46625337 0.46543872 0.4648657  0.46469665 0.4639844  0.46282038
 0.4624533  0.46277934 0.46262595 0.46221346 0.4620721  0.4618089
 0.4612606  0.46107116 0.4611859  0.46092734 0.46043208 0.46040404
 0.46041843 0.45975453 0.45864338 0.45794383 0.4580106  0.4583019
 0.45808837 0.45727026 0.45640612 0.45595402 0.45561817 0.45517665
 0.45496154 0.4551302  0.45519072 0.45483145 0.45397884 0.4525455
 0.4507339  0.4491587  0.44785053 0.44650507 0.44514498 0.44392395
 0.44272178 0.44139612 0.44010958 0.43904966 0.4377587  0.43585837
 0.43411314 0.43326545 0.4326129  0.43137264 0.42996895 0.42928797
 0.42880133 0.4278582  0.4268833  0.4262008  0.42539036 0.42418823
 0.42331854 0.42279562 0.42184916 0.4202819  0.41898552 0.4183315
 0.41792327 0.41719586 0.4162772  0.41526476 0.41456693 0.41373697
 0.41243473 0.41142535 0.41084862 0.40990624 0.40871745 0.40829003
 0.40797493 0.40692583 0.40619558 0.40656474 0.40662852 0.40585226
 0.40542713 0.40536353 0.40463197 0.40351263 0.40308285 0.4031683
 0.403137   0.4030755  0.4031015  0.40276012 0.4025401  0.40266985
 0.40268505 0.40249205 0.4021755  0.40164125 0.40112555 0.4012851
 0.40139762 0.4004999  0.3996698  0.39994174 0.40005714 0.39965227
 0.39967528 0.3996691  0.3986979  0.39793164 0.39835045 0.39877293
 0.39845255 0.39808723 0.39738098 0.39644834 0.39630148 0.39663982
 0.3960407  0.39560512 0.39662892 0.39727268 0.39601666 0.39437595
 0.39404705 0.39471838 0.39582378 0.39621967 0.39530793 0.39440244
 0.3938802  0.39199013 0.38897684 0.38825688 0.38916755 0.38855687
 0.38769034 0.38824713 0.38793963 0.38547796 0.38349193 0.3837215
 0.38435137 0.38396934 0.38271323 0.38132524 0.3808081  0.38068193
 0.37988403 0.3796353  0.38033566 0.3799368  0.3783657  0.37838528
 0.37895474 0.37800053 0.37690765 0.37697315 0.37649503 0.37554264
 0.37576774 0.3762842  0.37565136 0.37484854 0.3748376  0.3751119
 0.37541637 0.37549323 0.3752556  0.37523627 0.37514645 0.3745637
 0.3753015  0.37667552 0.3762786  0.3755087  0.3754938  0.37088358]

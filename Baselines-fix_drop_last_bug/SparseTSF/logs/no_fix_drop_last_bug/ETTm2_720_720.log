Args in experiment:
Namespace(is_training=1, model_id='ETTm2_720_720', model='SparseTSF', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=720, period_len=4, basis_num=6, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.02, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
model的参数数量: 32405
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 932400.0
Params: 32405.0
932400.0 MACs
>>>>>>>start training : ETTm2_720_720_SparseTSF_ETTm2_ftM_sl720_pl720_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33121
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.5054465
	speed: 0.0531s/iter; left time: 200.1942s
Max Memory (MB): 361.29541015625
Epoch: 1 cost time: 6.344125509262085
Epoch: 1, Steps: 129 | Train Loss: 0.5666023 Vali Loss: 0.2801818 Test Loss: 0.3706900
Validation loss decreased (inf --> 0.280182).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 2 | loss: 0.6087175
	speed: 0.1310s/iter; left time: 477.0019s
Max Memory (MB): 361.29541015625
Epoch: 2 cost time: 6.848592042922974
Epoch: 2, Steps: 129 | Train Loss: 0.5106927 Vali Loss: 0.2643739 Test Loss: 0.3525910
Validation loss decreased (0.280182 --> 0.264374).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 3 | loss: 0.6114642
	speed: 0.1636s/iter; left time: 574.8217s
Max Memory (MB): 361.29541015625
Epoch: 3 cost time: 7.184586048126221
Epoch: 3, Steps: 129 | Train Loss: 0.5048309 Vali Loss: 0.2639250 Test Loss: 0.3523660
Validation loss decreased (0.264374 --> 0.263925).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 4 | loss: 0.4677407
	speed: 0.1421s/iter; left time: 480.8403s
Max Memory (MB): 361.29541015625
Epoch: 4 cost time: 6.346844434738159
Epoch: 4, Steps: 129 | Train Loss: 0.5020021 Vali Loss: 0.2617890 Test Loss: 0.3575574
Validation loss decreased (0.263925 --> 0.261789).  Saving model ...
Updating learning rate to 0.016
	iters: 100, epoch: 5 | loss: 0.5886946
	speed: 0.1274s/iter; left time: 414.7770s
Max Memory (MB): 361.29541015625
Epoch: 5 cost time: 6.5855889320373535
Epoch: 5, Steps: 129 | Train Loss: 0.5007305 Vali Loss: 0.2633002 Test Loss: 0.3524433
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.012800000000000002
	iters: 100, epoch: 6 | loss: 0.4614582
	speed: 0.1698s/iter; left time: 530.7315s
Max Memory (MB): 361.29541015625
Epoch: 6 cost time: 7.485617637634277
Epoch: 6, Steps: 129 | Train Loss: 0.4981846 Vali Loss: 0.2605942 Test Loss: 0.3484074
Validation loss decreased (0.261789 --> 0.260594).  Saving model ...
Updating learning rate to 0.010240000000000003
	iters: 100, epoch: 7 | loss: 0.5789601
	speed: 0.1644s/iter; left time: 492.7735s
Max Memory (MB): 361.29541015625
Epoch: 7 cost time: 7.47737193107605
Epoch: 7, Steps: 129 | Train Loss: 0.4975468 Vali Loss: 0.2599518 Test Loss: 0.3479649
Validation loss decreased (0.260594 --> 0.259952).  Saving model ...
Updating learning rate to 0.008192000000000001
	iters: 100, epoch: 8 | loss: 0.5910494
	speed: 0.1639s/iter; left time: 470.1304s
Max Memory (MB): 361.29541015625
Epoch: 8 cost time: 7.556837558746338
Epoch: 8, Steps: 129 | Train Loss: 0.4970916 Vali Loss: 0.2620455 Test Loss: 0.3482159
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0065536000000000014
	iters: 100, epoch: 9 | loss: 0.4324180
	speed: 0.1615s/iter; left time: 442.3355s
Max Memory (MB): 361.29541015625
Epoch: 9 cost time: 7.311406373977661
Epoch: 9, Steps: 129 | Train Loss: 0.4958364 Vali Loss: 0.2603994 Test Loss: 0.3506797
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.005242880000000002
	iters: 100, epoch: 10 | loss: 0.3620209
	speed: 0.1670s/iter; left time: 435.8969s
Max Memory (MB): 361.29541015625
Epoch: 10 cost time: 7.052304267883301
Epoch: 10, Steps: 129 | Train Loss: 0.4960510 Vali Loss: 0.2593146 Test Loss: 0.3495761
Validation loss decreased (0.259952 --> 0.259315).  Saving model ...
Updating learning rate to 0.004194304000000002
	iters: 100, epoch: 11 | loss: 0.5221409
	speed: 0.1596s/iter; left time: 396.0308s
Max Memory (MB): 361.29541015625
Epoch: 11 cost time: 7.095989227294922
Epoch: 11, Steps: 129 | Train Loss: 0.4957806 Vali Loss: 0.2631800 Test Loss: 0.3490475
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.003355443200000002
	iters: 100, epoch: 12 | loss: 0.4943268
	speed: 0.1630s/iter; left time: 383.3394s
Max Memory (MB): 361.29541015625
Epoch: 12 cost time: 7.3552937507629395
Epoch: 12, Steps: 129 | Train Loss: 0.4945982 Vali Loss: 0.2610251 Test Loss: 0.3477161
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.002684354560000001
	iters: 100, epoch: 13 | loss: 0.6431344
	speed: 0.1679s/iter; left time: 373.1417s
Max Memory (MB): 361.29541015625
Epoch: 13 cost time: 7.273005723953247
Epoch: 13, Steps: 129 | Train Loss: 0.4952195 Vali Loss: 0.2608096 Test Loss: 0.3465802
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0021474836480000013
	iters: 100, epoch: 14 | loss: 0.5206428
	speed: 0.1618s/iter; left time: 338.8141s
Max Memory (MB): 361.29541015625
Epoch: 14 cost time: 7.266600131988525
Epoch: 14, Steps: 129 | Train Loss: 0.4945443 Vali Loss: 0.2601520 Test Loss: 0.3476409
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0017179869184000011
	iters: 100, epoch: 15 | loss: 0.4650452
	speed: 0.1692s/iter; left time: 332.5417s
Max Memory (MB): 361.29541015625
Epoch: 15 cost time: 7.6057822704315186
Epoch: 15, Steps: 129 | Train Loss: 0.4942356 Vali Loss: 0.2605771 Test Loss: 0.3474842
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 361.29541015625
>>>>>>>testing : ETTm2_720_720_SparseTSF_ETTm2_ftM_sl720_pl720_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.3495759665966034, mae:0.37734538316726685, rse:0.4747017025947571

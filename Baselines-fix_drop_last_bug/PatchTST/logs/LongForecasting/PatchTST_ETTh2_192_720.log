Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='192_720', model='PatchTST', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=720, fc_dropout=0.3, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:1
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
MACs: 4623360.0
Params: 293648.0
4.62M MACs
>>>>>>>start training : 192_720_PatchTST_ETTh2_ftM_sl192_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2161
test 2161
Epoch: 1 cost time: 8.054132461547852
Epoch: 1, Steps: 61 | Train Loss: 0.9550466 Vali Loss: 0.7157844 Test Loss: 0.4744675
Validation loss decreased (inf --> 0.715784).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 7.619025468826294
Epoch: 2, Steps: 61 | Train Loss: 0.9239837 Vali Loss: 0.6753683 Test Loss: 0.4436420
Validation loss decreased (0.715784 --> 0.675368).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 7.517883062362671
Epoch: 3, Steps: 61 | Train Loss: 0.8828628 Vali Loss: 0.6505731 Test Loss: 0.4269929
Validation loss decreased (0.675368 --> 0.650573).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 7.280737400054932
Epoch: 4, Steps: 61 | Train Loss: 0.8558279 Vali Loss: 0.6378946 Test Loss: 0.4187035
Validation loss decreased (0.650573 --> 0.637895).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 7.411738634109497
Epoch: 5, Steps: 61 | Train Loss: 0.8390357 Vali Loss: 0.6304537 Test Loss: 0.4145897
Validation loss decreased (0.637895 --> 0.630454).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 8.628109216690063
Epoch: 6, Steps: 61 | Train Loss: 0.8330726 Vali Loss: 0.6257067 Test Loss: 0.4120876
Validation loss decreased (0.630454 --> 0.625707).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 8.108783483505249
Epoch: 7, Steps: 61 | Train Loss: 0.8263611 Vali Loss: 0.6217239 Test Loss: 0.4108510
Validation loss decreased (0.625707 --> 0.621724).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 7.862048149108887
Epoch: 8, Steps: 61 | Train Loss: 0.8226871 Vali Loss: 0.6202899 Test Loss: 0.4098790
Validation loss decreased (0.621724 --> 0.620290).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 7.728759527206421
Epoch: 9, Steps: 61 | Train Loss: 0.8179909 Vali Loss: 0.6178945 Test Loss: 0.4092863
Validation loss decreased (0.620290 --> 0.617894).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 8.548215389251709
Epoch: 10, Steps: 61 | Train Loss: 0.8199638 Vali Loss: 0.6156555 Test Loss: 0.4089587
Validation loss decreased (0.617894 --> 0.615656).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 7.329104423522949
Epoch: 11, Steps: 61 | Train Loss: 0.8171752 Vali Loss: 0.6152043 Test Loss: 0.4086664
Validation loss decreased (0.615656 --> 0.615204).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 7.108476877212524
Epoch: 12, Steps: 61 | Train Loss: 0.8178824 Vali Loss: 0.6143069 Test Loss: 0.4084444
Validation loss decreased (0.615204 --> 0.614307).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 7.467853784561157
Epoch: 13, Steps: 61 | Train Loss: 0.8172782 Vali Loss: 0.6122416 Test Loss: 0.4083547
Validation loss decreased (0.614307 --> 0.612242).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 7.159906387329102
Epoch: 14, Steps: 61 | Train Loss: 0.8129104 Vali Loss: 0.6129616 Test Loss: 0.4081559
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 7.285348415374756
Epoch: 15, Steps: 61 | Train Loss: 0.8131498 Vali Loss: 0.6111456 Test Loss: 0.4080923
Validation loss decreased (0.612242 --> 0.611146).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 7.252662420272827
Epoch: 16, Steps: 61 | Train Loss: 0.8110407 Vali Loss: 0.6112883 Test Loss: 0.4080130
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 8.33479619026184
Epoch: 17, Steps: 61 | Train Loss: 0.8134876 Vali Loss: 0.6100701 Test Loss: 0.4078939
Validation loss decreased (0.611146 --> 0.610070).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 8.025578022003174
Epoch: 18, Steps: 61 | Train Loss: 0.8114505 Vali Loss: 0.6101824 Test Loss: 0.4078261
EarlyStopping counter: 1 out of 5
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 7.7587151527404785
Epoch: 19, Steps: 61 | Train Loss: 0.8116997 Vali Loss: 0.6105314 Test Loss: 0.4077365
EarlyStopping counter: 2 out of 5
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 7.237293720245361
Epoch: 20, Steps: 61 | Train Loss: 0.8117631 Vali Loss: 0.6099427 Test Loss: 0.4077089
Validation loss decreased (0.610070 --> 0.609943).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 8.661273002624512
Epoch: 21, Steps: 61 | Train Loss: 0.8108233 Vali Loss: 0.6097817 Test Loss: 0.4076051
Validation loss decreased (0.609943 --> 0.609782).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 7.320552110671997
Epoch: 22, Steps: 61 | Train Loss: 0.8120606 Vali Loss: 0.6095070 Test Loss: 0.4075783
Validation loss decreased (0.609782 --> 0.609507).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 7.641610383987427
Epoch: 23, Steps: 61 | Train Loss: 0.8110198 Vali Loss: 0.6098520 Test Loss: 0.4075034
EarlyStopping counter: 1 out of 5
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 7.388162851333618
Epoch: 24, Steps: 61 | Train Loss: 0.8102480 Vali Loss: 0.6093593 Test Loss: 0.4074684
Validation loss decreased (0.609507 --> 0.609359).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 6.995679616928101
Epoch: 25, Steps: 61 | Train Loss: 0.8103433 Vali Loss: 0.6095173 Test Loss: 0.4074357
EarlyStopping counter: 1 out of 5
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 6.768553972244263
Epoch: 26, Steps: 61 | Train Loss: 0.8105425 Vali Loss: 0.6090714 Test Loss: 0.4073912
Validation loss decreased (0.609359 --> 0.609071).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 7.793221712112427
Epoch: 27, Steps: 61 | Train Loss: 0.8111023 Vali Loss: 0.6088315 Test Loss: 0.4073639
Validation loss decreased (0.609071 --> 0.608832).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 8.243075370788574
Epoch: 28, Steps: 61 | Train Loss: 0.8091600 Vali Loss: 0.6086342 Test Loss: 0.4073611
Validation loss decreased (0.608832 --> 0.608634).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 8.008487701416016
Epoch: 29, Steps: 61 | Train Loss: 0.8132588 Vali Loss: 0.6085033 Test Loss: 0.4073497
Validation loss decreased (0.608634 --> 0.608503).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 7.729715824127197
Epoch: 30, Steps: 61 | Train Loss: 0.8060805 Vali Loss: 0.6083704 Test Loss: 0.4073416
Validation loss decreased (0.608503 --> 0.608370).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
>>>>>>>testing : 192_720_PatchTST_ETTh2_ftM_sl192_ll48_pl720_dm16_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
mse:0.40595462918281555, mae:0.434702605009079, rse:0.5092657208442688

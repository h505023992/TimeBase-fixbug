Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Autoformer_ETTm1_192_96', model='Autoformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Autoformer_ETTm1_192_96_Autoformer_ETTm1_ftM_sl192_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.3800751
	speed: 0.1402s/iter; left time: 4496.0999s
	iters: 200, epoch: 1 | loss: 0.3055233
	speed: 0.1070s/iter; left time: 3420.9274s
	iters: 300, epoch: 1 | loss: 0.3159781
	speed: 0.1037s/iter; left time: 3305.5092s
	iters: 400, epoch: 1 | loss: 0.3334939
	speed: 0.1017s/iter; left time: 3229.0548s
	iters: 500, epoch: 1 | loss: 0.3310257
	speed: 0.1045s/iter; left time: 3308.2072s
	iters: 600, epoch: 1 | loss: 0.2592896
	speed: 0.1096s/iter; left time: 3457.5592s
	iters: 700, epoch: 1 | loss: 0.3005193
	speed: 0.1126s/iter; left time: 3541.7794s
	iters: 800, epoch: 1 | loss: 0.3050980
	speed: 0.1146s/iter; left time: 3592.4740s
	iters: 900, epoch: 1 | loss: 0.2426244
	speed: 0.1159s/iter; left time: 3623.9450s
	iters: 1000, epoch: 1 | loss: 0.2473273
	speed: 0.1149s/iter; left time: 3581.9467s
Epoch: 1 cost time: 120.31015920639038
Epoch: 1, Steps: 1072 | Train Loss: 0.3275612 Vali Loss: 0.6939745 Test Loss: 0.5892364
Validation loss decreased (inf --> 0.693974).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2272178
	speed: 0.7882s/iter; left time: 24426.3057s
	iters: 200, epoch: 2 | loss: 0.2430708
	speed: 0.1016s/iter; left time: 3137.5731s
	iters: 300, epoch: 2 | loss: 0.2210110
	speed: 0.1023s/iter; left time: 3148.4475s
	iters: 400, epoch: 2 | loss: 0.2176369
	speed: 0.1059s/iter; left time: 3249.0677s
	iters: 500, epoch: 2 | loss: 0.2016620
	speed: 0.1109s/iter; left time: 3392.1800s
	iters: 600, epoch: 2 | loss: 0.2039597
	speed: 0.1171s/iter; left time: 3569.2555s
	iters: 700, epoch: 2 | loss: 0.2069370
	speed: 0.1170s/iter; left time: 3556.7104s
	iters: 800, epoch: 2 | loss: 0.2166562
	speed: 0.1133s/iter; left time: 3432.0016s
	iters: 900, epoch: 2 | loss: 0.2344704
	speed: 0.1130s/iter; left time: 3410.2367s
	iters: 1000, epoch: 2 | loss: 0.1804506
	speed: 0.1103s/iter; left time: 3318.4523s
Epoch: 2 cost time: 119.05694675445557
Epoch: 2, Steps: 1072 | Train Loss: 0.2177368 Vali Loss: 0.7372694 Test Loss: 0.5964524
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1461159
	speed: 0.8240s/iter; left time: 24652.3288s
	iters: 200, epoch: 3 | loss: 0.2213642
	speed: 0.1101s/iter; left time: 3283.7384s
	iters: 300, epoch: 3 | loss: 0.1536383
	speed: 0.1135s/iter; left time: 3373.8394s
	iters: 400, epoch: 3 | loss: 0.1433065
	speed: 0.1204s/iter; left time: 3566.0440s
	iters: 500, epoch: 3 | loss: 0.1881755
	speed: 0.1281s/iter; left time: 3780.5460s
	iters: 600, epoch: 3 | loss: 0.1622601
	speed: 0.1227s/iter; left time: 3609.1174s
	iters: 700, epoch: 3 | loss: 0.1317400
	speed: 0.1248s/iter; left time: 3660.1078s
	iters: 800, epoch: 3 | loss: 0.1275003
	speed: 0.1240s/iter; left time: 3624.3665s
	iters: 900, epoch: 3 | loss: 0.1375021
	speed: 0.1196s/iter; left time: 3483.5930s
	iters: 1000, epoch: 3 | loss: 0.1632067
	speed: 0.1163s/iter; left time: 3373.8538s
Epoch: 3 cost time: 127.97487354278564
Epoch: 3, Steps: 1072 | Train Loss: 0.1594223 Vali Loss: 0.7020604 Test Loss: 0.5801623
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1563967
	speed: 0.8422s/iter; left time: 24292.4887s
	iters: 200, epoch: 4 | loss: 0.1434344
	speed: 0.1110s/iter; left time: 3189.5336s
	iters: 300, epoch: 4 | loss: 0.1313560
	speed: 0.1191s/iter; left time: 3410.4967s
	iters: 400, epoch: 4 | loss: 0.1367862
	speed: 0.1148s/iter; left time: 3276.0908s
	iters: 500, epoch: 4 | loss: 0.1355966
	speed: 0.1146s/iter; left time: 3258.7994s
	iters: 600, epoch: 4 | loss: 0.1173268
	speed: 0.1167s/iter; left time: 3307.4940s
	iters: 700, epoch: 4 | loss: 0.1404811
	speed: 0.1139s/iter; left time: 3217.9053s
	iters: 800, epoch: 4 | loss: 0.1188625
	speed: 0.1086s/iter; left time: 3056.9172s
	iters: 900, epoch: 4 | loss: 0.1394529
	speed: 0.1056s/iter; left time: 2960.1807s
	iters: 1000, epoch: 4 | loss: 0.1141109
	speed: 0.1097s/iter; left time: 3065.1316s
Epoch: 4 cost time: 121.34706568717957
Epoch: 4, Steps: 1072 | Train Loss: 0.1343179 Vali Loss: 0.7090021 Test Loss: 0.6013333
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Autoformer_ETTm1_192_96_Autoformer_ETTm1_ftM_sl192_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.590263843536377, mae:0.5307933688163757

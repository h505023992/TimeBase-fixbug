Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Autoformer_ETTm1_336_96', model='Autoformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Autoformer_ETTm1_336_96_Autoformer_ETTm1_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4685177
	speed: 0.2565s/iter; left time: 8184.8076s
	iters: 200, epoch: 1 | loss: 0.4221472
	speed: 0.2134s/iter; left time: 6787.1680s
	iters: 300, epoch: 1 | loss: 0.4014199
	speed: 0.2082s/iter; left time: 6601.3170s
	iters: 400, epoch: 1 | loss: 0.3571939
	speed: 0.2051s/iter; left time: 6483.3368s
	iters: 500, epoch: 1 | loss: 0.3761196
	speed: 0.2057s/iter; left time: 6481.4839s
	iters: 600, epoch: 1 | loss: 0.3907044
	speed: 0.2076s/iter; left time: 6520.9622s
	iters: 700, epoch: 1 | loss: 0.3544889
	speed: 0.2060s/iter; left time: 6449.5716s
	iters: 800, epoch: 1 | loss: 0.3532545
	speed: 0.2093s/iter; left time: 6533.1157s
	iters: 900, epoch: 1 | loss: 0.3010518
	speed: 0.2114s/iter; left time: 6577.5345s
	iters: 1000, epoch: 1 | loss: 0.2974986
	speed: 0.2127s/iter; left time: 6594.7566s
Epoch: 1 cost time: 228.2336301803589
Epoch: 1, Steps: 1067 | Train Loss: 0.3448179 Vali Loss: 0.7480295 Test Loss: 0.6000532
Validation loss decreased (inf --> 0.748029).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3171587
	speed: 1.4837s/iter; left time: 45764.4881s
	iters: 200, epoch: 2 | loss: 0.2611283
	speed: 0.2150s/iter; left time: 6610.4009s
	iters: 300, epoch: 2 | loss: 0.2683108
	speed: 0.2203s/iter; left time: 6749.5433s
	iters: 400, epoch: 2 | loss: 0.3201008
	speed: 0.2148s/iter; left time: 6560.0444s
	iters: 500, epoch: 2 | loss: 0.2124072
	speed: 0.2134s/iter; left time: 6496.4329s
	iters: 600, epoch: 2 | loss: 0.2529904
	speed: 0.2008s/iter; left time: 6092.9828s
	iters: 700, epoch: 2 | loss: 0.2657901
	speed: 0.2117s/iter; left time: 6402.5046s
	iters: 800, epoch: 2 | loss: 0.2799434
	speed: 0.2186s/iter; left time: 6590.2312s
	iters: 900, epoch: 2 | loss: 0.1992970
	speed: 0.2191s/iter; left time: 6583.7519s
	iters: 1000, epoch: 2 | loss: 0.1792958
	speed: 0.2137s/iter; left time: 6399.9163s
Epoch: 2 cost time: 229.51379704475403
Epoch: 2, Steps: 1067 | Train Loss: 0.2383349 Vali Loss: 0.8126502 Test Loss: 0.6079515
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2017968
	speed: 1.5591s/iter; left time: 46426.4623s
	iters: 200, epoch: 3 | loss: 0.1805002
	speed: 0.2214s/iter; left time: 6571.1158s
	iters: 300, epoch: 3 | loss: 0.2212021
	speed: 0.2235s/iter; left time: 6610.9830s
	iters: 400, epoch: 3 | loss: 0.1624983
	speed: 0.2180s/iter; left time: 6427.2705s
	iters: 500, epoch: 3 | loss: 0.1729877
	speed: 0.2168s/iter; left time: 6368.0055s
	iters: 600, epoch: 3 | loss: 0.1878571
	speed: 0.2134s/iter; left time: 6248.7750s
	iters: 700, epoch: 3 | loss: 0.1743173
	speed: 0.2102s/iter; left time: 6134.3871s
	iters: 800, epoch: 3 | loss: 0.1529079
	speed: 0.2098s/iter; left time: 6099.5879s
	iters: 900, epoch: 3 | loss: 0.1921890
	speed: 0.2138s/iter; left time: 6196.4436s
	iters: 1000, epoch: 3 | loss: 0.1573988
	speed: 0.2156s/iter; left time: 6226.3359s
Epoch: 3 cost time: 232.0969638824463
Epoch: 3, Steps: 1067 | Train Loss: 0.1709353 Vali Loss: 0.7957168 Test Loss: 0.5829069
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1426409
	speed: 1.4998s/iter; left time: 43058.7186s
	iters: 200, epoch: 4 | loss: 0.1397653
	speed: 0.2106s/iter; left time: 6026.4938s
	iters: 300, epoch: 4 | loss: 0.1334975
	speed: 0.2106s/iter; left time: 6004.7260s
	iters: 400, epoch: 4 | loss: 0.1314098
	speed: 0.2204s/iter; left time: 6262.7880s
	iters: 500, epoch: 4 | loss: 0.1466168
	speed: 0.2247s/iter; left time: 6360.4348s
	iters: 600, epoch: 4 | loss: 0.1596710
	speed: 0.2188s/iter; left time: 6170.9810s
	iters: 700, epoch: 4 | loss: 0.1342992
	speed: 0.2191s/iter; left time: 6159.9180s
	iters: 800, epoch: 4 | loss: 0.1713958
	speed: 0.2240s/iter; left time: 6273.7867s
	iters: 900, epoch: 4 | loss: 0.1457447
	speed: 0.2155s/iter; left time: 6014.4692s
	iters: 1000, epoch: 4 | loss: 0.1258240
	speed: 0.2151s/iter; left time: 5981.8807s
Epoch: 4 cost time: 232.38113260269165
Epoch: 4, Steps: 1067 | Train Loss: 0.1419423 Vali Loss: 0.8161456 Test Loss: 0.5925147
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Autoformer_ETTm1_336_96_Autoformer_ETTm1_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.6009625792503357, mae:0.5301957726478577

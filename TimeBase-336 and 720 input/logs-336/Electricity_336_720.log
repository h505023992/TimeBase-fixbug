Args in experiment:
Namespace(is_training=1, model_id='Electricity_336_720', model='LightTimeBaseTST', data='custom', root_path='./dataset/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, period_len=24, basis_num=6, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=1, embed_type=0, enc_in=321, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.5, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=5, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:5
96300
>>>>>>>start training : Electricity_336_720_LightTimeBaseTST_custom_ftM_sl336_pl720_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17357
val 1913
test 4541
Epoch: 1 cost time: 94.80964064598083
Epoch: 1, Steps: 68 | Train Loss: 0.2696804 Vali Loss: 0.2053359 Test Loss: 0.2339693
Validation loss decreased (inf --> 0.205336).  Saving model ...
Updating learning rate to 0.5
Epoch: 2 cost time: 94.3997573852539
Epoch: 2, Steps: 68 | Train Loss: 0.3091881 Vali Loss: 0.2176288 Test Loss: 0.2380556
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.5
Epoch: 3 cost time: 97.38180375099182
Epoch: 3, Steps: 68 | Train Loss: 0.2439602 Vali Loss: 0.2005043 Test Loss: 0.2283127
Validation loss decreased (0.205336 --> 0.200504).  Saving model ...
Updating learning rate to 0.5
Epoch: 4 cost time: 96.48086643218994
Epoch: 4, Steps: 68 | Train Loss: 0.2439424 Vali Loss: 0.2016231 Test Loss: 0.2316524
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.4
Epoch: 5 cost time: 98.03708958625793
Epoch: 5, Steps: 68 | Train Loss: 0.2378065 Vali Loss: 0.1993610 Test Loss: 0.2252741
Validation loss decreased (0.200504 --> 0.199361).  Saving model ...
Updating learning rate to 0.32000000000000006
Epoch: 6 cost time: 98.4017105102539
Epoch: 6, Steps: 68 | Train Loss: 0.2336660 Vali Loss: 0.1923088 Test Loss: 0.2235680
Validation loss decreased (0.199361 --> 0.192309).  Saving model ...
Updating learning rate to 0.25600000000000006
Epoch: 7 cost time: 92.27481269836426
Epoch: 7, Steps: 68 | Train Loss: 0.2311988 Vali Loss: 0.1905276 Test Loss: 0.2194670
Validation loss decreased (0.192309 --> 0.190528).  Saving model ...
Updating learning rate to 0.20480000000000004
Epoch: 8 cost time: 93.66842722892761
Epoch: 8, Steps: 68 | Train Loss: 0.2291914 Vali Loss: 0.1916497 Test Loss: 0.2181386
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.16384000000000004
Epoch: 9 cost time: 94.37951564788818
Epoch: 9, Steps: 68 | Train Loss: 0.2278312 Vali Loss: 0.1886220 Test Loss: 0.2162521
Validation loss decreased (0.190528 --> 0.188622).  Saving model ...
Updating learning rate to 0.13107200000000005
Epoch: 10 cost time: 92.6369059085846
Epoch: 10, Steps: 68 | Train Loss: 0.2267316 Vali Loss: 0.1877425 Test Loss: 0.2165335
Validation loss decreased (0.188622 --> 0.187742).  Saving model ...
Updating learning rate to 0.10485760000000004
Epoch: 11 cost time: 91.1121301651001
Epoch: 11, Steps: 68 | Train Loss: 0.2257948 Vali Loss: 0.1894658 Test Loss: 0.2141192
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.08388608000000004
Epoch: 12 cost time: 94.4655647277832
Epoch: 12, Steps: 68 | Train Loss: 0.2249656 Vali Loss: 0.1868785 Test Loss: 0.2145740
Validation loss decreased (0.187742 --> 0.186878).  Saving model ...
Updating learning rate to 0.06710886400000003
Epoch: 13 cost time: 95.78801894187927
Epoch: 13, Steps: 68 | Train Loss: 0.2244613 Vali Loss: 0.1871911 Test Loss: 0.2130270
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.05368709120000003
Epoch: 14 cost time: 91.16377663612366
Epoch: 14, Steps: 68 | Train Loss: 0.2237840 Vali Loss: 0.1869338 Test Loss: 0.2129589
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.042949672960000025
Epoch: 15 cost time: 91.75466299057007
Epoch: 15, Steps: 68 | Train Loss: 0.2233626 Vali Loss: 0.1875545 Test Loss: 0.2126118
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.03435973836800002
Epoch: 16 cost time: 86.41917610168457
Epoch: 16, Steps: 68 | Train Loss: 0.2230453 Vali Loss: 0.1865377 Test Loss: 0.2119988
Validation loss decreased (0.186878 --> 0.186538).  Saving model ...
Updating learning rate to 0.027487790694400018
Epoch: 17 cost time: 82.57898592948914
Epoch: 17, Steps: 68 | Train Loss: 0.2226026 Vali Loss: 0.1858931 Test Loss: 0.2121260
Validation loss decreased (0.186538 --> 0.185893).  Saving model ...
Updating learning rate to 0.021990232555520017
Epoch: 18 cost time: 81.45351815223694
Epoch: 18, Steps: 68 | Train Loss: 0.2223444 Vali Loss: 0.1854628 Test Loss: 0.2115101
Validation loss decreased (0.185893 --> 0.185463).  Saving model ...
Updating learning rate to 0.017592186044416015
Epoch: 19 cost time: 85.55364322662354
Epoch: 19, Steps: 68 | Train Loss: 0.2221480 Vali Loss: 0.1833235 Test Loss: 0.2120072
Validation loss decreased (0.185463 --> 0.183324).  Saving model ...
Updating learning rate to 0.014073748835532812
Epoch: 20 cost time: 80.85612177848816
Epoch: 20, Steps: 68 | Train Loss: 0.2218267 Vali Loss: 0.1838083 Test Loss: 0.2118475
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.011258999068426251
Epoch: 21 cost time: 82.58513522148132
Epoch: 21, Steps: 68 | Train Loss: 0.2216277 Vali Loss: 0.1845375 Test Loss: 0.2116939
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.009007199254741001
Epoch: 22 cost time: 80.94571590423584
Epoch: 22, Steps: 68 | Train Loss: 0.2215745 Vali Loss: 0.1844616 Test Loss: 0.2111610
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.007205759403792801
Epoch: 23 cost time: 84.26220488548279
Epoch: 23, Steps: 68 | Train Loss: 0.2214170 Vali Loss: 0.1825410 Test Loss: 0.2108746
Validation loss decreased (0.183324 --> 0.182541).  Saving model ...
Updating learning rate to 0.0057646075230342415
Epoch: 24 cost time: 82.2445240020752
Epoch: 24, Steps: 68 | Train Loss: 0.2212513 Vali Loss: 0.1842749 Test Loss: 0.2107661
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0046116860184273935
Epoch: 25 cost time: 80.2810127735138
Epoch: 25, Steps: 68 | Train Loss: 0.2211882 Vali Loss: 0.1840400 Test Loss: 0.2106845
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.003689348814741915
Epoch: 26 cost time: 79.144052028656
Epoch: 26, Steps: 68 | Train Loss: 0.2211149 Vali Loss: 0.1826917 Test Loss: 0.2113112
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.002951479051793532
Epoch: 27 cost time: 81.09805130958557
Epoch: 27, Steps: 68 | Train Loss: 0.2210874 Vali Loss: 0.1840829 Test Loss: 0.2108525
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.002361183241434826
Epoch: 28 cost time: 81.33134937286377
Epoch: 28, Steps: 68 | Train Loss: 0.2210331 Vali Loss: 0.1841953 Test Loss: 0.2107470
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : Electricity_336_720_LightTimeBaseTST_custom_ftM_sl336_pl720_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.20954880321025848, mae:0.29429417848587036, rse:0.45772409439086914

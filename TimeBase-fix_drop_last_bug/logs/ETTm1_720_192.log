Args in experiment:
Namespace(is_training=1, model_id='ETTm1_720_192', model='LightTimeBaseTST', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=192, period_len=4, basis_num=20, use_period_norm=1, use_orthogonal=1, orthogonal_weight=0.04, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.02, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:1
4628
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 127680.0
Params: 4628.0
127680.0 MACs
>>>>>>>start training : ETTm1_720_192_LightTimeBaseTST_ETTm1_ftM_sl720_pl192_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5032984
	speed: 0.0786s/iter; left time: 303.6056s
Max Memory (MB): 35.4619140625
Epoch: 1 cost time: 10.309162616729736
Epoch: 1, Steps: 132 | Train Loss: 0.5115677 Vali Loss: 0.9323074 Test Loss: 0.5663409
Validation loss decreased (inf --> 0.932307).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 2 | loss: 0.3380247
	speed: 0.2152s/iter; left time: 802.5745s
Max Memory (MB): 35.4619140625
Epoch: 2 cost time: 7.442866802215576
Epoch: 2, Steps: 132 | Train Loss: 0.3688402 Vali Loss: 0.6181113 Test Loss: 0.3789889
Validation loss decreased (0.932307 --> 0.618111).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 3 | loss: 0.3627359
	speed: 0.1656s/iter; left time: 595.7729s
Max Memory (MB): 35.4619140625
Epoch: 3 cost time: 8.481149196624756
Epoch: 3, Steps: 132 | Train Loss: 0.3376451 Vali Loss: 0.5705891 Test Loss: 0.3745316
Validation loss decreased (0.618111 --> 0.570589).  Saving model ...
Updating learning rate to 0.02
	iters: 100, epoch: 4 | loss: 0.3336491
	speed: 0.2450s/iter; left time: 848.8261s
Max Memory (MB): 35.4619140625
Epoch: 4 cost time: 10.54688572883606
Epoch: 4, Steps: 132 | Train Loss: 0.3315323 Vali Loss: 0.5678552 Test Loss: 0.3818499
Validation loss decreased (0.570589 --> 0.567855).  Saving model ...
Updating learning rate to 0.016
	iters: 100, epoch: 5 | loss: 0.3276503
	speed: 0.1982s/iter; left time: 660.6467s
Max Memory (MB): 35.4619140625
Epoch: 5 cost time: 9.832000732421875
Epoch: 5, Steps: 132 | Train Loss: 0.3271993 Vali Loss: 0.5508769 Test Loss: 0.3685610
Validation loss decreased (0.567855 --> 0.550877).  Saving model ...
Updating learning rate to 0.012800000000000002
	iters: 100, epoch: 6 | loss: 0.3125400
	speed: 0.2460s/iter; left time: 787.2883s
Max Memory (MB): 35.4619140625
Epoch: 6 cost time: 11.212607145309448
Epoch: 6, Steps: 132 | Train Loss: 0.3222507 Vali Loss: 0.5386572 Test Loss: 0.3661821
Validation loss decreased (0.550877 --> 0.538657).  Saving model ...
Updating learning rate to 0.010240000000000003
	iters: 100, epoch: 7 | loss: 0.3290609
	speed: 0.2090s/iter; left time: 641.2940s
Max Memory (MB): 35.4619140625
Epoch: 7 cost time: 8.309187889099121
Epoch: 7, Steps: 132 | Train Loss: 0.3191770 Vali Loss: 0.5378978 Test Loss: 0.3663732
Validation loss decreased (0.538657 --> 0.537898).  Saving model ...
Updating learning rate to 0.008192000000000001
	iters: 100, epoch: 8 | loss: 0.3055212
	speed: 0.2050s/iter; left time: 602.1636s
Max Memory (MB): 35.4619140625
Epoch: 8 cost time: 9.021445274353027
Epoch: 8, Steps: 132 | Train Loss: 0.3155499 Vali Loss: 0.5496015 Test Loss: 0.3605954
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0065536000000000014
	iters: 100, epoch: 9 | loss: 0.3198942
	speed: 0.2159s/iter; left time: 605.6182s
Max Memory (MB): 35.4619140625
Epoch: 9 cost time: 9.321705102920532
Epoch: 9, Steps: 132 | Train Loss: 0.3138616 Vali Loss: 0.5552892 Test Loss: 0.3553269
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.005242880000000002
	iters: 100, epoch: 10 | loss: 0.3323222
	speed: 0.2293s/iter; left time: 612.8911s
Max Memory (MB): 35.4619140625
Epoch: 10 cost time: 12.232405185699463
Epoch: 10, Steps: 132 | Train Loss: 0.3135006 Vali Loss: 0.5496645 Test Loss: 0.3541523
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.004194304000000002
	iters: 100, epoch: 11 | loss: 0.2967109
	speed: 0.2292s/iter; left time: 582.3513s
Max Memory (MB): 35.4619140625
Epoch: 11 cost time: 7.739242315292358
Epoch: 11, Steps: 132 | Train Loss: 0.3109043 Vali Loss: 0.5289593 Test Loss: 0.3474155
Validation loss decreased (0.537898 --> 0.528959).  Saving model ...
Updating learning rate to 0.003355443200000002
	iters: 100, epoch: 12 | loss: 0.3014807
	speed: 0.2083s/iter; left time: 501.7651s
Max Memory (MB): 35.4619140625
Epoch: 12 cost time: 11.017830848693848
Epoch: 12, Steps: 132 | Train Loss: 0.3093151 Vali Loss: 0.5327965 Test Loss: 0.3502533
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.002684354560000001
	iters: 100, epoch: 13 | loss: 0.2878384
	speed: 0.2398s/iter; left time: 546.1233s
Max Memory (MB): 35.4619140625
Epoch: 13 cost time: 10.04638409614563
Epoch: 13, Steps: 132 | Train Loss: 0.3076351 Vali Loss: 0.5276396 Test Loss: 0.3453949
Validation loss decreased (0.528959 --> 0.527640).  Saving model ...
Updating learning rate to 0.0021474836480000013
	iters: 100, epoch: 14 | loss: 0.3028576
	speed: 0.2069s/iter; left time: 443.8742s
Max Memory (MB): 35.4619140625
Epoch: 14 cost time: 9.077503681182861
Epoch: 14, Steps: 132 | Train Loss: 0.3070888 Vali Loss: 0.5351741 Test Loss: 0.3458826
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0017179869184000011
	iters: 100, epoch: 15 | loss: 0.3031690
	speed: 0.1742s/iter; left time: 350.6828s
Max Memory (MB): 35.4619140625
Epoch: 15 cost time: 6.12747597694397
Epoch: 15, Steps: 132 | Train Loss: 0.3061635 Vali Loss: 0.5317441 Test Loss: 0.3412085
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0013743895347200009
	iters: 100, epoch: 16 | loss: 0.3092267
	speed: 0.1362s/iter; left time: 256.2401s
Max Memory (MB): 35.4619140625
Epoch: 16 cost time: 8.032812595367432
Epoch: 16, Steps: 132 | Train Loss: 0.3052338 Vali Loss: 0.5267299 Test Loss: 0.3395240
Validation loss decreased (0.527640 --> 0.526730).  Saving model ...
Updating learning rate to 0.0010995116277760007
	iters: 100, epoch: 17 | loss: 0.3017140
	speed: 0.2472s/iter; left time: 432.3883s
Max Memory (MB): 35.4619140625
Epoch: 17 cost time: 11.314951181411743
Epoch: 17, Steps: 132 | Train Loss: 0.3047941 Vali Loss: 0.5191836 Test Loss: 0.3413978
Validation loss decreased (0.526730 --> 0.519184).  Saving model ...
Updating learning rate to 0.0008796093022208007
	iters: 100, epoch: 18 | loss: 0.3316699
	speed: 0.2165s/iter; left time: 350.1330s
Max Memory (MB): 35.4619140625
Epoch: 18 cost time: 9.031545162200928
Epoch: 18, Steps: 132 | Train Loss: 0.3043545 Vali Loss: 0.5277115 Test Loss: 0.3403152
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0007036874417766406
	iters: 100, epoch: 19 | loss: 0.3024729
	speed: 0.2156s/iter; left time: 320.2160s
Max Memory (MB): 35.4619140625
Epoch: 19 cost time: 10.550636768341064
Epoch: 19, Steps: 132 | Train Loss: 0.3037610 Vali Loss: 0.5200517 Test Loss: 0.3400007
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0005629499534213125
	iters: 100, epoch: 20 | loss: 0.2758678
	speed: 0.1908s/iter; left time: 258.2080s
Max Memory (MB): 35.4619140625
Epoch: 20 cost time: 8.469876527786255
Epoch: 20, Steps: 132 | Train Loss: 0.3034937 Vali Loss: 0.5199239 Test Loss: 0.3388119
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0004503599627370501
	iters: 100, epoch: 21 | loss: 0.2978487
	speed: 0.2050s/iter; left time: 250.3028s
Max Memory (MB): 35.4619140625
Epoch: 21 cost time: 10.473618745803833
Epoch: 21, Steps: 132 | Train Loss: 0.3029516 Vali Loss: 0.5181177 Test Loss: 0.3394639
Validation loss decreased (0.519184 --> 0.518118).  Saving model ...
Updating learning rate to 0.00036028797018964004
	iters: 100, epoch: 22 | loss: 0.2829535
	speed: 0.2490s/iter; left time: 271.1977s
Max Memory (MB): 35.4619140625
Epoch: 22 cost time: 9.951133251190186
Epoch: 22, Steps: 132 | Train Loss: 0.3027841 Vali Loss: 0.5183930 Test Loss: 0.3380395
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00028823037615171204
	iters: 100, epoch: 23 | loss: 0.2914788
	speed: 0.1827s/iter; left time: 174.8374s
Max Memory (MB): 35.4619140625
Epoch: 23 cost time: 7.826038599014282
Epoch: 23, Steps: 132 | Train Loss: 0.3024113 Vali Loss: 0.5245034 Test Loss: 0.3385989
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00023058430092136968
	iters: 100, epoch: 24 | loss: 0.2965318
	speed: 0.2299s/iter; left time: 189.6548s
Max Memory (MB): 35.4619140625
Epoch: 24 cost time: 10.152260303497314
Epoch: 24, Steps: 132 | Train Loss: 0.3022912 Vali Loss: 0.5219283 Test Loss: 0.3387660
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00018446744073709575
	iters: 100, epoch: 25 | loss: 0.2926897
	speed: 0.1814s/iter; left time: 125.6995s
Max Memory (MB): 35.4619140625
Epoch: 25 cost time: 9.075185537338257
Epoch: 25, Steps: 132 | Train Loss: 0.3020423 Vali Loss: 0.5265652 Test Loss: 0.3383926
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001475739525896766
	iters: 100, epoch: 26 | loss: 0.3097252
	speed: 0.2369s/iter; left time: 132.8761s
Max Memory (MB): 35.4619140625
Epoch: 26 cost time: 10.538617372512817
Epoch: 26, Steps: 132 | Train Loss: 0.3020774 Vali Loss: 0.5164072 Test Loss: 0.3383621
Validation loss decreased (0.518118 --> 0.516407).  Saving model ...
Updating learning rate to 0.00011805916207174128
	iters: 100, epoch: 27 | loss: 0.3108286
	speed: 0.2113s/iter; left time: 90.6298s
Max Memory (MB): 35.4619140625
Epoch: 27 cost time: 9.04178762435913
Epoch: 27, Steps: 132 | Train Loss: 0.3019348 Vali Loss: 0.5189993 Test Loss: 0.3371578
EarlyStopping counter: 1 out of 5
Updating learning rate to 9.444732965739304e-05
	iters: 100, epoch: 28 | loss: 0.2908515
	speed: 0.1927s/iter; left time: 57.2452s
Max Memory (MB): 35.4619140625
Epoch: 28 cost time: 10.19945240020752
Epoch: 28, Steps: 132 | Train Loss: 0.3016119 Vali Loss: 0.5222672 Test Loss: 0.3378093
EarlyStopping counter: 2 out of 5
Updating learning rate to 7.555786372591443e-05
	iters: 100, epoch: 29 | loss: 0.3032278
	speed: 0.2093s/iter; left time: 34.5296s
Max Memory (MB): 35.4619140625
Epoch: 29 cost time: 8.470531463623047
Epoch: 29, Steps: 132 | Train Loss: 0.3017061 Vali Loss: 0.5196713 Test Loss: 0.3383608
EarlyStopping counter: 3 out of 5
Updating learning rate to 6.044629098073155e-05
	iters: 100, epoch: 30 | loss: 0.3061329
	speed: 0.1810s/iter; left time: 5.9718s
Max Memory (MB): 35.4619140625
Epoch: 30 cost time: 10.795848369598389
Epoch: 30, Steps: 132 | Train Loss: 0.3017658 Vali Loss: 0.5187846 Test Loss: 0.3378984
EarlyStopping counter: 4 out of 5
Updating learning rate to 4.835703278458524e-05
Final Max Memory (MB): 35.4619140625
>>>>>>>testing : ETTm1_720_192_LightTimeBaseTST_ETTm1_ftM_sl720_pl192_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.3385310173034668, mae:0.3712659776210785, rse:0.5538609623908997

Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Informer_ETTm1_192_96', model='Informer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Informer_ETTm1_192_96_Informer_ETTm1_ftM_sl192_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4276868
	speed: 0.2889s/iter; left time: 9261.3397s
	iters: 200, epoch: 1 | loss: 0.3353617
	speed: 0.2386s/iter; left time: 7627.4106s
	iters: 300, epoch: 1 | loss: 0.2981989
	speed: 0.2341s/iter; left time: 7459.6312s
	iters: 400, epoch: 1 | loss: 0.2736607
	speed: 0.2356s/iter; left time: 7481.6902s
	iters: 500, epoch: 1 | loss: 0.2723219
	speed: 0.2361s/iter; left time: 7475.1250s
	iters: 600, epoch: 1 | loss: 0.3361457
	speed: 0.2380s/iter; left time: 7512.1504s
	iters: 700, epoch: 1 | loss: 0.2402953
	speed: 0.2336s/iter; left time: 7348.8768s
	iters: 800, epoch: 1 | loss: 0.2502707
	speed: 0.2330s/iter; left time: 7308.6038s
	iters: 900, epoch: 1 | loss: 0.3403870
	speed: 0.2329s/iter; left time: 7279.1674s
	iters: 1000, epoch: 1 | loss: 0.2315494
	speed: 0.2308s/iter; left time: 7192.9990s
Epoch: 1 cost time: 257.1990180015564
Epoch: 1, Steps: 1072 | Train Loss: 0.3143352 Vali Loss: 0.6681269 Test Loss: 0.6076975
Validation loss decreased (inf --> 0.668127).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2105309
	speed: 1.1739s/iter; left time: 36377.9784s
	iters: 200, epoch: 2 | loss: 0.2732247
	speed: 0.2327s/iter; left time: 7187.7396s
	iters: 300, epoch: 2 | loss: 0.2421575
	speed: 0.2349s/iter; left time: 7232.1610s
	iters: 400, epoch: 2 | loss: 0.2211207
	speed: 0.2332s/iter; left time: 7156.2286s
	iters: 500, epoch: 2 | loss: 0.2212546
	speed: 0.2310s/iter; left time: 7067.1601s
	iters: 600, epoch: 2 | loss: 0.2194117
	speed: 0.2312s/iter; left time: 7048.0680s
	iters: 700, epoch: 2 | loss: 0.1925979
	speed: 0.2309s/iter; left time: 7017.3493s
	iters: 800, epoch: 2 | loss: 0.2250703
	speed: 0.2351s/iter; left time: 7119.9693s
	iters: 900, epoch: 2 | loss: 0.1882733
	speed: 0.2343s/iter; left time: 7073.5504s
	iters: 1000, epoch: 2 | loss: 0.2190774
	speed: 0.2323s/iter; left time: 6990.9689s
Epoch: 2 cost time: 250.70234203338623
Epoch: 2, Steps: 1072 | Train Loss: 0.2275449 Vali Loss: 0.7994627 Test Loss: 0.7930685
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1778079
	speed: 1.1739s/iter; left time: 35119.0212s
	iters: 200, epoch: 3 | loss: 0.1856978
	speed: 0.2355s/iter; left time: 7020.9928s
	iters: 300, epoch: 3 | loss: 0.1656268
	speed: 0.2377s/iter; left time: 7063.4109s
	iters: 400, epoch: 3 | loss: 0.1776059
	speed: 0.2360s/iter; left time: 6989.4428s
	iters: 500, epoch: 3 | loss: 0.1677690
	speed: 0.2322s/iter; left time: 6852.8140s
	iters: 600, epoch: 3 | loss: 0.1988827
	speed: 0.2326s/iter; left time: 6841.7565s
	iters: 700, epoch: 3 | loss: 0.1712786
	speed: 0.2328s/iter; left time: 6825.5064s
	iters: 800, epoch: 3 | loss: 0.1530663
	speed: 0.2363s/iter; left time: 6903.7902s
	iters: 900, epoch: 3 | loss: 0.1624494
	speed: 0.2353s/iter; left time: 6851.2602s
	iters: 1000, epoch: 3 | loss: 0.1782038
	speed: 0.2340s/iter; left time: 6790.8091s
Epoch: 3 cost time: 252.20387983322144
Epoch: 3, Steps: 1072 | Train Loss: 0.1767677 Vali Loss: 0.8197035 Test Loss: 0.8219496
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1508337
	speed: 1.1797s/iter; left time: 34029.2616s
	iters: 200, epoch: 4 | loss: 0.1456019
	speed: 0.2355s/iter; left time: 6768.0946s
	iters: 300, epoch: 4 | loss: 0.1492105
	speed: 0.2327s/iter; left time: 6665.7551s
	iters: 400, epoch: 4 | loss: 0.1495962
	speed: 0.2317s/iter; left time: 6613.3979s
	iters: 500, epoch: 4 | loss: 0.1545392
	speed: 0.2323s/iter; left time: 6606.7657s
	iters: 600, epoch: 4 | loss: 0.1560627
	speed: 0.2316s/iter; left time: 6564.9980s
	iters: 700, epoch: 4 | loss: 0.1248595
	speed: 0.2322s/iter; left time: 6559.0466s
	iters: 800, epoch: 4 | loss: 0.1287124
	speed: 0.2338s/iter; left time: 6581.6444s
	iters: 900, epoch: 4 | loss: 0.1462630
	speed: 0.2365s/iter; left time: 6633.5060s
	iters: 1000, epoch: 4 | loss: 0.1418117
	speed: 0.2322s/iter; left time: 6490.0366s
Epoch: 4 cost time: 250.62072825431824
Epoch: 4, Steps: 1072 | Train Loss: 0.1486766 Vali Loss: 0.9233734 Test Loss: 0.9502371
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Informer_ETTm1_192_96_Informer_ETTm1_ftM_sl192_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.6070173978805542, mae:0.541876494884491

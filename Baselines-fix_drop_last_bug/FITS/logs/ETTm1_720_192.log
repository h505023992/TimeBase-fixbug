Args in experiment:
Namespace(is_training=1, model_id='ETTm1_720_192', model='FITS', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=196, base_T=24, H_order=6)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H6_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  43552768.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.3469052
	speed: 0.0858s/iter; left time: 665.5796s
	iters: 200, epoch: 1 | loss: 0.2894922
	speed: 0.0735s/iter; left time: 562.8570s
Epoch: 1 cost time: 20.248722076416016
Epoch: 1, Steps: 262 | Train Loss: 0.3658277 Vali Loss: 0.7221369 Test Loss: 0.4773000
Validation loss decreased (inf --> 0.722137).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2256158
	speed: 0.3174s/iter; left time: 2380.4116s
	iters: 200, epoch: 2 | loss: 0.1893284
	speed: 0.0594s/iter; left time: 439.7286s
Epoch: 2 cost time: 17.07459282875061
Epoch: 2, Steps: 262 | Train Loss: 0.2092232 Vali Loss: 0.6610022 Test Loss: 0.4509076
Validation loss decreased (0.722137 --> 0.661002).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.1739866
	speed: 0.2833s/iter; left time: 2050.5167s
	iters: 200, epoch: 3 | loss: 0.1544552
	speed: 0.0648s/iter; left time: 462.3290s
Epoch: 3 cost time: 17.553956270217896
Epoch: 3, Steps: 262 | Train Loss: 0.1574429 Vali Loss: 0.6307299 Test Loss: 0.4323976
Validation loss decreased (0.661002 --> 0.630730).  Saving model ...
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.1384475
	speed: 0.2747s/iter; left time: 1915.7816s
	iters: 200, epoch: 4 | loss: 0.1181724
	speed: 0.0537s/iter; left time: 369.3457s
Epoch: 4 cost time: 15.811587572097778
Epoch: 4, Steps: 262 | Train Loss: 0.1278532 Vali Loss: 0.6105376 Test Loss: 0.4163918
Validation loss decreased (0.630730 --> 0.610538).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.1112754
	speed: 0.2971s/iter; left time: 1994.4627s
	iters: 200, epoch: 5 | loss: 0.1044174
	speed: 0.0637s/iter; left time: 420.9990s
Epoch: 5 cost time: 19.194629430770874
Epoch: 5, Steps: 262 | Train Loss: 0.1093839 Vali Loss: 0.5926555 Test Loss: 0.4041668
Validation loss decreased (0.610538 --> 0.592656).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.0926514
	speed: 0.3197s/iter; left time: 2062.2977s
	iters: 200, epoch: 6 | loss: 0.0949331
	speed: 0.0616s/iter; left time: 391.0814s
Epoch: 6 cost time: 17.427651405334473
Epoch: 6, Steps: 262 | Train Loss: 0.0974964 Vali Loss: 0.5779575 Test Loss: 0.3943961
Validation loss decreased (0.592656 --> 0.577957).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.0939944
	speed: 0.2730s/iter; left time: 1689.6649s
	iters: 200, epoch: 7 | loss: 0.0832418
	speed: 0.0562s/iter; left time: 342.3448s
Epoch: 7 cost time: 17.582220792770386
Epoch: 7, Steps: 262 | Train Loss: 0.0896762 Vali Loss: 0.5693486 Test Loss: 0.3849544
Validation loss decreased (0.577957 --> 0.569349).  Saving model ...
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.0848781
	speed: 0.2803s/iter; left time: 1661.1624s
	iters: 200, epoch: 8 | loss: 0.0744817
	speed: 0.0626s/iter; left time: 364.5717s
Epoch: 8 cost time: 17.24294424057007
Epoch: 8, Steps: 262 | Train Loss: 0.0843991 Vali Loss: 0.5593333 Test Loss: 0.3800344
Validation loss decreased (0.569349 --> 0.559333).  Saving model ...
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.0877454
	speed: 0.3025s/iter; left time: 1713.5848s
	iters: 200, epoch: 9 | loss: 0.0795871
	speed: 0.0651s/iter; left time: 362.5267s
Epoch: 9 cost time: 18.2008855342865
Epoch: 9, Steps: 262 | Train Loss: 0.0807503 Vali Loss: 0.5540581 Test Loss: 0.3740805
Validation loss decreased (0.559333 --> 0.554058).  Saving model ...
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.0823345
	speed: 0.2787s/iter; left time: 1505.8102s
	iters: 200, epoch: 10 | loss: 0.0761143
	speed: 0.0554s/iter; left time: 293.5956s
Epoch: 10 cost time: 15.456626176834106
Epoch: 10, Steps: 262 | Train Loss: 0.0782217 Vali Loss: 0.5498266 Test Loss: 0.3696641
Validation loss decreased (0.554058 --> 0.549827).  Saving model ...
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.0863958
	speed: 0.2540s/iter; left time: 1305.9560s
	iters: 200, epoch: 11 | loss: 0.0758282
	speed: 0.0537s/iter; left time: 270.7581s
Epoch: 11 cost time: 15.041550636291504
Epoch: 11, Steps: 262 | Train Loss: 0.0764335 Vali Loss: 0.5468925 Test Loss: 0.3656481
Validation loss decreased (0.549827 --> 0.546893).  Saving model ...
Updating learning rate to 0.00029936846961918935
	iters: 100, epoch: 12 | loss: 0.0756233
	speed: 0.2509s/iter; left time: 1224.1560s
	iters: 200, epoch: 12 | loss: 0.0751136
	speed: 0.0594s/iter; left time: 283.7662s
Epoch: 12 cost time: 16.49906635284424
Epoch: 12, Steps: 262 | Train Loss: 0.0751273 Vali Loss: 0.5412339 Test Loss: 0.3630389
Validation loss decreased (0.546893 --> 0.541234).  Saving model ...
Updating learning rate to 0.0002844000461382298
	iters: 100, epoch: 13 | loss: 0.0726122
	speed: 0.2815s/iter; left time: 1299.7457s
	iters: 200, epoch: 13 | loss: 0.0693047
	speed: 0.0609s/iter; left time: 274.9765s
Epoch: 13 cost time: 16.892921924591064
Epoch: 13, Steps: 262 | Train Loss: 0.0741676 Vali Loss: 0.5401194 Test Loss: 0.3601666
Validation loss decreased (0.541234 --> 0.540119).  Saving model ...
Updating learning rate to 0.0002701800438313183
	iters: 100, epoch: 14 | loss: 0.0768296
	speed: 0.2485s/iter; left time: 1082.3977s
	iters: 200, epoch: 14 | loss: 0.0769019
	speed: 0.0528s/iter; left time: 224.5894s
Epoch: 14 cost time: 14.595898866653442
Epoch: 14, Steps: 262 | Train Loss: 0.0734640 Vali Loss: 0.5392562 Test Loss: 0.3577204
Validation loss decreased (0.540119 --> 0.539256).  Saving model ...
Updating learning rate to 0.0002566710416397524
	iters: 100, epoch: 15 | loss: 0.0704608
	speed: 0.2405s/iter; left time: 984.1822s
	iters: 200, epoch: 15 | loss: 0.0701740
	speed: 0.0515s/iter; left time: 205.6634s
Epoch: 15 cost time: 14.814027786254883
Epoch: 15, Steps: 262 | Train Loss: 0.0729691 Vali Loss: 0.5374037 Test Loss: 0.3557619
Validation loss decreased (0.539256 --> 0.537404).  Saving model ...
Updating learning rate to 0.00024383748955776477
	iters: 100, epoch: 16 | loss: 0.0710779
	speed: 0.2301s/iter; left time: 881.6468s
	iters: 200, epoch: 16 | loss: 0.0710124
	speed: 0.0516s/iter; left time: 192.5927s
Epoch: 16 cost time: 15.022704839706421
Epoch: 16, Steps: 262 | Train Loss: 0.0725788 Vali Loss: 0.5366515 Test Loss: 0.3540237
Validation loss decreased (0.537404 --> 0.536651).  Saving model ...
Updating learning rate to 0.0002316456150798765
	iters: 100, epoch: 17 | loss: 0.0714865
	speed: 0.2779s/iter; left time: 991.7650s
	iters: 200, epoch: 17 | loss: 0.0740624
	speed: 0.0642s/iter; left time: 222.6647s
Epoch: 17 cost time: 17.432481050491333
Epoch: 17, Steps: 262 | Train Loss: 0.0723109 Vali Loss: 0.5331711 Test Loss: 0.3527236
Validation loss decreased (0.536651 --> 0.533171).  Saving model ...
Updating learning rate to 0.00022006333432588268
	iters: 100, epoch: 18 | loss: 0.0666287
	speed: 0.2543s/iter; left time: 840.9361s
	iters: 200, epoch: 18 | loss: 0.0694469
	speed: 0.0513s/iter; left time: 164.3811s
Epoch: 18 cost time: 14.09587574005127
Epoch: 18, Steps: 262 | Train Loss: 0.0720926 Vali Loss: 0.5337274 Test Loss: 0.3513406
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00020906016760958854
	iters: 100, epoch: 19 | loss: 0.0739652
	speed: 0.2269s/iter; left time: 690.9334s
	iters: 200, epoch: 19 | loss: 0.0746422
	speed: 0.0530s/iter; left time: 156.0814s
Epoch: 19 cost time: 15.081685304641724
Epoch: 19, Steps: 262 | Train Loss: 0.0719302 Vali Loss: 0.5340536 Test Loss: 0.3500965
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0001986071592291091
	iters: 100, epoch: 20 | loss: 0.0716060
	speed: 0.2430s/iter; left time: 676.3697s
	iters: 200, epoch: 20 | loss: 0.0695832
	speed: 0.0550s/iter; left time: 147.5485s
Epoch: 20 cost time: 16.017329931259155
Epoch: 20, Steps: 262 | Train Loss: 0.0718070 Vali Loss: 0.5329509 Test Loss: 0.3489553
Validation loss decreased (0.533171 --> 0.532951).  Saving model ...
Updating learning rate to 0.00018867680126765363
	iters: 100, epoch: 21 | loss: 0.0636141
	speed: 0.3351s/iter; left time: 844.6856s
	iters: 200, epoch: 21 | loss: 0.0766970
	speed: 0.0707s/iter; left time: 171.2189s
Epoch: 21 cost time: 19.518606901168823
Epoch: 21, Steps: 262 | Train Loss: 0.0717252 Vali Loss: 0.5318579 Test Loss: 0.3484469
Validation loss decreased (0.532951 --> 0.531858).  Saving model ...
Updating learning rate to 0.00017924296120427094
	iters: 100, epoch: 22 | loss: 0.0737499
	speed: 0.2747s/iter; left time: 620.6574s
	iters: 200, epoch: 22 | loss: 0.0707603
	speed: 0.0693s/iter; left time: 149.7237s
Epoch: 22 cost time: 16.94452738761902
Epoch: 22, Steps: 262 | Train Loss: 0.0716877 Vali Loss: 0.5316859 Test Loss: 0.3476804
Validation loss decreased (0.531858 --> 0.531686).  Saving model ...
Updating learning rate to 0.0001702808131440574
	iters: 100, epoch: 23 | loss: 0.0639401
	speed: 0.2869s/iter; left time: 572.9915s
	iters: 200, epoch: 23 | loss: 0.0684501
	speed: 0.0662s/iter; left time: 125.5455s
Epoch: 23 cost time: 18.240652561187744
Epoch: 23, Steps: 262 | Train Loss: 0.0716242 Vali Loss: 0.5325285 Test Loss: 0.3470038
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001617667724868545
	iters: 100, epoch: 24 | loss: 0.0716076
	speed: 0.2859s/iter; left time: 496.0642s
	iters: 200, epoch: 24 | loss: 0.0727833
	speed: 0.0704s/iter; left time: 115.0285s
Epoch: 24 cost time: 17.93950080871582
Epoch: 24, Steps: 262 | Train Loss: 0.0715991 Vali Loss: 0.5312182 Test Loss: 0.3470933
Validation loss decreased (0.531686 --> 0.531218).  Saving model ...
Updating learning rate to 0.00015367843386251178
	iters: 100, epoch: 25 | loss: 0.0749980
	speed: 0.3282s/iter; left time: 483.3844s
	iters: 200, epoch: 25 | loss: 0.0670161
	speed: 0.0709s/iter; left time: 97.3658s
Epoch: 25 cost time: 19.73757290840149
Epoch: 25, Steps: 262 | Train Loss: 0.0715540 Vali Loss: 0.5325050 Test Loss: 0.3465063
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001459945121693862
	iters: 100, epoch: 26 | loss: 0.0737050
	speed: 0.2986s/iter; left time: 361.6049s
	iters: 200, epoch: 26 | loss: 0.0764313
	speed: 0.0587s/iter; left time: 65.2123s
Epoch: 26 cost time: 17.12812304496765
Epoch: 26, Steps: 262 | Train Loss: 0.0715532 Vali Loss: 0.5308615 Test Loss: 0.3462448
Validation loss decreased (0.531218 --> 0.530861).  Saving model ...
Updating learning rate to 0.00013869478656091687
	iters: 100, epoch: 27 | loss: 0.0733108
	speed: 0.2819s/iter; left time: 267.5303s
	iters: 200, epoch: 27 | loss: 0.0734388
	speed: 0.0588s/iter; left time: 49.8918s
Epoch: 27 cost time: 16.651418209075928
Epoch: 27, Steps: 262 | Train Loss: 0.0715272 Vali Loss: 0.5313364 Test Loss: 0.3464462
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00013176004723287101
	iters: 100, epoch: 28 | loss: 0.0793775
	speed: 0.2999s/iter; left time: 206.0449s
	iters: 200, epoch: 28 | loss: 0.0723534
	speed: 0.0725s/iter; left time: 42.5537s
Epoch: 28 cost time: 19.486791610717773
Epoch: 28, Steps: 262 | Train Loss: 0.0715189 Vali Loss: 0.5315354 Test Loss: 0.3460470
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00012517204487122748
	iters: 100, epoch: 29 | loss: 0.0746764
	speed: 0.3008s/iter; left time: 127.8447s
	iters: 200, epoch: 29 | loss: 0.0663470
	speed: 0.0759s/iter; left time: 24.6649s
Epoch: 29 cost time: 18.850754976272583
Epoch: 29, Steps: 262 | Train Loss: 0.0714981 Vali Loss: 0.5309866 Test Loss: 0.3458854
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00011891344262766608
	iters: 100, epoch: 30 | loss: 0.0710916
	speed: 0.2885s/iter; left time: 47.0226s
	iters: 200, epoch: 30 | loss: 0.0646565
	speed: 0.0679s/iter; left time: 4.2755s
Epoch: 30 cost time: 18.77645707130432
Epoch: 30, Steps: 262 | Train Loss: 0.0715468 Vali Loss: 0.5314678 Test Loss: 0.3457519
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00011296777049628277
train 33649
val 11329
test 11329
Model(
  (freq_upsampler): Linear(in_features=196, out_features=248, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  43552768.0
params:  48856.0
Trainable parameters:  48856
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
	iters: 100, epoch: 1 | loss: 0.2945185
	speed: 0.0695s/iter; left time: 539.6960s
	iters: 200, epoch: 1 | loss: 0.3131000
	speed: 0.0646s/iter; left time: 495.0299s
Epoch: 1 cost time: 17.1024432182312
Epoch: 1, Steps: 262 | Train Loss: 0.3005091 Vali Loss: 0.5181526 Test Loss: 0.3402900
Validation loss decreased (inf --> 0.518153).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2953906
	speed: 0.3106s/iter; left time: 2328.8924s
	iters: 200, epoch: 2 | loss: 0.2898246
	speed: 0.0735s/iter; left time: 543.6643s
Epoch: 2 cost time: 20.929587364196777
Epoch: 2, Steps: 262 | Train Loss: 0.2985154 Vali Loss: 0.5130646 Test Loss: 0.3386148
Validation loss decreased (0.518153 --> 0.513065).  Saving model ...
Updating learning rate to 0.000475
	iters: 100, epoch: 3 | loss: 0.3072829
	speed: 0.3244s/iter; left time: 2347.4259s
	iters: 200, epoch: 3 | loss: 0.3420139
	speed: 0.0584s/iter; left time: 417.1424s
Epoch: 3 cost time: 17.484129905700684
Epoch: 3, Steps: 262 | Train Loss: 0.2979349 Vali Loss: 0.5140378 Test Loss: 0.3392005
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00045125
	iters: 100, epoch: 4 | loss: 0.2831659
	speed: 0.2765s/iter; left time: 1928.7530s
	iters: 200, epoch: 4 | loss: 0.3142766
	speed: 0.0659s/iter; left time: 452.8308s
Epoch: 4 cost time: 16.561355352401733
Epoch: 4, Steps: 262 | Train Loss: 0.2977249 Vali Loss: 0.5123872 Test Loss: 0.3385227
Validation loss decreased (0.513065 --> 0.512387).  Saving model ...
Updating learning rate to 0.0004286875
	iters: 100, epoch: 5 | loss: 0.2860583
	speed: 0.2554s/iter; left time: 1714.5389s
	iters: 200, epoch: 5 | loss: 0.2936070
	speed: 0.0525s/iter; left time: 346.9338s
Epoch: 5 cost time: 15.294421672821045
Epoch: 5, Steps: 262 | Train Loss: 0.2973777 Vali Loss: 0.5107976 Test Loss: 0.3379826
Validation loss decreased (0.512387 --> 0.510798).  Saving model ...
Updating learning rate to 0.00040725312499999993
	iters: 100, epoch: 6 | loss: 0.2738486
	speed: 0.2835s/iter; left time: 1828.8195s
	iters: 200, epoch: 6 | loss: 0.3002135
	speed: 0.0739s/iter; left time: 469.5725s
Epoch: 6 cost time: 20.089338779449463
Epoch: 6, Steps: 262 | Train Loss: 0.2973957 Vali Loss: 0.5092167 Test Loss: 0.3391385
Validation loss decreased (0.510798 --> 0.509217).  Saving model ...
Updating learning rate to 0.0003868904687499999
	iters: 100, epoch: 7 | loss: 0.2729427
	speed: 0.3234s/iter; left time: 2001.7233s
	iters: 200, epoch: 7 | loss: 0.3016547
	speed: 0.0676s/iter; left time: 411.8129s
Epoch: 7 cost time: 18.22348427772522
Epoch: 7, Steps: 262 | Train Loss: 0.2972643 Vali Loss: 0.5108686 Test Loss: 0.3390978
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00036754594531249993
	iters: 100, epoch: 8 | loss: 0.3092552
	speed: 0.2838s/iter; left time: 1682.3354s
	iters: 200, epoch: 8 | loss: 0.3293317
	speed: 0.0602s/iter; left time: 350.7346s
Epoch: 8 cost time: 18.103891611099243
Epoch: 8, Steps: 262 | Train Loss: 0.2969659 Vali Loss: 0.5104304 Test Loss: 0.3380500
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00034916864804687486
	iters: 100, epoch: 9 | loss: 0.2612231
	speed: 0.2953s/iter; left time: 1672.9428s
	iters: 200, epoch: 9 | loss: 0.2670502
	speed: 0.0712s/iter; left time: 396.1428s
Epoch: 9 cost time: 19.353297233581543
Epoch: 9, Steps: 262 | Train Loss: 0.2970906 Vali Loss: 0.5107613 Test Loss: 0.3385450
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00033171021564453113
	iters: 100, epoch: 10 | loss: 0.3169443
	speed: 0.3219s/iter; left time: 1739.0870s
	iters: 200, epoch: 10 | loss: 0.2993664
	speed: 0.0666s/iter; left time: 353.1812s
Epoch: 10 cost time: 19.58464288711548
Epoch: 10, Steps: 262 | Train Loss: 0.2967903 Vali Loss: 0.5111807 Test Loss: 0.3371213
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00031512470486230455
	iters: 100, epoch: 11 | loss: 0.3104585
	speed: 0.3120s/iter; left time: 1603.8489s
	iters: 200, epoch: 11 | loss: 0.3130556
	speed: 0.0754s/iter; left time: 380.2144s
Epoch: 11 cost time: 19.0242862701416
Epoch: 11, Steps: 262 | Train Loss: 0.2968626 Vali Loss: 0.5101584 Test Loss: 0.3378763
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTm1_720_192_FITS_ETTm1_ftM_sl720_ll48_pl192_H6_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:0.33910125494003296, mae:0.3685961961746216, rse:0.5543272495269775, corr:[0.54390836 0.55211794 0.5535572  0.5572409  0.55948025 0.5603231
 0.56216615 0.56369203 0.56403774 0.56466925 0.5654313  0.56548923
 0.56594354 0.56662256 0.5657083  0.5638023  0.5629081  0.56237215
 0.5607726  0.5588302  0.55764824 0.55696374 0.5563201  0.55529904
 0.5529764  0.5502988  0.5494012  0.5501422  0.5502407  0.5491625
 0.5487629  0.5495954  0.5502939  0.55079293 0.5514074  0.55157006
 0.5508599  0.550806   0.551337   0.55068123 0.5493991  0.54932433
 0.54986995 0.5497307  0.54964674 0.5504238  0.55051076 0.5493334
 0.5489599  0.5500346  0.5505253  0.54982084 0.549341   0.5491846
 0.5485754  0.5479647  0.54809064 0.548162   0.5476612  0.5472819
 0.54778254 0.5484302  0.5483219  0.54765826 0.5475332  0.54787076
 0.5479135  0.5474752  0.5473421  0.5480963  0.54895055 0.54873157
 0.5479276  0.54791313 0.5484162  0.5480981  0.5473107  0.54734826
 0.5478943  0.5478663  0.54736054 0.54728234 0.5477777  0.54806554
 0.5477497  0.54707086 0.54654324 0.54640704 0.54666185 0.5470101
 0.5472629  0.54756355 0.54789734 0.5478931  0.5474943  0.54713154
 0.54706305 0.5470506  0.546802   0.5465536  0.5461928  0.5455293
 0.5450265  0.5450476  0.5452097  0.54490167 0.5441705  0.5439443
 0.5441273  0.544047   0.54369366 0.54357076 0.54373395 0.54367447
 0.5432409  0.5427552  0.54235166 0.5418738  0.54149884 0.5415872
 0.5419388  0.5417029  0.5408183  0.5404463  0.5408551  0.54074067
 0.53972596 0.53922296 0.5398608  0.5404877  0.54012626 0.53966516
 0.53996676 0.5402877  0.53994024 0.53965104 0.5400791  0.5405377
 0.5405835  0.5402429  0.53996986 0.54047596 0.54148334 0.5417578
 0.5410723  0.54064476 0.54115784 0.5414266  0.54095155 0.5406244
 0.5408754  0.54085475 0.54007405 0.53929466 0.5391839  0.5394904
 0.54017574 0.5409173  0.5409723  0.54015034 0.5396923  0.54000574
 0.54031944 0.5403364  0.54050016 0.54059374 0.5402765  0.5401498
 0.5404815  0.54046696 0.5402048  0.5404649  0.5407886  0.5406022
 0.5404951  0.5409716  0.54094684 0.539908   0.53915036 0.53956133
 0.53992665 0.5395634  0.5391433  0.53901666 0.5387951  0.53892255
 0.53936577 0.53942376 0.53969425 0.54111516 0.54185414 0.5396575 ]

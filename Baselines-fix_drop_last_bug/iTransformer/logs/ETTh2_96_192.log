Args in experiment:
Namespace(is_training=1, model_id='ETTh2_96_192', model='iTransformer', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=8, e_layers=2, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=2, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)
Use GPU: cuda:2
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
MACs: 3068416.0
Params: 236608.0
3.07M MACs
>>>>>>>start training : ETTh2_96_192_iTransformer_ETTh2_M_ft96_sl48_ll192_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3934011
	speed: 0.0417s/iter; left time: 104.7255s
	iters: 200, epoch: 1 | loss: 0.6218084
	speed: 0.0267s/iter; left time: 64.2676s
Max Memory (MB): 13.216796875
Epoch: 1 cost time: 8.570836305618286
Epoch: 1, Steps: 261 | Train Loss: 0.5968446 Vali Loss: 0.2892559 Test Loss: 0.3907852
Validation loss decreased (inf --> 0.289256).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4072393
	speed: 0.2586s/iter; left time: 581.8842s
	iters: 200, epoch: 2 | loss: 0.3465062
	speed: 0.0272s/iter; left time: 58.4568s
Max Memory (MB): 13.216796875
Epoch: 2 cost time: 7.7586071491241455
Epoch: 2, Steps: 261 | Train Loss: 0.5444830 Vali Loss: 0.2818649 Test Loss: 0.3814882
Validation loss decreased (0.289256 --> 0.281865).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.4304248
	speed: 0.2486s/iter; left time: 494.4260s
	iters: 200, epoch: 3 | loss: 0.7103391
	speed: 0.0246s/iter; left time: 46.4960s
Max Memory (MB): 13.216796875
Epoch: 3 cost time: 7.189777135848999
Epoch: 3, Steps: 261 | Train Loss: 0.5243425 Vali Loss: 0.2830510 Test Loss: 0.3806545
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3451964
	speed: 0.2386s/iter; left time: 412.3656s
	iters: 200, epoch: 4 | loss: 0.3983935
	speed: 0.0250s/iter; left time: 40.7428s
Max Memory (MB): 13.216796875
Epoch: 4 cost time: 7.26732325553894
Epoch: 4, Steps: 261 | Train Loss: 0.5127011 Vali Loss: 0.2811624 Test Loss: 0.3843119
Validation loss decreased (0.281865 --> 0.281162).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3002466
	speed: 0.2550s/iter; left time: 374.0545s
	iters: 200, epoch: 5 | loss: 0.8215727
	speed: 0.0349s/iter; left time: 47.7131s
Max Memory (MB): 13.216796875
Epoch: 5 cost time: 8.833680152893066
Epoch: 5, Steps: 261 | Train Loss: 0.5084925 Vali Loss: 0.2825645 Test Loss: 0.3827424
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8379353
	speed: 0.2892s/iter; left time: 348.7800s
	iters: 200, epoch: 6 | loss: 0.4589848
	speed: 0.0279s/iter; left time: 30.8591s
Max Memory (MB): 13.216796875
Epoch: 6 cost time: 8.104197025299072
Epoch: 6, Steps: 261 | Train Loss: 0.5063680 Vali Loss: 0.2825867 Test Loss: 0.3827966
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3201257
	speed: 0.2800s/iter; left time: 264.5856s
	iters: 200, epoch: 7 | loss: 0.5536140
	speed: 0.0283s/iter; left time: 23.9337s
Max Memory (MB): 13.216796875
Epoch: 7 cost time: 8.287311792373657
Epoch: 7, Steps: 261 | Train Loss: 0.5046918 Vali Loss: 0.2828436 Test Loss: 0.3826752
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_96_192_iTransformer_ETTh2_M_ft96_sl48_ll192_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (2689, 1, 192, 7) (2689, 1, 192, 7)
test shape: (2689, 192, 7) (2689, 192, 7)
mse:0.38431182503700256, mae:0.3999941349029541

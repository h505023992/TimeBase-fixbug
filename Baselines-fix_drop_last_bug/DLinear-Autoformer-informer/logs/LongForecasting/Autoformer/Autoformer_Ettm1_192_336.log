Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Autoformer_ETTm1_192_336', model='Autoformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Autoformer_ETTm1_192_336_Autoformer_ETTm1_ftM_sl192_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4486184
	speed: 0.1829s/iter; left time: 5821.5081s
	iters: 200, epoch: 1 | loss: 0.4508478
	speed: 0.1573s/iter; left time: 4990.2680s
	iters: 300, epoch: 1 | loss: 0.4269536
	speed: 0.1617s/iter; left time: 5112.0898s
	iters: 400, epoch: 1 | loss: 0.3869626
	speed: 0.1528s/iter; left time: 4815.8987s
	iters: 500, epoch: 1 | loss: 0.4277283
	speed: 0.1564s/iter; left time: 4913.2562s
	iters: 600, epoch: 1 | loss: 0.3242215
	speed: 0.1553s/iter; left time: 4864.4769s
	iters: 700, epoch: 1 | loss: 0.3427407
	speed: 0.1563s/iter; left time: 4880.2977s
	iters: 800, epoch: 1 | loss: 0.2966976
	speed: 0.1571s/iter; left time: 4888.1141s
	iters: 900, epoch: 1 | loss: 0.3898513
	speed: 0.1518s/iter; left time: 4708.6061s
	iters: 1000, epoch: 1 | loss: 0.3311341
	speed: 0.1521s/iter; left time: 4701.6509s
Epoch: 1 cost time: 168.5147807598114
Epoch: 1, Steps: 1064 | Train Loss: 0.3817622 Vali Loss: 0.8102935 Test Loss: 0.5544946
Validation loss decreased (inf --> 0.810293).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3553480
	speed: 1.2540s/iter; left time: 38569.6757s
	iters: 200, epoch: 2 | loss: 0.3054008
	speed: 0.1499s/iter; left time: 4594.4523s
	iters: 300, epoch: 2 | loss: 0.3371649
	speed: 0.1504s/iter; left time: 4596.8624s
	iters: 400, epoch: 2 | loss: 0.3137196
	speed: 0.1561s/iter; left time: 4755.5413s
	iters: 500, epoch: 2 | loss: 0.4290217
	speed: 0.1546s/iter; left time: 4692.6887s
	iters: 600, epoch: 2 | loss: 0.2677034
	speed: 0.1553s/iter; left time: 4698.3861s
	iters: 700, epoch: 2 | loss: 0.3005998
	speed: 0.1540s/iter; left time: 4643.4500s
	iters: 800, epoch: 2 | loss: 0.2852575
	speed: 0.1544s/iter; left time: 4640.9795s
	iters: 900, epoch: 2 | loss: 0.2595637
	speed: 0.1557s/iter; left time: 4663.2793s
	iters: 1000, epoch: 2 | loss: 0.2883707
	speed: 0.1494s/iter; left time: 4460.2336s
Epoch: 2 cost time: 163.60184597969055
Epoch: 2, Steps: 1064 | Train Loss: 0.3037671 Vali Loss: 0.8879319 Test Loss: 0.6164384
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2287426
	speed: 1.3018s/iter; left time: 38654.9118s
	iters: 200, epoch: 3 | loss: 0.3182748
	speed: 0.1501s/iter; left time: 4442.5952s
	iters: 300, epoch: 3 | loss: 0.2401519
	speed: 0.1492s/iter; left time: 4399.0477s
	iters: 400, epoch: 3 | loss: 0.2726587
	speed: 0.1487s/iter; left time: 4370.8274s
	iters: 500, epoch: 3 | loss: 0.2716547
	speed: 0.1545s/iter; left time: 4526.2816s
	iters: 600, epoch: 3 | loss: 0.2945133
	speed: 0.1579s/iter; left time: 4609.4379s
	iters: 700, epoch: 3 | loss: 0.2426084
	speed: 0.1554s/iter; left time: 4520.5485s
	iters: 800, epoch: 3 | loss: 0.2218441
	speed: 0.1512s/iter; left time: 4382.5705s
	iters: 900, epoch: 3 | loss: 0.2461452
	speed: 0.1504s/iter; left time: 4345.6117s
	iters: 1000, epoch: 3 | loss: 0.2526805
	speed: 0.1510s/iter; left time: 4346.7864s
Epoch: 3 cost time: 162.79738402366638
Epoch: 3, Steps: 1064 | Train Loss: 0.2592957 Vali Loss: 0.9233639 Test Loss: 0.6102619
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2591487
	speed: 1.2700s/iter; left time: 36358.1928s
	iters: 200, epoch: 4 | loss: 0.2413951
	speed: 0.1509s/iter; left time: 4306.2351s
	iters: 300, epoch: 4 | loss: 0.2064134
	speed: 0.1510s/iter; left time: 4293.5009s
	iters: 400, epoch: 4 | loss: 0.2524366
	speed: 0.1506s/iter; left time: 4265.6207s
	iters: 500, epoch: 4 | loss: 0.2169377
	speed: 0.1530s/iter; left time: 4319.3297s
	iters: 600, epoch: 4 | loss: 0.2236995
	speed: 0.1535s/iter; left time: 4319.1721s
	iters: 700, epoch: 4 | loss: 0.2457365
	speed: 0.1552s/iter; left time: 4349.0104s
	iters: 800, epoch: 4 | loss: 0.2304519
	speed: 0.1553s/iter; left time: 4337.0543s
	iters: 900, epoch: 4 | loss: 0.2415449
	speed: 0.1572s/iter; left time: 4375.7080s
	iters: 1000, epoch: 4 | loss: 0.2232998
	speed: 0.1575s/iter; left time: 4366.3203s
Epoch: 4 cost time: 165.15095281600952
Epoch: 4, Steps: 1064 | Train Loss: 0.2386679 Vali Loss: 0.9593297 Test Loss: 0.6210404
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Autoformer_ETTm1_192_336_Autoformer_ETTm1_ftM_sl192_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.5545226335525513, mae:0.5164656043052673

Args in experiment:
Namespace(is_training=1, model_id='ETTh2_720_336', model='SparseTSF', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=336, period_len=24, basis_num=6, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.03, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
model的参数数量: 445
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 196560.0
Params: 445.0
196560.0 MACs
>>>>>>>start training : ETTh2_720_336_SparseTSF_ETTh2_ftM_sl720_pl336_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2545
test 2545
Max Memory (MB): 40.58447265625
Epoch: 1 cost time: 1.084413766860962
Epoch: 1, Steps: 29 | Train Loss: 0.8554290 Vali Loss: 0.5658172 Test Loss: 0.3667602
Validation loss decreased (inf --> 0.565817).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 49.8603515625
Epoch: 2 cost time: 0.9929535388946533
Epoch: 2, Steps: 29 | Train Loss: 0.7888912 Vali Loss: 0.4349266 Test Loss: 0.3633145
Validation loss decreased (0.565817 --> 0.434927).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 49.8603515625
Epoch: 3 cost time: 1.0155208110809326
Epoch: 3, Steps: 29 | Train Loss: 0.6808421 Vali Loss: 0.4294107 Test Loss: 0.3214781
Validation loss decreased (0.434927 --> 0.429411).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 50.4697265625
Epoch: 4 cost time: 1.0141119956970215
Epoch: 4, Steps: 29 | Train Loss: 0.6478811 Vali Loss: 0.4016709 Test Loss: 0.3128884
Validation loss decreased (0.429411 --> 0.401671).  Saving model ...
Updating learning rate to 0.024
Max Memory (MB): 50.4697265625
Epoch: 5 cost time: 1.035614013671875
Epoch: 5, Steps: 29 | Train Loss: 0.6367047 Vali Loss: 0.3862694 Test Loss: 0.3092826
Validation loss decreased (0.401671 --> 0.386269).  Saving model ...
Updating learning rate to 0.019200000000000002
Max Memory (MB): 50.4697265625
Epoch: 6 cost time: 1.0354385375976562
Epoch: 6, Steps: 29 | Train Loss: 0.6297054 Vali Loss: 0.3879032 Test Loss: 0.3059155
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.015360000000000004
Max Memory (MB): 50.4697265625
Epoch: 7 cost time: 1.0402328968048096
Epoch: 7, Steps: 29 | Train Loss: 0.6271711 Vali Loss: 0.3824679 Test Loss: 0.3106754
Validation loss decreased (0.386269 --> 0.382468).  Saving model ...
Updating learning rate to 0.012288000000000002
Max Memory (MB): 50.4697265625
Epoch: 8 cost time: 0.9890949726104736
Epoch: 8, Steps: 29 | Train Loss: 0.6280776 Vali Loss: 0.3851106 Test Loss: 0.3069176
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.009830400000000001
Max Memory (MB): 50.4697265625
Epoch: 9 cost time: 1.131781816482544
Epoch: 9, Steps: 29 | Train Loss: 0.6284804 Vali Loss: 0.3837235 Test Loss: 0.3073167
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.007864320000000003
Max Memory (MB): 50.4697265625
Epoch: 10 cost time: 1.013509750366211
Epoch: 10, Steps: 29 | Train Loss: 0.6260232 Vali Loss: 0.3790153 Test Loss: 0.3093389
Validation loss decreased (0.382468 --> 0.379015).  Saving model ...
Updating learning rate to 0.006291456000000002
Max Memory (MB): 50.4697265625
Epoch: 11 cost time: 1.0716936588287354
Epoch: 11, Steps: 29 | Train Loss: 0.6241177 Vali Loss: 0.3731824 Test Loss: 0.3087853
Validation loss decreased (0.379015 --> 0.373182).  Saving model ...
Updating learning rate to 0.005033164800000003
Max Memory (MB): 50.4697265625
Epoch: 12 cost time: 1.0139710903167725
Epoch: 12, Steps: 29 | Train Loss: 0.6265305 Vali Loss: 0.3839160 Test Loss: 0.3065568
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.004026531840000002
Max Memory (MB): 50.4697265625
Epoch: 13 cost time: 1.0694851875305176
Epoch: 13, Steps: 29 | Train Loss: 0.6244827 Vali Loss: 0.3772860 Test Loss: 0.3068620
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0032212254720000015
Max Memory (MB): 50.4697265625
Epoch: 14 cost time: 1.063256025314331
Epoch: 14, Steps: 29 | Train Loss: 0.6255964 Vali Loss: 0.3804401 Test Loss: 0.3073478
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0025769803776000016
Max Memory (MB): 50.4697265625
Epoch: 15 cost time: 0.9873266220092773
Epoch: 15, Steps: 29 | Train Loss: 0.6263758 Vali Loss: 0.3830454 Test Loss: 0.3076629
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.002061584302080001
Max Memory (MB): 50.4697265625
Epoch: 16 cost time: 0.9914302825927734
Epoch: 16, Steps: 29 | Train Loss: 0.6248512 Vali Loss: 0.3801276 Test Loss: 0.3071520
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 50.4697265625
>>>>>>>testing : ETTh2_720_336_SparseTSF_ETTh2_ftM_sl720_pl336_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.30878517031669617, mae:0.37044456601142883, rse:0.4454827904701233

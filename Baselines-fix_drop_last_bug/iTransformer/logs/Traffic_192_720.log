Args in experiment:
Namespace(is_training=1, model_id='traffic_192_720', model='iTransformer', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=192, label_len=48, pred_len=720, enc_in=862, dec_in=862, c_out=862, d_model=256, n_heads=8, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=2, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)
Use GPU: cuda:2
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
MACs: 889720832.0
Params: 1026512.0
889.72M MACs
>>>>>>>start training : traffic_192_720_iTransformer_custom_M_ft192_sl48_ll720_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11369
val 1037
test 2789
	iters: 100, epoch: 1 | loss: 0.5437109
	speed: 0.2312s/iter; left time: 797.8784s
	iters: 200, epoch: 1 | loss: 0.4593703
	speed: 0.1977s/iter; left time: 662.4613s
	iters: 300, epoch: 1 | loss: 0.4307643
	speed: 0.2045s/iter; left time: 664.8737s
Max Memory (MB): 5384.32373046875
Epoch: 1 cost time: 74.92412757873535
Epoch: 1, Steps: 355 | Train Loss: 0.5304128 Vali Loss: 0.5299327 Test Loss: 0.6354131
Validation loss decreased (inf --> 0.529933).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3709558
	speed: 2.0399s/iter; left time: 6315.5361s
	iters: 200, epoch: 2 | loss: 0.3647433
	speed: 0.2125s/iter; left time: 636.5449s
	iters: 300, epoch: 2 | loss: 0.3751407
	speed: 0.2136s/iter; left time: 618.6477s
Max Memory (MB): 5384.32373046875
Epoch: 2 cost time: 78.410888671875
Epoch: 2, Steps: 355 | Train Loss: 0.3749311 Vali Loss: 0.4683666 Test Loss: 0.5488065
Validation loss decreased (0.529933 --> 0.468367).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3377318
	speed: 2.1186s/iter; left time: 5807.0490s
	iters: 200, epoch: 3 | loss: 0.3479294
	speed: 0.2164s/iter; left time: 571.5020s
	iters: 300, epoch: 3 | loss: 0.3514479
	speed: 0.2180s/iter; left time: 553.8681s
Max Memory (MB): 5384.32373046875
Epoch: 3 cost time: 80.92851710319519
Epoch: 3, Steps: 355 | Train Loss: 0.3471114 Vali Loss: 0.4556538 Test Loss: 0.5301816
Validation loss decreased (0.468367 --> 0.455654).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3544098
	speed: 2.2806s/iter; left time: 5441.5736s
	iters: 200, epoch: 4 | loss: 0.3462420
	speed: 0.2146s/iter; left time: 490.5357s
	iters: 300, epoch: 4 | loss: 0.3322068
	speed: 0.2304s/iter; left time: 503.5960s
Max Memory (MB): 5384.32373046875
Epoch: 4 cost time: 85.26296377182007
Epoch: 4, Steps: 355 | Train Loss: 0.3384990 Vali Loss: 0.4500145 Test Loss: 0.5231286
Validation loss decreased (0.455654 --> 0.450015).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3259706
	speed: 2.2014s/iter; left time: 4471.0608s
	iters: 200, epoch: 5 | loss: 0.3318503
	speed: 0.2160s/iter; left time: 417.1281s
	iters: 300, epoch: 5 | loss: 0.3311632
	speed: 0.2153s/iter; left time: 394.1654s
Max Memory (MB): 5384.32373046875
Epoch: 5 cost time: 82.35756945610046
Epoch: 5, Steps: 355 | Train Loss: 0.3349185 Vali Loss: 0.4477074 Test Loss: 0.5196521
Validation loss decreased (0.450015 --> 0.447707).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3364964
	speed: 2.3702s/iter; left time: 3972.5252s
	iters: 200, epoch: 6 | loss: 0.3321468
	speed: 0.2010s/iter; left time: 316.7747s
	iters: 300, epoch: 6 | loss: 0.3247073
	speed: 0.2061s/iter; left time: 304.1378s
Max Memory (MB): 5384.32373046875
Epoch: 6 cost time: 76.9995768070221
Epoch: 6, Steps: 355 | Train Loss: 0.3332134 Vali Loss: 0.4467785 Test Loss: 0.5179628
Validation loss decreased (0.447707 --> 0.446779).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3338180
	speed: 2.2776s/iter; left time: 3008.7544s
	iters: 200, epoch: 7 | loss: 0.3437395
	speed: 0.2006s/iter; left time: 244.9197s
	iters: 300, epoch: 7 | loss: 0.3348562
	speed: 0.2129s/iter; left time: 238.6520s
Max Memory (MB): 5384.32373046875
Epoch: 7 cost time: 81.78069162368774
Epoch: 7, Steps: 355 | Train Loss: 0.3323842 Vali Loss: 0.4460496 Test Loss: 0.5173797
Validation loss decreased (0.446779 --> 0.446050).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3229843
	speed: 2.2160s/iter; left time: 2140.6901s
	iters: 200, epoch: 8 | loss: 0.3309752
	speed: 0.2140s/iter; left time: 185.3118s
	iters: 300, epoch: 8 | loss: 0.3380508
	speed: 0.2201s/iter; left time: 168.6113s
Max Memory (MB): 5384.32373046875
Epoch: 8 cost time: 80.72813820838928
Epoch: 8, Steps: 355 | Train Loss: 0.3319714 Vali Loss: 0.4460581 Test Loss: 0.5169078
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3321855
	speed: 2.2568s/iter; left time: 1378.8843s
	iters: 200, epoch: 9 | loss: 0.3323294
	speed: 0.2008s/iter; left time: 102.6004s
	iters: 300, epoch: 9 | loss: 0.3389780
	speed: 0.2027s/iter; left time: 83.2908s
Max Memory (MB): 5384.32373046875
Epoch: 9 cost time: 77.283287525177
Epoch: 9, Steps: 355 | Train Loss: 0.3317535 Vali Loss: 0.4457907 Test Loss: 0.5167521
Validation loss decreased (0.446050 --> 0.445791).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3213395
	speed: 2.3208s/iter; left time: 594.1238s
	iters: 200, epoch: 10 | loss: 0.3290121
	speed: 0.2306s/iter; left time: 35.9694s
	iters: 300, epoch: 10 | loss: 0.3281692
	speed: 0.2270s/iter; left time: 12.7132s
Max Memory (MB): 5384.32373046875
Epoch: 10 cost time: 86.61701250076294
Epoch: 10, Steps: 355 | Train Loss: 0.3316193 Vali Loss: 0.4458981 Test Loss: 0.5166487
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : traffic_192_720_iTransformer_custom_M_ft192_sl48_ll720_pl256_dm8_nh2_el1_dl256_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2789
test shape: (2789, 1, 720, 862) (2789, 1, 720, 862)
test shape: (2789, 720, 862) (2789, 720, 862)
mse:0.5167562365531921, mae:0.36093857884407043

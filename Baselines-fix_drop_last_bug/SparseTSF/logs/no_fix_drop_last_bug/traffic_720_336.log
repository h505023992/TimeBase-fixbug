Args in experiment:
Namespace(is_training=1, model_id='traffic_720_336', model='SparseTSF', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=336, period_len=24, basis_num=6, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=862, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.03, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
model的参数数量: 445
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 24204960.0
Params: 445.0
24.20M MACs
>>>>>>>start training : traffic_720_336_SparseTSF_custom_ftM_sl720_pl336_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11225
val 1421
test 3173
Max Memory (MB): 2143.78759765625
Epoch: 1 cost time: 46.98863506317139
Epoch: 1, Steps: 87 | Train Loss: 0.6198682 Vali Loss: 0.5101990 Test Loss: 0.6165301
Validation loss decreased (inf --> 0.510199).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 2436.1650390625
Epoch: 2 cost time: 45.958024740219116
Epoch: 2, Steps: 87 | Train Loss: 0.3004988 Vali Loss: 0.3467044 Test Loss: 0.4100465
Validation loss decreased (0.510199 --> 0.346704).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 2436.1650390625
Epoch: 3 cost time: 46.12737202644348
Epoch: 3, Steps: 87 | Train Loss: 0.2511375 Vali Loss: 0.3426133 Test Loss: 0.4052768
Validation loss decreased (0.346704 --> 0.342613).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 2436.1650390625
Epoch: 4 cost time: 46.006375312805176
Epoch: 4, Steps: 87 | Train Loss: 0.2492474 Vali Loss: 0.3417425 Test Loss: 0.4039485
Validation loss decreased (0.342613 --> 0.341743).  Saving model ...
Updating learning rate to 0.024
Max Memory (MB): 2436.1650390625
Epoch: 5 cost time: 46.75018763542175
Epoch: 5, Steps: 87 | Train Loss: 0.2490592 Vali Loss: 0.3418840 Test Loss: 0.4038943
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.019200000000000002
Max Memory (MB): 2436.1650390625
Epoch: 6 cost time: 45.589083194732666
Epoch: 6, Steps: 87 | Train Loss: 0.2488250 Vali Loss: 0.3410628 Test Loss: 0.4053833
Validation loss decreased (0.341743 --> 0.341063).  Saving model ...
Updating learning rate to 0.015360000000000004
Max Memory (MB): 2436.1650390625
Epoch: 7 cost time: 46.568668603897095
Epoch: 7, Steps: 87 | Train Loss: 0.2487392 Vali Loss: 0.3410002 Test Loss: 0.4041300
Validation loss decreased (0.341063 --> 0.341000).  Saving model ...
Updating learning rate to 0.012288000000000002
Max Memory (MB): 2436.1650390625
Epoch: 8 cost time: 48.22718262672424
Epoch: 8, Steps: 87 | Train Loss: 0.2486239 Vali Loss: 0.3407138 Test Loss: 0.4035435
Validation loss decreased (0.341000 --> 0.340714).  Saving model ...
Updating learning rate to 0.009830400000000001
Max Memory (MB): 2436.1650390625
Epoch: 9 cost time: 45.059608459472656
Epoch: 9, Steps: 87 | Train Loss: 0.2485881 Vali Loss: 0.3404289 Test Loss: 0.4032133
Validation loss decreased (0.340714 --> 0.340429).  Saving model ...
Updating learning rate to 0.007864320000000003
Max Memory (MB): 2436.1650390625
Epoch: 10 cost time: 46.65409302711487
Epoch: 10, Steps: 87 | Train Loss: 0.2485384 Vali Loss: 0.3408184 Test Loss: 0.4023705
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.006291456000000002
Max Memory (MB): 2436.1650390625
Epoch: 11 cost time: 45.80477499961853
Epoch: 11, Steps: 87 | Train Loss: 0.2485337 Vali Loss: 0.3403734 Test Loss: 0.4022349
Validation loss decreased (0.340429 --> 0.340373).  Saving model ...
Updating learning rate to 0.005033164800000003
Max Memory (MB): 2436.1650390625
Epoch: 12 cost time: 46.97222661972046
Epoch: 12, Steps: 87 | Train Loss: 0.2485181 Vali Loss: 0.3412168 Test Loss: 0.4035295
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.004026531840000002
Max Memory (MB): 2436.1650390625
Epoch: 13 cost time: 46.14912724494934
Epoch: 13, Steps: 87 | Train Loss: 0.2484110 Vali Loss: 0.3408994 Test Loss: 0.4032040
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0032212254720000015
Max Memory (MB): 2436.1650390625
Epoch: 14 cost time: 46.651345014572144
Epoch: 14, Steps: 87 | Train Loss: 0.2484426 Vali Loss: 0.3407018 Test Loss: 0.4034333
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0025769803776000016
Max Memory (MB): 2436.1650390625
Epoch: 15 cost time: 45.41038727760315
Epoch: 15, Steps: 87 | Train Loss: 0.2484261 Vali Loss: 0.3410122 Test Loss: 0.4026658
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.002061584302080001
Max Memory (MB): 2436.1650390625
Epoch: 16 cost time: 46.69388484954834
Epoch: 16, Steps: 87 | Train Loss: 0.2483551 Vali Loss: 0.3408402 Test Loss: 0.4036690
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 2436.1650390625
>>>>>>>testing : traffic_720_336_SparseTSF_custom_ftM_sl720_pl336_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
mse:0.4022342264652252, mae:0.2719935178756714, rse:0.5191758275032043

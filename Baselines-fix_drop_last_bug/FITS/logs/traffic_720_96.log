Args in experiment:
Namespace(is_training=1, model_id='traffic_720_96', model='FITS', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=862, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, ab=2, hidden_size=1, kernel=5, groups=1, levels=3, stacks=1, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0005, des='Exp', loss='mse', lradj='type3', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, aug_method='NA', aug_rate=0.5, in_batch_augmentation=False, in_dataset_augmentation=False, data_size=1, aug_data_size=1, seed=0, testset_div=2, test_time_train=False, train_mode=2, cut_freq=258, base_T=24, H_order=8)
Use GPU: cuda:0
>>>>>>>start training : traffic_720_96_FITS_custom_ftM_sl720_ll48_pl96_H8_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=258, out_features=292, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8312272896.0
params:  75628.0
Trainable parameters:  75628
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 55.887858390808105
Epoch: 1, Steps: 89 | Train Loss: 1.0683518 Vali Loss: 1.1539661 Test Loss: 1.3186885
Validation loss decreased (inf --> 1.153966).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 54.1430127620697
Epoch: 2, Steps: 89 | Train Loss: 0.8169290 Vali Loss: 1.0426141 Test Loss: 1.1930792
Validation loss decreased (1.153966 --> 1.042614).  Saving model ...
Updating learning rate to 0.000475
Epoch: 3 cost time: 54.090123653411865
Epoch: 3, Steps: 89 | Train Loss: 0.7167329 Vali Loss: 0.9801154 Test Loss: 1.1226211
Validation loss decreased (1.042614 --> 0.980115).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 54.704368591308594
Epoch: 4, Steps: 89 | Train Loss: 0.6434892 Vali Loss: 0.9251493 Test Loss: 1.0609567
Validation loss decreased (0.980115 --> 0.925149).  Saving model ...
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 52.739161014556885
Epoch: 5, Steps: 89 | Train Loss: 0.5829457 Vali Loss: 0.8777657 Test Loss: 1.0074651
Validation loss decreased (0.925149 --> 0.877766).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 53.94683885574341
Epoch: 6, Steps: 89 | Train Loss: 0.5314648 Vali Loss: 0.8323402 Test Loss: 0.9566007
Validation loss decreased (0.877766 --> 0.832340).  Saving model ...
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 49.53287935256958
Epoch: 7, Steps: 89 | Train Loss: 0.4869864 Vali Loss: 0.7965541 Test Loss: 0.9169934
Validation loss decreased (0.832340 --> 0.796554).  Saving model ...
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 53.60206198692322
Epoch: 8, Steps: 89 | Train Loss: 0.4482284 Vali Loss: 0.7623886 Test Loss: 0.8751544
Validation loss decreased (0.796554 --> 0.762389).  Saving model ...
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 56.02807354927063
Epoch: 9, Steps: 89 | Train Loss: 0.4143477 Vali Loss: 0.7285776 Test Loss: 0.8379796
Validation loss decreased (0.762389 --> 0.728578).  Saving model ...
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 52.87289214134216
Epoch: 10, Steps: 89 | Train Loss: 0.3843397 Vali Loss: 0.7003176 Test Loss: 0.8051161
Validation loss decreased (0.728578 --> 0.700318).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 55.633907079696655
Epoch: 11, Steps: 89 | Train Loss: 0.3577967 Vali Loss: 0.6745619 Test Loss: 0.7745531
Validation loss decreased (0.700318 --> 0.674562).  Saving model ...
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 52.50852942466736
Epoch: 12, Steps: 89 | Train Loss: 0.3341569 Vali Loss: 0.6497549 Test Loss: 0.7483143
Validation loss decreased (0.674562 --> 0.649755).  Saving model ...
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 52.9399619102478
Epoch: 13, Steps: 89 | Train Loss: 0.3130537 Vali Loss: 0.6310282 Test Loss: 0.7259618
Validation loss decreased (0.649755 --> 0.631028).  Saving model ...
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 52.654707193374634
Epoch: 14, Steps: 89 | Train Loss: 0.2941007 Vali Loss: 0.6128241 Test Loss: 0.7049748
Validation loss decreased (0.631028 --> 0.612824).  Saving model ...
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 52.06633400917053
Epoch: 15, Steps: 89 | Train Loss: 0.2770705 Vali Loss: 0.5943304 Test Loss: 0.6833705
Validation loss decreased (0.612824 --> 0.594330).  Saving model ...
Updating learning rate to 0.00024383748955776477
Epoch: 16 cost time: 53.74787259101868
Epoch: 16, Steps: 89 | Train Loss: 0.2616738 Vali Loss: 0.5774398 Test Loss: 0.6645894
Validation loss decreased (0.594330 --> 0.577440).  Saving model ...
Updating learning rate to 0.0002316456150798765
Epoch: 17 cost time: 53.27139139175415
Epoch: 17, Steps: 89 | Train Loss: 0.2478025 Vali Loss: 0.5621313 Test Loss: 0.6460533
Validation loss decreased (0.577440 --> 0.562131).  Saving model ...
Updating learning rate to 0.00022006333432588268
Epoch: 18 cost time: 53.49200463294983
Epoch: 18, Steps: 89 | Train Loss: 0.2351420 Vali Loss: 0.5484475 Test Loss: 0.6319857
Validation loss decreased (0.562131 --> 0.548447).  Saving model ...
Updating learning rate to 0.00020906016760958854
Epoch: 19 cost time: 52.88037848472595
Epoch: 19, Steps: 89 | Train Loss: 0.2236656 Vali Loss: 0.5375153 Test Loss: 0.6190490
Validation loss decreased (0.548447 --> 0.537515).  Saving model ...
Updating learning rate to 0.0001986071592291091
Epoch: 20 cost time: 53.8472855091095
Epoch: 20, Steps: 89 | Train Loss: 0.2131692 Vali Loss: 0.5267404 Test Loss: 0.6060860
Validation loss decreased (0.537515 --> 0.526740).  Saving model ...
Updating learning rate to 0.00018867680126765363
Epoch: 21 cost time: 54.180148124694824
Epoch: 21, Steps: 89 | Train Loss: 0.2036534 Vali Loss: 0.5168818 Test Loss: 0.5946172
Validation loss decreased (0.526740 --> 0.516882).  Saving model ...
Updating learning rate to 0.00017924296120427094
Epoch: 22 cost time: 52.46780252456665
Epoch: 22, Steps: 89 | Train Loss: 0.1948806 Vali Loss: 0.5065838 Test Loss: 0.5836726
Validation loss decreased (0.516882 --> 0.506584).  Saving model ...
Updating learning rate to 0.0001702808131440574
Epoch: 23 cost time: 53.21752953529358
Epoch: 23, Steps: 89 | Train Loss: 0.1868609 Vali Loss: 0.4995256 Test Loss: 0.5759528
Validation loss decreased (0.506584 --> 0.499526).  Saving model ...
Updating learning rate to 0.0001617667724868545
Epoch: 24 cost time: 53.38501501083374
Epoch: 24, Steps: 89 | Train Loss: 0.1794888 Vali Loss: 0.4912381 Test Loss: 0.5648041
Validation loss decreased (0.499526 --> 0.491238).  Saving model ...
Updating learning rate to 0.00015367843386251178
Epoch: 25 cost time: 54.60448884963989
Epoch: 25, Steps: 89 | Train Loss: 0.1726605 Vali Loss: 0.4825926 Test Loss: 0.5563380
Validation loss decreased (0.491238 --> 0.482593).  Saving model ...
Updating learning rate to 0.0001459945121693862
Epoch: 26 cost time: 52.763142108917236
Epoch: 26, Steps: 89 | Train Loss: 0.1664224 Vali Loss: 0.4751812 Test Loss: 0.5479584
Validation loss decreased (0.482593 --> 0.475181).  Saving model ...
Updating learning rate to 0.00013869478656091687
Epoch: 27 cost time: 54.51903772354126
Epoch: 27, Steps: 89 | Train Loss: 0.1606511 Vali Loss: 0.4693228 Test Loss: 0.5406619
Validation loss decreased (0.475181 --> 0.469323).  Saving model ...
Updating learning rate to 0.00013176004723287101
Epoch: 28 cost time: 53.32549810409546
Epoch: 28, Steps: 89 | Train Loss: 0.1553013 Vali Loss: 0.4629922 Test Loss: 0.5346664
Validation loss decreased (0.469323 --> 0.462992).  Saving model ...
Updating learning rate to 0.00012517204487122748
Epoch: 29 cost time: 53.5517475605011
Epoch: 29, Steps: 89 | Train Loss: 0.1503534 Vali Loss: 0.4576620 Test Loss: 0.5279447
Validation loss decreased (0.462992 --> 0.457662).  Saving model ...
Updating learning rate to 0.00011891344262766608
Epoch: 30 cost time: 54.704609394073486
Epoch: 30, Steps: 89 | Train Loss: 0.1457632 Vali Loss: 0.4533143 Test Loss: 0.5226131
Validation loss decreased (0.457662 --> 0.453314).  Saving model ...
Updating learning rate to 0.00011296777049628277
train 11465
val 1661
test 3413
Model(
  (freq_upsampler): Linear(in_features=258, out_features=292, bias=True)
)
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs:  8312272896.0
params:  75628.0
Trainable parameters:  75628
!!!!!!!!!!!!!!learning rate!!!!!!!!!!!!!!!
0.0005
Epoch: 1 cost time: 52.806381940841675
Epoch: 1, Steps: 89 | Train Loss: 0.2545956 Vali Loss: 0.3276990 Test Loss: 0.4035003
Validation loss decreased (inf --> 0.327699).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 53.90925312042236
Epoch: 2, Steps: 89 | Train Loss: 0.2331871 Vali Loss: 0.3278691 Test Loss: 0.4021117
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.000475
Epoch: 3 cost time: 54.73440217971802
Epoch: 3, Steps: 89 | Train Loss: 0.2327348 Vali Loss: 0.3273434 Test Loss: 0.4023131
Validation loss decreased (0.327699 --> 0.327343).  Saving model ...
Updating learning rate to 0.00045125
Epoch: 4 cost time: 53.95457434654236
Epoch: 4, Steps: 89 | Train Loss: 0.2325034 Vali Loss: 0.3275447 Test Loss: 0.4017498
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0004286875
Epoch: 5 cost time: 55.171313524246216
Epoch: 5, Steps: 89 | Train Loss: 0.2324140 Vali Loss: 0.3254846 Test Loss: 0.4011654
Validation loss decreased (0.327343 --> 0.325485).  Saving model ...
Updating learning rate to 0.00040725312499999993
Epoch: 6 cost time: 49.68975782394409
Epoch: 6, Steps: 89 | Train Loss: 0.2321786 Vali Loss: 0.3275097 Test Loss: 0.4015955
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0003868904687499999
Epoch: 7 cost time: 52.503358364105225
Epoch: 7, Steps: 89 | Train Loss: 0.2322065 Vali Loss: 0.3267010 Test Loss: 0.4007770
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.00036754594531249993
Epoch: 8 cost time: 51.04851818084717
Epoch: 8, Steps: 89 | Train Loss: 0.2321682 Vali Loss: 0.3266546 Test Loss: 0.4007684
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.00034916864804687486
Epoch: 9 cost time: 51.15756845474243
Epoch: 9, Steps: 89 | Train Loss: 0.2320704 Vali Loss: 0.3271013 Test Loss: 0.4008030
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.00033171021564453113
Epoch: 10 cost time: 52.78995084762573
Epoch: 10, Steps: 89 | Train Loss: 0.2318155 Vali Loss: 0.3253561 Test Loss: 0.4008148
Validation loss decreased (0.325485 --> 0.325356).  Saving model ...
Updating learning rate to 0.00031512470486230455
Epoch: 11 cost time: 52.19291543960571
Epoch: 11, Steps: 89 | Train Loss: 0.2319957 Vali Loss: 0.3253890 Test Loss: 0.4012723
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00029936846961918935
Epoch: 12 cost time: 53.71644425392151
Epoch: 12, Steps: 89 | Train Loss: 0.2317535 Vali Loss: 0.3260973 Test Loss: 0.4010565
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0002844000461382298
Epoch: 13 cost time: 51.2745463848114
Epoch: 13, Steps: 89 | Train Loss: 0.2317011 Vali Loss: 0.3256033 Test Loss: 0.4010629
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0002701800438313183
Epoch: 14 cost time: 52.79966354370117
Epoch: 14, Steps: 89 | Train Loss: 0.2316967 Vali Loss: 0.3272358 Test Loss: 0.4012727
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0002566710416397524
Epoch: 15 cost time: 52.882075786590576
Epoch: 15, Steps: 89 | Train Loss: 0.2318448 Vali Loss: 0.3261132 Test Loss: 0.4001841
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : traffic_720_96_FITS_custom_ftM_sl720_ll48_pl96_H8_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3413
mse:0.4019687786102295, mae:0.27493737030029297, rse:0.5157649517059326, corr:[0.28108868 0.2923793  0.2933363  0.2930552  0.2931632  0.29345593
 0.29348406 0.29336336 0.29269567 0.29226112 0.29220933 0.2915566
 0.29103795 0.2912479  0.29167977 0.29225028 0.29260546 0.29256806
 0.29258177 0.2925292  0.2922102  0.29207054 0.29185665 0.29168278
 0.29336008 0.29458767 0.29471028 0.2944992  0.2945959  0.2940287
 0.29296342 0.29274404 0.2928148  0.29263127 0.29299212 0.2933658
 0.29313102 0.29334527 0.29384032 0.2935063  0.29326308 0.29379973
 0.2939818  0.29353365 0.2932183  0.2930534  0.29292405 0.29315946
 0.29346415 0.29314741 0.29298717 0.29284164 0.29283828 0.29334065
 0.29335937 0.2924007  0.29189184 0.2921531  0.29213923 0.29217282
 0.29262707 0.29265898 0.2927164  0.29351684 0.29406342 0.29370996
 0.2930667  0.29230708 0.29167342 0.2917889  0.2923142  0.29274416
 0.29269353 0.2920708  0.29181004 0.29227996 0.29247466 0.29201594
 0.29153576 0.291334   0.29140732 0.2916565  0.29159936 0.29128674
 0.2913711  0.29156575 0.29144612 0.2915926  0.2916157  0.2907776
 0.29042906 0.29046166 0.28953716 0.2890985  0.28908357 0.29214412]

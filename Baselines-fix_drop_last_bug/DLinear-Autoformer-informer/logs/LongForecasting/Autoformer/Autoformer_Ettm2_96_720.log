Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Autoformer_ETTm2_96_720', model='Autoformer', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Autoformer_ETTm2_96_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.2832706
	speed: 0.2320s/iter; left time: 7319.0719s
	iters: 200, epoch: 1 | loss: 0.6631321
	speed: 0.2039s/iter; left time: 6413.0783s
	iters: 300, epoch: 1 | loss: 0.3694186
	speed: 0.2041s/iter; left time: 6400.0735s
	iters: 400, epoch: 1 | loss: 0.5616058
	speed: 0.2025s/iter; left time: 6328.0661s
	iters: 500, epoch: 1 | loss: 0.9588846
	speed: 0.2023s/iter; left time: 6300.9662s
	iters: 600, epoch: 1 | loss: 0.8062330
	speed: 0.2003s/iter; left time: 6218.6657s
	iters: 700, epoch: 1 | loss: 1.0249479
	speed: 0.2039s/iter; left time: 6311.4706s
	iters: 800, epoch: 1 | loss: 0.3439954
	speed: 0.2045s/iter; left time: 6309.3721s
	iters: 900, epoch: 1 | loss: 0.4108966
	speed: 0.2034s/iter; left time: 6253.5516s
	iters: 1000, epoch: 1 | loss: 0.2626381
	speed: 0.2040s/iter; left time: 6252.8467s
Epoch: 1 cost time: 217.69812488555908
Epoch: 1, Steps: 1055 | Train Loss: 0.5894724 Vali Loss: 0.3205286 Test Loss: 0.4584209
Validation loss decreased (inf --> 0.320529).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6818913
	speed: 1.6527s/iter; left time: 50402.0619s
	iters: 200, epoch: 2 | loss: 0.5986651
	speed: 0.2016s/iter; left time: 6128.5680s
	iters: 300, epoch: 2 | loss: 0.5897815
	speed: 0.2024s/iter; left time: 6133.0006s
	iters: 400, epoch: 2 | loss: 0.3113443
	speed: 0.2051s/iter; left time: 6192.0713s
	iters: 500, epoch: 2 | loss: 0.6988712
	speed: 0.2030s/iter; left time: 6108.6341s
	iters: 600, epoch: 2 | loss: 0.4714535
	speed: 0.2019s/iter; left time: 6057.6172s
	iters: 700, epoch: 2 | loss: 0.3455751
	speed: 0.2034s/iter; left time: 6080.1387s
	iters: 800, epoch: 2 | loss: 0.3761119
	speed: 0.2051s/iter; left time: 6110.1734s
	iters: 900, epoch: 2 | loss: 0.3671152
	speed: 0.2020s/iter; left time: 5999.5048s
	iters: 1000, epoch: 2 | loss: 0.4548031
	speed: 0.2011s/iter; left time: 5953.0066s
Epoch: 2 cost time: 214.63786816596985
Epoch: 2, Steps: 1055 | Train Loss: 0.5453502 Vali Loss: 0.3378103 Test Loss: 0.4825839
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7034729
	speed: 1.5981s/iter; left time: 47049.7770s
	iters: 200, epoch: 3 | loss: 0.4150502
	speed: 0.2009s/iter; left time: 5893.4962s
	iters: 300, epoch: 3 | loss: 0.2762783
	speed: 0.2015s/iter; left time: 5892.8668s
	iters: 400, epoch: 3 | loss: 0.6955594
	speed: 0.2026s/iter; left time: 5903.8288s
	iters: 500, epoch: 3 | loss: 0.2715690
	speed: 0.2045s/iter; left time: 5938.8214s
	iters: 600, epoch: 3 | loss: 0.7992452
	speed: 0.2052s/iter; left time: 5938.7073s
	iters: 700, epoch: 3 | loss: 0.4969018
	speed: 0.2059s/iter; left time: 5939.2526s
	iters: 800, epoch: 3 | loss: 0.6859297
	speed: 0.2003s/iter; left time: 5756.0428s
	iters: 900, epoch: 3 | loss: 0.5578740
	speed: 0.2010s/iter; left time: 5758.1852s
	iters: 1000, epoch: 3 | loss: 0.3249232
	speed: 0.2016s/iter; left time: 5752.9137s
Epoch: 3 cost time: 214.45615911483765
Epoch: 3, Steps: 1055 | Train Loss: 0.4969026 Vali Loss: 0.3663964 Test Loss: 0.5319582
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4585572
	speed: 1.5964s/iter; left time: 45314.6637s
	iters: 200, epoch: 4 | loss: 0.5022599
	speed: 0.2018s/iter; left time: 5708.3439s
	iters: 300, epoch: 4 | loss: 0.3433617
	speed: 0.2008s/iter; left time: 5658.8093s
	iters: 400, epoch: 4 | loss: 0.5438328
	speed: 0.2015s/iter; left time: 5660.3168s
	iters: 500, epoch: 4 | loss: 0.4201833
	speed: 0.2036s/iter; left time: 5696.6868s
	iters: 600, epoch: 4 | loss: 0.4429412
	speed: 0.2062s/iter; left time: 5751.0507s
	iters: 700, epoch: 4 | loss: 0.3837438
	speed: 0.2073s/iter; left time: 5760.6482s
	iters: 800, epoch: 4 | loss: 0.5354751
	speed: 0.2011s/iter; left time: 5568.9502s
	iters: 900, epoch: 4 | loss: 0.5503592
	speed: 0.2009s/iter; left time: 5542.9626s
	iters: 1000, epoch: 4 | loss: 0.3069904
	speed: 0.2021s/iter; left time: 5554.1017s
Epoch: 4 cost time: 215.24673056602478
Epoch: 4, Steps: 1055 | Train Loss: 0.4685246 Vali Loss: 0.3402639 Test Loss: 0.5083239
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Autoformer_ETTm2_96_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.45790860056877136, mae:0.43979084491729736

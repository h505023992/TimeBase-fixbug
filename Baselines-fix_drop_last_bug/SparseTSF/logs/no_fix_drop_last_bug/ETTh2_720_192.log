Args in experiment:
Namespace(is_training=1, model_id='ETTh2_720_192', model='SparseTSF', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=720, label_len=48, pred_len=192, period_len=24, basis_num=6, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=7, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='learned', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=256, patience=5, learning_rate=0.03, des='test', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=0, devices='0,1', test_flop=False)
Use GPU: cuda:0
model的参数数量: 265
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
MACs: 166320.0
Params: 265.0
166320.0 MACs
>>>>>>>start training : ETTh2_720_192_SparseTSF_ETTh2_ftM_sl720_pl192_test_0_seed2023>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7729
val 2689
test 2689
Max Memory (MB): 36.2158203125
Epoch: 1 cost time: 1.0994963645935059
Epoch: 1, Steps: 30 | Train Loss: 0.7693345 Vali Loss: 0.4705123 Test Loss: 0.3759452
Validation loss decreased (inf --> 0.470512).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 41.6376953125
Epoch: 2 cost time: 1.0377418994903564
Epoch: 2, Steps: 30 | Train Loss: 0.6938135 Vali Loss: 0.3564626 Test Loss: 0.3849016
Validation loss decreased (0.470512 --> 0.356463).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 41.6376953125
Epoch: 3 cost time: 0.9806790351867676
Epoch: 3, Steps: 30 | Train Loss: 0.6032047 Vali Loss: 0.3041255 Test Loss: 0.3367262
Validation loss decreased (0.356463 --> 0.304126).  Saving model ...
Updating learning rate to 0.03
Max Memory (MB): 41.6376953125
Epoch: 4 cost time: 1.1096069812774658
Epoch: 4, Steps: 30 | Train Loss: 0.5494942 Vali Loss: 0.2925640 Test Loss: 0.3217883
Validation loss decreased (0.304126 --> 0.292564).  Saving model ...
Updating learning rate to 0.024
Max Memory (MB): 41.6376953125
Epoch: 5 cost time: 0.9785170555114746
Epoch: 5, Steps: 30 | Train Loss: 0.5351108 Vali Loss: 0.2911181 Test Loss: 0.3163665
Validation loss decreased (0.292564 --> 0.291118).  Saving model ...
Updating learning rate to 0.019200000000000002
Max Memory (MB): 41.6376953125
Epoch: 6 cost time: 0.9897186756134033
Epoch: 6, Steps: 30 | Train Loss: 0.5329059 Vali Loss: 0.2915589 Test Loss: 0.3127558
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.015360000000000004
Max Memory (MB): 41.6376953125
Epoch: 7 cost time: 1.0950391292572021
Epoch: 7, Steps: 30 | Train Loss: 0.5303995 Vali Loss: 0.2890506 Test Loss: 0.3131114
Validation loss decreased (0.291118 --> 0.289051).  Saving model ...
Updating learning rate to 0.012288000000000002
Max Memory (MB): 41.6376953125
Epoch: 8 cost time: 1.0559937953948975
Epoch: 8, Steps: 30 | Train Loss: 0.5304568 Vali Loss: 0.2919375 Test Loss: 0.3075055
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.009830400000000001
Max Memory (MB): 41.6376953125
Epoch: 9 cost time: 1.110863447189331
Epoch: 9, Steps: 30 | Train Loss: 0.5306533 Vali Loss: 0.2870248 Test Loss: 0.3102412
Validation loss decreased (0.289051 --> 0.287025).  Saving model ...
Updating learning rate to 0.007864320000000003
Max Memory (MB): 41.6376953125
Epoch: 10 cost time: 1.00705885887146
Epoch: 10, Steps: 30 | Train Loss: 0.5295132 Vali Loss: 0.2857162 Test Loss: 0.3140536
Validation loss decreased (0.287025 --> 0.285716).  Saving model ...
Updating learning rate to 0.006291456000000002
Max Memory (MB): 41.6376953125
Epoch: 11 cost time: 0.9759726524353027
Epoch: 11, Steps: 30 | Train Loss: 0.5282029 Vali Loss: 0.2862835 Test Loss: 0.3142459
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.005033164800000003
Max Memory (MB): 41.6376953125
Epoch: 12 cost time: 1.0268590450286865
Epoch: 12, Steps: 30 | Train Loss: 0.5279384 Vali Loss: 0.2848967 Test Loss: 0.3131085
Validation loss decreased (0.285716 --> 0.284897).  Saving model ...
Updating learning rate to 0.004026531840000002
Max Memory (MB): 41.6376953125
Epoch: 13 cost time: 1.0062546730041504
Epoch: 13, Steps: 30 | Train Loss: 0.5273323 Vali Loss: 0.2853475 Test Loss: 0.3140609
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0032212254720000015
Max Memory (MB): 41.6376953125
Epoch: 14 cost time: 1.0219826698303223
Epoch: 14, Steps: 30 | Train Loss: 0.5273749 Vali Loss: 0.2878794 Test Loss: 0.3105749
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0025769803776000016
Max Memory (MB): 41.6376953125
Epoch: 15 cost time: 0.9995725154876709
Epoch: 15, Steps: 30 | Train Loss: 0.5279100 Vali Loss: 0.2872286 Test Loss: 0.3136048
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.002061584302080001
Max Memory (MB): 41.6376953125
Epoch: 16 cost time: 0.9916949272155762
Epoch: 16, Steps: 30 | Train Loss: 0.5274300 Vali Loss: 0.2855845 Test Loss: 0.3122539
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.001649267441664001
Max Memory (MB): 41.6376953125
Epoch: 17 cost time: 0.98282790184021
Epoch: 17, Steps: 30 | Train Loss: 0.5254141 Vali Loss: 0.2885809 Test Loss: 0.3126076
EarlyStopping counter: 5 out of 5
Early stopping
Final Max Memory (MB): 41.6376953125
>>>>>>>testing : ETTh2_720_192_SparseTSF_ETTh2_ftM_sl720_pl192_test_0_seed2023<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3131084740161896, mae:0.3622157573699951, rse:0.4460558295249939
